{"title": "Learning Abstractions for Program Synthesis.", "fields": ["subject matter expert", "predicate", "program synthesis", "speedup", "template"], "abstract": "Many example-guided program synthesis techniques use abstractions to prune the search space. While abstraction-based synthesis has proven to be very powerful, a domain expert needs to provide a suitable abstract domain, together with the abstract transformers of each DSL construct. However, coming up with useful abstractions can be non-trivial, as it requires both domain expertise and knowledge about the synthesizer. In this paper, we propose a new technique for learning abstractions that are useful for instantiating a general synthesis framework in a new domain. Given a DSL and a small set of training problems, our method uses tree interpolation to infer reusable predicate templates that speed up synthesis in a given domain. Our method also learns suitable abstract transformers by solving a certain kind of second-order constraint solving problem in a data-driven way. We have implemented the proposed method in a tool called Atlas and evaluate it in the context of the Blaze meta-synthesizer. Our evaluation shows that (a) Atlas can learn useful abstract domains and transformers from few training problems, and (b) the abstractions learned by Atlas allow Blaze to achieve significantly better results compared to manually-crafted abstractions.", "citation": "Not cited", "year": "2018", "departments": ["University of Texas at Austin", "University of Texas at Austin", "University of Texas at Austin", "Microsoft"], "conf": "cav", "authors": ["Xinyu Wang.....http://dblp.org/pers/hd/w/Wang:Xinyu", "Greg Anderson.....http://dblp.org/pers/hd/a/Anderson:Greg", "Isil Dillig.....http://dblp.org/pers/hd/d/Dillig:Isil", "Kenneth L. McMillan.....http://dblp.org/pers/hd/m/McMillan:Kenneth_L="], "pages": 20}