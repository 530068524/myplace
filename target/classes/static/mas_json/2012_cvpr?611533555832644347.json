{"title": "Revisiting uncertainty in graph cut solutions.", "fields": ["marginal distribution", "cut", "graph cuts in computer vision", "conditional random field", "belief propagation"], "abstract": "Graph cuts is a popular algorithm for finding the MAP assignment of many large-scale graphical models that are common in computer vision. While graph cuts is powerful, it does not provide information about the marginal probabilities associated with the solution it finds. To assess uncertainty, we are forced to fall back on less efficient and inexact inference algorithms such as loopy belief propagation, or use less principled surrogate representations of uncertainty such as the min-marginal approach of Kohli & Torr [8]. In this work, we give new justification for using min-marginals to compute the uncertainty in conditional random fields, framing the min-marginal outputs as exact marginals under a specially-chosen generative probabilistic model. We leverage this view to learn properly calibrated marginal probabilities as the result of straightforward maximization of the training likelihood, showing that the necessary subgradients can be computed efficiently using dynamic graph cut operations. We also show how this approach can be extended to compute multi-label marginal distributions, where again dynamic graph cuts enable efficient marginal inference and maximum likelihood learning. We demonstrate empirically that \u2014 after proper training \u2014 uncertainties based on min-marginals provide better-calibrated probabilities than baselines and that these distributions can be exploited in a decision-theoretic way for improved segmentation in low-level vision.", "citation": "Citations (12)", "year": "2012", "departments": ["University of Toronto", "Harvard University"], "conf": "cvpr", "authors": ["Daniel Tarlow.....http://dblp.org/pers/hd/t/Tarlow:Daniel", "Ryan Prescott Adams.....http://dblp.org/pers/hd/a/Adams:Ryan_Prescott"], "pages": 8}