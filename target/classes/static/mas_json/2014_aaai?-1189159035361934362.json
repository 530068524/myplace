{"title": "Gradient Descent with Proximal Average for Nonconvex and Composite Regularization.", "fields": ["regularization", "composite number", "gradient descent", "optimization problem", "machine learning"], "abstract": "Sparse modeling has been highly successful in many realworld applications. While a lot of interests have been on convex regularization, recent studies show that nonconvex regularizers can outperform their convex counterparts in many situations. However, the resulting nonconvex optimization problems are often challenging, especially for composite regularizers such as the nonconvex overlapping group lasso. In this paper, by using a recent mathematical tool known as the proximal average, we propose a novel proximal gradient descent method for optimization with a wide class of nonconvex and composite regularizers. Instead of directly solving the proximal step associated with a composite regularizer, we average the solutions from the proximal problems of the constituent regularizers. This simple strategy has guaranteed convergence and low per-iteration complexity. Experimental results on a number of synthetic and real-world data sets demonstrate the effectiveness and efficiency of the proposed optimization algorithm, and also the improved classification performance resulting from the nonconvex regularizers.", "citation": "Citations (6)", "departments": ["Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology"], "authors": ["Wenliang Zhong.....http://dblp.org/pers/hd/z/Zhong:Wenliang", "James T. Kwok.....http://dblp.org/pers/hd/k/Kwok:James_T="], "conf": "aaai", "year": "2014", "pages": 7}