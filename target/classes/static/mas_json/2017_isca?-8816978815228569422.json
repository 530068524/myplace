{"title": "Aggressive Pipelining of Irregular Applications on Reconfigurable Hardware.", "fields": ["hardware acceleration", "pipeline", "reconfigurability", "datapath", "compile time"], "abstract": "CPU-FPGA heterogeneous platforms offer a promising solution for high-performance and energy-efficient computing systems by providing specialized accelerators with post-silicon reconfigurability. To unleash the power of FPGA, however, the programmability gap has to be filled so that applications specified in high-level programming languages can be efficiently mapped and scheduled on FPGA. The above problem is even more challenging for irregular applications, in which the execution dependency can only be determined at run time. Thus over-serialized accelerators are generated from existing works that rely on compile time analysis to schedule the computation.   In this work, we propose a comprehensive software-hardware co-design framework, which captures parallelism in irregular applications and aggressively schedules pipelined execution on reconfigurable platform. Based on an inherently parallel abstraction packaging parallelism for runtime schedule, our framework significantly differs from existing works that tend to schedule executions at compile time. An irregular application is formulated as a set of tasks with their dependencies specified as rules describing the conditions under which a subset of tasks can be executed concurrently. Then datapaths on FPGA will be generated by transforming applications in the formulation into task pipelines orchestrated by evaluating rules at runtime, which could exploit fine-grained pipeline parallelism as handcrafted accelerators do.   An evaluation shows that this framework is able to produce datapath with its quality close to handcrafted designs. Experiments show that generated accelerators are dramatically more efficient than those created by current high-level synthesis tools. Meanwhile, accelerators generated for a set of irregular applications attain 0.5x~1.9x performance compared to equivalent software implementations we selected on a server-grade 10-core processor, with the memory subsystem remaining as the bottleneck.", "citation": "Citations (1)", "departments": ["Tsinghua University", "Tsinghua University", "Tsinghua University", "Tsinghua University", "Tsinghua University"], "authors": ["Zhaoshi Li.....http://dblp.org/pers/hd/l/Li:Zhaoshi", "Leibo Liu.....http://dblp.org/pers/hd/l/Liu:Leibo", "Yangdong Deng.....http://dblp.org/pers/hd/d/Deng:Yangdong", "Shouyi Yin.....http://dblp.org/pers/hd/y/Yin:Shouyi", "Yao Wang.....http://dblp.org/pers/hd/w/Wang:Yao", "Shaojun Wei.....http://dblp.org/pers/hd/w/Wei:Shaojun"], "conf": "isca", "year": "2017", "pages": 12}