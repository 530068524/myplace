{"title": "Stochastic Three-Composite Convex Minimization.", "fields": ["proximal gradient methods", "convex analysis", "stochastic gradient descent", "drift plus penalty", "proximal gradient methods for learning"], "abstract": "We propose a stochastic optimization method for the minimization of the sum of three convex functions, one of which has Lipschitz continuous gradient as well as restricted strong convexity. Our approach is most suitable in the setting where it is computationally advantageous to process smooth term in the decomposition with its stochastic gradient estimate and the other two functions separately with their proximal operators, such as doubly regularized empirical risk minimization problems. We prove the convergence characterization of the proposed algorithm in expectation under the standard assumptions for the stochastic gradient estimate of the smooth term. Our method operates in the primal space and can be considered as a stochastic extension of the three-operator splitting method. Finally, numerical evidence supports the effectiveness of our method in real-world problems.", "citation": "Citations (1)", "departments": ["\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne", "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne"], "authors": ["Alp Yurtsever.....http://dblp.org/pers/hd/y/Yurtsever:Alp", "Bang C\u00f4ng Vu.....http://dblp.org/pers/hd/v/Vu:Bang_C=ocirc=ng", "Volkan Cevher.....http://dblp.org/pers/hd/c/Cevher:Volkan"], "conf": "nips", "year": "2016", "pages": 9}