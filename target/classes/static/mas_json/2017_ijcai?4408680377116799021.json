{"title": "Single-Pass PCA of Large High-Dimensional Data.", "fields": ["data matrix", "sparse pca", "clustering high dimensional data", "singular value", "orders of magnitude"], "abstract": "Principal component analysis (PCA) is a fundamental dimension reduction tool in statistics and machine learning. For large and high-dimensional data, computing the PCA (i.e., the singular vectors corresponding to a number of dominant singular values of the data matrix) becomes a challenging task. In this work, a single-pass randomized algorithm is proposed to compute PCA with only one pass over the data. It is suitable for processing extremely large and high-dimensional data stored in slow memory (hard disk) or the data generated in a streaming fashion. Experiments with synthetic and real data validate the algorithm's accuracy, which has orders of magnitude smaller error than an existing single-pass algorithm. For a set of high-dimensional data stored as a 150 GB file, the proposed algorithm is able to compute the first 50 principal components in just 24 minutes on a typical 24-core computer, with less than 1 GB memory cost.", "citation": "Citations (1)", "year": "2017", "departments": ["Tsinghua University", "Chinese Academy of Sciences", "Old Dominion University"], "conf": "ijcai", "authors": ["Wenjian Yu.....http://dblp.org/pers/hd/y/Yu:Wenjian", "Yu Gu.....http://dblp.org/pers/hd/g/Gu:Yu", "Jian Li.....http://dblp.org/pers/hd/l/Li:Jian", "Shenghua Liu.....http://dblp.org/pers/hd/l/Liu:Shenghua", "Yaohang Li.....http://dblp.org/pers/hd/l/Li:Yaohang"], "pages": 7}