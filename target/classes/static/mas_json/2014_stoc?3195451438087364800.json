{"title": "The power of localization for efficiently learning linear separators with noise.", "fields": ["linear classifier", "unit sphere", "active learning", "uniform distribution", "outlier", "hinge loss", "isotropy", "exponential growth", "adversary"], "abstract": "We introduce a new approach for designing computationally efficient and noise tolerant algorithms for learning linear separators. We consider the malicious noise model of Valiant [41, 32] and the adversarial label noise model of Kearns, Schapire, and Sellie [34]. For malicious noise, where the adversary can corrupt an  \u03b7  of fraction both the label part and the feature part, we provide a polynomial-time algorithm for learning linear separators in R  d   under the uniform distribution with nearly information-theoretically optimal noise tolerance of  \u03b7  = \u03a9( e ), improving on the \u03a9(&epsilon/d 1/4 ) noise-tolerance of [31] and the \u03a9(e 2 /log(d/e) of [35]. For the  adversarial label noise  model, where the distribution over the feature vectors is unchanged, and the overall probability of a noisy label is constrained to be at most  \u03b7 , we give a polynomial-time algorithm for learning linear separators in R  d   under the uniform distribution that can also handle a noise rate of  \u03b7  = \u03a9( e ). This improves over the results of [31] which either required runtime super-exponential in 1/ e  (ours is polynomial in 1/ e ) or tolerated less noise.   In the case that the distribution is isotropic log-concave, we present a polynomial-time algorithm for the malicious noise model that tolerates \u03a9(e/log 2 (1/e)) noise, and a polynomial-time algorithm for the adversarial label noise model that also handles \u03a9(e/log 2 (1/e)) noise. Both of these also improve on results from [35]. In particular, in the case of malicious noise, unlike previous results, our noise tolerance has no dependence on the dimension  d  of the space.   Our algorithms are also efficient in the active learning setting, where learning algorithms only receive the classifications of examples when they ask for them. We show that, in this model, our algorithms achieve a label complexity whose dependence on the error parameter  e  is polylogarithmic (and thus exponentially better than that of any passive algorithm). This provides the first polynomial time active learning algorithm for learning linear separators in the presence of malicious noise or adversarial label noise.", "citation": "Citations (61)", "year": "2014", "departments": ["Princeton University", "Georgia Institute of Technology", "Microsoft", "Rutgers University", "Carnegie Mellon University", "Sentient Techno ... n Francisco, CA"], "conf": "stoc", "authors": ["Pranjal Awasthi.....http://dblp.org/pers/hd/a/Awasthi:Pranjal", "Maria-Florina Balcan.....http://dblp.org/pers/hd/b/Balcan:Maria=Florina", "Philip M. Long.....http://dblp.org/pers/hd/l/Long:Philip_M="], "pages": 10}