{"title": "Stochastic Online Greedy Learning with Semi-bandit Feedbacks.", "fields": ["greedy randomized adaptive search procedure", "combinatorial optimization", "regret", "time horizon", "greedy algorithm"], "abstract": "The greedy algorithm is extensively studied in the field of combinatorial optimization for decades. In this paper, we address the online learning problem when the input to the greedy algorithm is stochastic with unknown parameters that have to be learned over time. We first propose the greedy regret and \u220a-quasi greedy regret as learning metrics comparing with the performance of offline greedy algorithm. We then propose two online greedy learning algorithms with semi-bandit feedbacks, which use multi-armed bandit and pure exploration bandit policies at each level of greedy learning, one for each of the regret metrics respectively. Both algorithms achieve O(log T) problem-dependent regret bound (T being the time horizon) for a general class of combinatorial structures and reward functions that allow greedy solutions. We further show that the bound is tight in T and other problem instance parameters.", "citation": "Citations (10)", "year": "2015", "departments": ["Tsinghua University", "Tsinghua University", "Microsoft"], "conf": "nips", "authors": ["Tian Lin.....http://dblp.org/pers/hd/l/Lin:Tian", "Jian Li.....http://dblp.org/pers/hd/l/Li:Jian", "Wei Chen.....http://dblp.org/pers/hd/c/Chen:Wei"], "pages": 9}