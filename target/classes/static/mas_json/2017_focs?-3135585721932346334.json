{"title": "A Time-Space Lower Bound for a Large Class of Learning Problems.", "fields": ["parity", "matrix", "combinatorics", "discrete mathematics", "mathematics", "p complete", "upper and lower bounds", "singular value", "special case"], "abstract": "We prove a general time-space lower bound that applies for a large class of learning problems and shows that for every problem in that class, any learning algorithm requires either a memory of quadratic size or an exponential number of samples. As a special case, this gives a new proof for the time-space lower bound for parity learning [R16]. Our result is stated in terms of the norm of the matrix that corresponds to the learning problem. Let X, A be two finite sets. Let M: A \u00d7 X \\rightarrow \\{-1,1\\} be a matrix. The matrix M corresponds to the following learning problem: An unknown element x \u220a X was chosen uniformly at random. A learner tries to learn x from a stream of samples, (a_1, b_1), (a_2, b_2)..., where for every i, a_i \u220a A is chosen uniformly at random and b_i = M(a_i,x). Let \\sigma be the largest singular value of M and note that always \\sigma \u2264 |A|^{1/2} \u22c5 |X|^{1/2}. We show that if \\sigma \u2264 |A|^{1/2} \u22c5 |X|^{1/2 - \u2265ilon, then any learning algorithm for the corresponding learning problem requires either a memory of size quadratic in \u2265ilon n or number of samples exponential in \u2265ilon n, where n = \\log_2 |X|.As a special case, this gives a new proof for the memorysamples lower bound for parity learning [14].", "citation": "Not cited", "departments": ["Princeton University"], "authors": ["Ran Raz.....http://dblp.org/pers/hd/r/Raz:Ran"], "conf": "focs", "year": "2017", "pages": 11}