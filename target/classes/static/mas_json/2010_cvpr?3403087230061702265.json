{"title": "Learning a hierarchy of discriminative space-time neighborhood features for human action recognition.", "fields": ["metric", "pose", "discriminative model", "information space", "bag of words model"], "abstract": "Recent work shows how to use local spatio-temporal features to learn models of realistic human actions from video. However, existing methods typically rely on a predefined spatial binning of the local descriptors to impose spatial information beyond a pure \u201cbag-of-words\u201d model, and thus may fail to capture the most informative space-time relationships. We propose to learn the shapes of space-time feature neighborhoods that are most discriminative for a given action category. Given a set of training videos, our method first extracts local motion and appearance features, quantizes them to a visual vocabulary, and then forms candidate neighborhoods consisting of the words associated with nearby points and their orientation with respect to the central interest point. Rather than dictate a particular scaling of the spatial and temporal dimensions to determine which points are near, we show how to learn the class-specific distance functions that form the most informative configurations. Descriptors for these variable-sized neighborhoods are then recursively mapped to higher-level vocabularies, producing a hierarchy of space-time configurations at successively broader scales. Our approach yields state-of-theart performance on the UCF Sports and KTH datasets.", "citation": "Citations (542)", "year": "2010", "departments": ["University of Texas at Austin", "University of Texas at Austin"], "conf": "cvpr", "authors": ["Adriana Kovashka.....http://dblp.org/pers/hd/k/Kovashka:Adriana", "Kristen Grauman.....http://dblp.org/pers/hd/g/Grauman:Kristen"], "pages": 8}