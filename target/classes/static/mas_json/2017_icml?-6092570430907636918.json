{"title": "Learned Optimizers that Scale and Generalize.", "fields": ["gradient descent", "convolutional neural network", "resnet", "computation", "architecture"], "abstract": "Learning to learn has emerged as an important direction for achieving artificial intelligence. Two of the primary barriers to its adoption are an inability to scale to larger problems and a limited ability to generalize to new tasks. We introduce a learned gradient descent optimizer that generalizes well to new tasks, and which has significantly reduced memory and computation overhead. We achieve this by introducing a novel hierarchical RNN architecture, with minimal per-parameter overhead, augmented with additional architectural features that mirror the known structure of optimization tasks. We also develop a meta-training ensemble of small, diverse optimization tasks capturing common properties of loss landscapes. The optimizer learns to outperform RMSProp/ADAM on problems in this corpus. More importantly, it performs comparably or better when applied to small convolutional neural networks, despite seeing no neural networks in its meta-training set. Finally, it generalizes to train Inception V3 and ResNet V2 architectures on the ImageNet dataset for thousands of steps, optimization problems that are of a vastly different scale than those it was trained on. We release an open source implementation of the meta-training algorithm.", "citation": "Citations (9)", "year": "2017", "departments": ["Stanford University", "Google", "Dalhousie University"], "conf": "icml", "authors": ["Olga Wichrowska.....http://dblp.org/pers/hd/w/Wichrowska:Olga", "Niru Maheswaranathan.....http://dblp.org/pers/hd/m/Maheswaranathan:Niru", "Matthew W. Hoffman.....http://dblp.org/pers/hd/h/Hoffman:Matthew_W=", "Sergio Gomez Colmenarejo.....http://dblp.org/pers/hd/c/Colmenarejo:Sergio_Gomez", "Misha Denil.....http://dblp.org/pers/hd/d/Denil:Misha", "Nando de Freitas.....http://dblp.org/pers/hd/f/Freitas:Nando_de", "Jascha Sohl-Dickstein.....http://dblp.org/pers/hd/s/Sohl=Dickstein:Jascha"], "pages": 10}