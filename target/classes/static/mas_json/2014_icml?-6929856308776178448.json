{"title": "Sample-based approximate regularization.", "fields": ["machine learning", "fidelity", "sampling", "parameterized complexity", "regularization"], "abstract": "We introduce a method for regularizing linearly parameterized functions using general derivative-based penalties, which relies on sampling as well as finite-difference approximations of the relevant derivatives. We call this approach sample-based approximate regularization (SAR). We provide theoretical guarantees on the fidelity of such regularizers, compared to those they approximate, and prove that the approximations converge efficiently. We also examine the empirical performance of SAR on several datasets.", "citation": "Citations (1)", "year": "2014", "departments": ["McGill University", "McGill University", "Carnegie Mellon University", "McGill University"], "conf": "icml", "authors": ["Philip Bachman.....http://dblp.org/pers/hd/b/Bachman:Philip", "Amir-massoud Farahmand.....http://dblp.org/pers/hd/f/Farahmand:Amir=massoud", "Doina Precup.....http://dblp.org/pers/hd/p/Precup:Doina"], "pages": 9}