{"title": "Cambricon: An Instruction Set Architecture for Neural Networks.", "fields": ["general purpose computing on graphics processing units", "neuromorphic engineering", "architecture", "latency", "instruction set"], "abstract": "Neural Networks (NN) are a family of models for a broad range of emerging machine learning and pattern recondition applications. NN techniques are conventionally executed on general-purpose processors (such as CPU and GPGPU), which are usually not energy-efficient since they invest excessive hardware resources to flexibly support various workloads. Consequently, application-specific hardware accelerators for neural networks have been proposed recently to improve the energy-efficiency. However, such accelerators were designed for a small set of NN techniques sharing similar computational patterns, and they adopt complex and informative instructions (control signals) directly corresponding to high-level functional blocks of an NN (such as layers), or even an NN as a whole. Although straightforward and easy-to-implement for a limited set of similar NN techniques, the lack of agility in the instruction set prevents such accelerator designs from supporting a variety of different NN techniques with sufficient flexibility and efficiency.   In this paper, we propose a novel domain-specific Instruction Set Architecture (ISA) for NN accelerators, called Cambricon, which is a load-store architecture that integrates scalar, vector, matrix, logical, data transfer, and control instructions, based on a comprehensive analysis of existing NN techniques. Our evaluation over a total of ten representative yet distinct NN techniques have demonstrated that Cambricon exhibits strong descriptive capacity over a broad range of NN techniques, and provides higher code density than general-purpose ISAs such as \u00d786, MIPS, and GPGPU. Compared to the latest state-of-the-art NN accelerator design DaDianNao [5] (which can only accommodate 3 types of NN techniques), our Cambricon-based accelerator prototype implemented in TSMC 65nm technology incurs only negligible latency/power/area overheads, with a versatile coverage of 10 different NN benchmarks.", "citation": "Citations (32)", "year": "2016", "departments": ["ICT, CAS, Beiji ...  Cambricon Ltd.", "ICT, CAS, Beiji ...  Cambricon Ltd.", "ICT, CAS, Beiji ...  Cambricon Ltd.", "ICT, CAS, Beiji ...  Cambricon Ltd.", "ICT, CAS, Beiji ...  Cambricon Ltd."], "conf": "isca", "authors": ["Shaoli Liu.....http://dblp.org/pers/hd/l/Liu:Shaoli", "Zidong Du.....http://dblp.org/pers/hd/d/Du:Zidong", "Jinhua Tao.....http://dblp.org/pers/hd/t/Tao:Jinhua", "Dong Han.....http://dblp.org/pers/hd/h/Han:Dong", "Tao Luo.....http://dblp.org/pers/hd/l/Luo:Tao", "Yuan Xie.....http://dblp.org/pers/hd/x/Xie:Yuan", "Yunji Chen.....http://dblp.org/pers/hd/c/Chen:Yunji", "Tianshi Chen.....http://dblp.org/pers/hd/c/Chen:Tianshi"], "pages": 13}