{"title": "Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences.", "fields": ["parsing", "observable", "autonomous agent", "recurrent neural network", "sentence"], "abstract": "We propose a neural sequence-to-sequence model for direction following, a task that is essential to realizing effective autonomous agents. Our alignment-based encoder-decoder model with long short-term memory recurrent neural networks (LSTM-RNN) translates natural language instructions to action sequences based upon a representation of the observable world state. We introduce a multi-level aligner that empowers our model to focus on sentence \"regions\" salient to the current world state by using multiple abstractions of the input sentence. In contrast to existing methods, our model uses no specialized linguistic resources (e.g., parsers) or task-specific annotations (e.g., seed lexicons). It is therefore generalizable, yet still achieves the best results reported to-date on a benchmark single-sentence dataset and competitive results for the limited-training multi-sentence setting. We analyze our model through a series of ablations that elucidate the contributions of the primary components of our model.", "citation": "Citations (58)", "departments": ["Toyota Technological Institute at Chicago", "Toyota Technological Institute at Chicago", "Toyota Technological Institute at Chicago"], "authors": ["Hongyuan Mei.....http://dblp.org/pers/hd/m/Mei:Hongyuan", "Mohit Bansal.....http://dblp.org/pers/hd/b/Bansal:Mohit", "Matthew R. Walter.....http://dblp.org/pers/hd/w/Walter:Matthew_R="], "conf": "aaai", "year": "2016", "pages": 7}