{"title": "O(logT) Projections for Stochastic Optimization of Smooth and Strongly Convex Functions.", "fields": ["conic optimization", "stochastic gradient descent", "smoothness", "convexity", "stochastic optimization"], "abstract": "Traditional algorithms for stochastic optimization require projecting the solution at each iteration into a given domain to ensure its feasibility. When facing complex domains, such as the positive semidefinite cone, the projection operation can be expensive, leading to a high computational cost per iteration. In this paper, we present a novel algorithm that aims to reduce the number of projections for stochastic optimization. The proposed algorithm combines the strength of several recent developments in stochastic optimization, including mini-batches, extra-gradient, and epoch gradient descent, in order to effectively explore the smoothness and strong convexity. We show, both in expectation and with a high probability, that when the objective function is both smooth and strongly convex, the proposed algorithm achieves the optimal O(1/T) rate of convergence with only O(log T) projections. Our empirical study verifies the theoretical result.", "citation": "Citations (11)", "departments": ["Michigan State University", "General Electric", "Michigan State University", "Zhejiang University"], "authors": ["Lijun Zhang.....http://dblp.org/pers/hd/z/Zhang_0005:Lijun", "Tianbao Yang.....http://dblp.org/pers/hd/y/Yang:Tianbao", "Rong Jin.....http://dblp.org/pers/hd/j/Jin:Rong", "Xiaofei He.....http://dblp.org/pers/hd/h/He:Xiaofei"], "conf": "icml", "year": "2013", "pages": 9}