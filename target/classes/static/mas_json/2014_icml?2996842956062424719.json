{"title": "Methods of Moments for Learning Stochastic Languages: Unified Presentation and Empirical Comparison.", "fields": ["statistical assumption", "probabilistic logic", "probabilistic automaton", "method of moments", "synthetic data"], "abstract": "Probabilistic latent-variable models are a powerful tool for modelling structured data. However, traditional expectation-maximization methods of learning such models are both computationally expensive and prone to local-minima. In contrast to these traditional methods, recently developed learning algorithms based upon the method of moments are both computationally efficient and provide strong statistical guarantees. In this work we provide a unified presentation and empirical comparison of three general moment-based methods in the context of modelling stochastic languages. By rephrasing these methods upon a common theoretical ground, introducing novel theoretical results where necessary, we provide a clear comparison, making explicit the statistical assumptions upon which each method relies. With this theoretical grounding, we then provide an in-depth empirical analysis of the methods on both real and synthetic data with the goal of elucidating performance trends and highlighting important implementation details.", "citation": "Citations (16)", "year": "2014", "departments": ["McGill University", "McGill University", "McGill University"], "conf": "icml", "authors": ["Borja Balle.....http://dblp.org/pers/hd/b/Balle:Borja", "William L. Hamilton.....http://dblp.org/pers/hd/h/Hamilton:William_L=", "Joelle Pineau.....http://dblp.org/pers/hd/p/Pineau:Joelle"], "pages": 9}