{"title": "Online Learning in Markov Decision Processes with Changing Cost Sequences.", "fields": ["md2", "uniform boundedness", "special case", "markov decision process", "exponential function"], "abstract": "In this paper we consider online learning in finite Markov decision processes (MDPs) with changing cost sequences under full and bandit-information. We propose to view this problem as an instance of online linear optimization. We propose two methods for this problem: MD2 (mirror descent with approximate projections) and the continuous exponential weights algorithm with Dikin walks. We provide a rigorous complexity analysis of these techniques, while providing near-optimal regret-bounds (in particular, we take into account the computational costs of performing approximate projections in MD2). In the case of full-information feedback, our results complement existing ones. In the case of bandit-information feedback we consider the online stochastic shortest path problem, a special case of the above MDP problems, and manage to improve the existing results by removing the previous restrictive assumption that the state-visitation probabilities are uniformly bounded away from zero under all policies.", "citation": "Citations (9)", "year": "2014", "departments": ["University of Alberta", "University of Alberta", "University of Alberta"], "conf": "icml", "authors": ["Travis Dick.....http://dblp.org/pers/hd/d/Dick:Travis", "Andr\u00e1s Gy\u00f6rgy.....http://dblp.org/pers/hd/g/Gy=ouml=rgy:Andr=aacute=s", "Csaba Szepesv\u00e1ri.....http://dblp.org/pers/hd/s/Szepesv=aacute=ri:Csaba"], "pages": 9}