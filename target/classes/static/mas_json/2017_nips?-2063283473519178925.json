{"title": "Nearest-Neighbor Sample Compression: Efficiency, Consistency, Infinite Dimensions.", "fields": ["hinge", "metric space", "mathematical proof", "compression", "k nearest neighbors algorithm"], "abstract": "We examine the Bayes-consistency of a recently proposed 1-nearest-neighbor-based multiclass learning algorithm. This algorithm is derived from sample compression bounds and enjoys the statistical advantages of tight, fully empirical generalization bounds, as well as the algorithmic advantages of a faster runtime and memory savings. We prove that this algorithm is strongly Bayes-consistent in metric spaces with finite doubling dimension --- the first consistency result for an efficient nearest-neighbor sample compression scheme. Rather surprisingly, we discover that this algorithm continues to be Bayes-consistent even in a certain infinite-dimensional setting, in which the basic measure-theoretic conditions on which classic consistency proofs hinge are violated. This is all the more surprising, since it is known that k-NN is not Bayes-consistent in this setting. We pose several challenging open problems for future research.", "citation": "Not cited", "year": "2017", "departments": ["Ben-Gurion University of the Negev", "Ben-Gurion University of the Negev", "Weizmann Institute of Science"], "conf": "nips", "authors": ["Aryeh Kontorovich.....http://dblp.org/pers/hd/k/Kontorovich:Aryeh", "Sivan Sabato.....http://dblp.org/pers/hd/s/Sabato:Sivan", "Roi Weiss.....http://dblp.org/pers/hd/w/Weiss:Roi"], "pages": 11}