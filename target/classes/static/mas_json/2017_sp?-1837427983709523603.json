{"title": "Is Interaction Necessary for Distributed Private Learning?", "fields": ["convex function", "approximation algorithm", "randomized response", "information privacy", "server"], "abstract": "Recent large-scale deployments of differentially private algorithms employ the local model for privacy (sometimes called PRAM or randomized response), where data are randomized on each individual's device before being sent to a server that computes approximate, aggregate statistics. The server need not be trusted for privacy, leaving data control in users' hands. For an important class of convex optimization problems (including logistic regression, support vector machines, and the Euclidean median), the best known locally differentially-private algorithms are highly interactive, requiring as many rounds of back and forth as there are users in the protocol. We ask: how much interaction is necessary to optimize convex functions in the local DP model? Existing lower bounds either do not apply to convex optimization, or say nothing about interaction. We provide new algorithms which are either noninteractive or use relatively few rounds of interaction. We also show lower bounds on the accuracy of an important class of noninteractive algorithms, suggesting a separation between what is possible with and without interaction.", "citation": "Citations (5)", "departments": ["Pennsylvania State University", "Apple Inc."], "authors": ["Adam D. Smith.....http://dblp.org/pers/hd/s/Smith:Adam_D=", "Abhradeep Thakurta.....http://dblp.org/pers/hd/t/Thakurta:Abhradeep", "Jalaj Upadhyay.....http://dblp.org/pers/hd/u/Upadhyay:Jalaj"], "conf": "sp", "year": "2017", "pages": 20}