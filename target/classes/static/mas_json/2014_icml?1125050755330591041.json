{"title": "Stochastic Neighbor Compression.", "fields": ["data set", "fold", "speedup", "large margin nearest neighbor", "curse of dimensionality"], "abstract": "We present Stochastic Neighbor Compression (SNC), an algorithm to compress a dataset for the purpose of k-nearest neighbor (kNN) classification. Given training data, SNC learns a much smaller synthetic data set, that minimizes the stochastic 1-nearest neighbor classification error on the training data. This approach has several appealing properties: due to its small size, the compressed set speeds up kNN testing drastically (up to several orders of magnitude, in our experiments); it makes the kNN classifier substantially more robust to label noise; on 4 of 7 data sets it yields lower test error than kNN on the entire training set, even at compression ratios as low as 2%; finally, the SNC compression leads to impressive speed ups over kNN even when kNN and SNC are both used with ball-tree data structures, hashing, and LMNN dimensionality reduction--demonstrating that it is complementary to existing state-of-the-art algorithms to speed up kNN classification and leads to substantial further improvements.", "citation": "Citations (18)", "year": "2014", "departments": ["Washington University in St. Louis", "Washington University in St. Louis", "Washington University in St. Louis", "Washington University in St. Louis"], "conf": "icml", "authors": ["Matt J. Kusner.....http://dblp.org/pers/hd/k/Kusner:Matt_J=", "Stephen Tyree.....http://dblp.org/pers/hd/t/Tyree:Stephen", "Kilian Q. Weinberger.....http://dblp.org/pers/hd/w/Weinberger:Kilian_Q=", "Kunal Agrawal.....http://dblp.org/pers/hd/a/Agrawal:Kunal"], "pages": 9}