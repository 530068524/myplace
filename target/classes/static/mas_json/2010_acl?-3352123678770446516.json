{"title": "Training Phrase Translation Models with Leaving-One-Out.", "fields": ["phrase search", "example based machine translation", "bleu", "synchronous context free grammar", "phrase"], "abstract": "Several attempts have been made to learn phrase translation probabilities for phrase-based statistical machine translation that go beyond pure counting of phrases in word-aligned training data. Most approaches report problems with over-fitting. We describe a novel leaving-one-out approach to prevent over-fitting that allows us to train phrase models that show improved translation performance on the WMT08 Europarl German-English task. In contrast to most previous work where phrase models were trained separately from other models used in translation, we include all components such as single word lexica and reordering models in training. Using this consistent training of phrase models we are able to achieve improvements of up to 1.4 points in BLEU. As a side effect, the phrase table size is reduced by more than 80%.", "citation": "Citations (90)", "year": "2010", "departments": ["RWTH Aachen University", "RWTH Aachen University", "RWTH Aachen University"], "conf": "acl", "authors": ["Joern Wuebker.....http://dblp.org/pers/hd/w/Wuebker:Joern", "Arne Mauser.....http://dblp.org/pers/hd/m/Mauser:Arne", "Hermann Ney.....http://dblp.org/pers/hd/n/Ney:Hermann"], "pages": 10}