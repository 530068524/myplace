{"title": "Truly Nonparametric Online Variational Inference for Hierarchical Dirichlet Processes.", "fields": ["hierarchical dirichlet process", "variational message passing", "topic model", "dirichlet distribution", "local optimum"], "abstract": "Variational methods provide a computationally scalable alternative to Monte Carlo methods for large-scale, Bayesian nonparametric learning. In practice, however, conventional batch and online variational methods quickly become trapped in local optima. In this paper, we consider a nonparametric topic model based on the hierarchical Dirichlet process (HDP), and develop a novel online variational inference algorithm based on split-merge topic updates. We derive a simpler and faster variational approximation of the HDP, and show that by intelligently splitting and merging components of the variational posterior, we can achieve substantially better predictions of test data than conventional online and batch variational algorithms. For streaming analysis of large datasets where batch analysis is in-feasible, we show that our split-merge updates better capture the nonparametric properties of the underlying model, allowing continual learning of new topics.", "citation": "Citations (72)", "departments": ["Brown University", "Brown University"], "authors": ["Michael Bryant.....http://dblp.org/pers/hd/b/Bryant_0002:Michael", "Erik B. Sudderth.....http://dblp.org/pers/hd/s/Sudderth:Erik_B="], "conf": "nips", "year": "2012", "pages": 9}