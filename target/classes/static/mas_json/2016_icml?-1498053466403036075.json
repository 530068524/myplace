{"title": "Importance Sampling Tree for Large-scale Empirical Expectation.", "fields": ["importance sampling", "perceptron", "adaboost", "convolution", "order of magnitude"], "abstract": "We propose a tree-based procedure inspired by the Monte-Carlo Tree Search that dynamically modulates an importance-based sampling to prioritize computation, while getting unbiased estimates of weighted sums. We apply this generic method to learning on very large training sets, and to the evaluation of large-scale SVMs.\n\nThe core idea is to reformulate the estimation of a score - whether a loss or a prediction estimate - as an empirical expectation, and to use such a tree whose leaves carry the samples to focus efforts over the problematic \"heavy weight\" ones.\n\nWe illustrate the potential of this approach on three problems: to improve Adaboost and a multi-layer perceptron on 2D synthetic tasks with several million points, to train a large-scale convolution network on several millions deformations of the CIFAR data-set, and to compute the response of a SVM with several hundreds of thousands of support vectors. In each case, we show how it either cuts down computation by more than one order of magnitude and/or allows to get better loss estimates.", "citation": "Citations (5)", "year": "2016", "departments": ["\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne", "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne", "Idiap Research Institute"], "conf": "icml", "authors": ["Olivier Can\u00e9vet.....http://dblp.org/pers/hd/c/Can=eacute=vet:Olivier", "Cijo Jose.....http://dblp.org/pers/hd/j/Jose:Cijo", "Fran\u00e7ois Fleuret.....http://dblp.org/pers/hd/f/Fleuret:Fran=ccedil=ois"], "pages": 9}