{"title": "Can computers learn from humans to see better?: inferring scene semantics from viewers' eye movements.", "fields": ["scene statistics", "eye tracking", "facial expression", "semantic gap", "salience"], "abstract": "This paper describes an attempt to bridge the  semantic gap  between computer vision and scene understanding employing eye movements. Even as computer vision algorithms can efficiently detect scene objects, discovering semantic relationships between these objects is as essential for scene understanding. Humans understand complex scenes by rapidly moving their eyes (saccades) to selectively focus on  salient  entities (fixations). For 110 social scenes, we compared verbal descriptions provided by observers against eye movements recorded during a free-viewing task. Data analysis confirms (i) a strong correlation between task-explicit linguistic descriptions and task-implicit eye movements, both of which are influenced by underlying scene semantics and (ii) the ability of eye movements in the form of  fixations  and  saccades  to indicate salient  entities  and  entity relationships  mentioned in scene descriptions.   We demonstrate how eye movements are useful for inferring the meaning of  social  (everyday scenes depicting human activities) and  affective  (emotion-evoking content like  expressive faces, nudes ) scenes. While saliency has always been studied through the prism of fixations, we show that saccades are particularly useful for (i) distinguishing mild and high-intensity facial expressions and (ii) discovering interactive actions between scene entities.", "citation": "Citations (27)", "departments": ["University of Trento", "University of Trento", "University of Trento"], "authors": ["Subramanian Ramanathan.....http://dblp.org/pers/hd/r/Ramanathan:Subramanian", "Victoria Yanulevskaya.....http://dblp.org/pers/hd/y/Yanulevskaya:Victoria", "Nicu Sebe.....http://dblp.org/pers/hd/s/Sebe:Nicu"], "conf": "mm", "year": "2011", "pages": 10}