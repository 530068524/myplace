{"title": "Transfer of samples in batch reinforcement learning.", "fields": ["tuple", "error driven learning", "reinforcement learning", "learning classifier system", "multi task learning"], "abstract": "The main objective of transfer in reinforcement learning is to reduce the complexity of learning the solution of a target task by effectively reusing the knowledge retained from solving a set of source tasks. In this paper, we introduce a novel algorithm that transfers samples (i.e., tuples \u2329 s, a, s', r \u232a) from source to target tasks. Under the assumption that tasks have similar transition models and reward functions, we propose a method to select samples from the source tasks that are mostly similar to the target task, and, then, to use them as input for batch reinforcement-learning algorithms. As a result, the number of samples an agent needs to collect from the target task to learn its solution is reduced. We empirically show that, following the proposed approach, the transfer of samples is effective in reducing the learning complexity, even when some source tasks are significantly different from the target task.", "citation": "Citations (93)", "year": "2008", "departments": ["Polytechnic University of Milan", "Polytechnic University of Milan", "Polytechnic University of Milan"], "conf": "icml", "authors": ["Alessandro Lazaric.....http://dblp.org/pers/hd/l/Lazaric:Alessandro", "Marcello Restelli.....http://dblp.org/pers/hd/r/Restelli:Marcello", "Andrea Bonarini.....http://dblp.org/pers/hd/b/Bonarini:Andrea"], "pages": 8}