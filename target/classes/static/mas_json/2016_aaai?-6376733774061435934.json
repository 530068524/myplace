{"title": "Expected Tensor Decomposition with Stochastic Gradient Descent.", "fields": ["symmetric tensor", "infinity", "special case", "stochastic gradient descent", "tensor"], "abstract": "In this study, we investigate expected CP decomposition\u2014 a special case of CP decomposition in which a tensor to be decomposed is given as the sum or average of tensor samples \u03a7(t) for t = 1, . . . , T. To determine this decomposition, we develope stochastic-gradient-descent-type algorithms with four appealing features: efficient memory use, ability to work in an online setting, robustness of parameter tuning, and simplicity. Our theoretical analysis show that the solutions do not diverge to infinity for any initial value or step size. Experimental results confirm that our algorithms significantly outperform all existing methods in terms of accuracy. We also show that they can successfully decompose a large tensor, containing billion-scale nonzero elements.", "citation": "Citations (3)", "departments": ["Shizuoka University", "National Institute of Informatics", "National Institute of Informatics"], "authors": ["Takanori Maehara.....http://dblp.org/pers/hd/m/Maehara:Takanori", "Kohei Hayashi.....http://dblp.org/pers/hd/h/Hayashi:Kohei", "Ken-ichi Kawarabayashi.....http://dblp.org/pers/hd/k/Kawarabayashi:Ken=ichi"], "conf": "aaai", "year": "2016", "pages": 7}