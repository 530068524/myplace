{"title": "Spatio-temporal relationship match: Video structure comparison for recognition of complex human activities.", "fields": ["activity recognition", "feature extraction", "pattern recognition", "computer vision", "structural similarity"], "abstract": "Human activity recognition is a challenging task, especially when its background is unknown or changing, and when scale or illumination differs in each video. Approaches utilizing spatio-temporal local features have proved that they are able to cope with such difficulties, but they mainly focused on classifying short videos of simple periodic actions. In this paper, we present a new activity recognition methodology that overcomes the limitations of the previous approaches using local features. We introduce a novel matching, spatio-temporal relationship match, which is designed to measure structural similarity between sets of features extracted from two videos. Our match hierarchically considers spatio-temporal relationships among feature points, thereby enabling detection and localization of complex non-periodic activities. In contrast to previous approaches to \u2018classify\u2019 videos, our approach is designed to \u2018detect and localize\u2019 all occurring activities from continuous videos where multiple actors and pedestrians are present. We implement and test our methodology on a newly-introduced dataset containing videos of multiple interacting persons and individual pedestrians. The results confirm that our system is able to recognize complex non-periodic activities (e.g. \u2018push\u2019 and \u2018hug\u2019) from sets of spatio-temporal features even when multiple activities are present in the scene", "citation": "Citations (523)", "year": "2009", "departments": ["Electronics and Telecommunications Research Institute", "University of Texas at Austin"], "conf": "iccv", "authors": ["Michael S. Ryoo.....http://dblp.org/pers/hd/r/Ryoo:Michael_S=", "Jake K. Aggarwal.....http://dblp.org/pers/hd/a/Aggarwal:Jake_K="], "pages": 8}