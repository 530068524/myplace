{"title": "File recipe compression in data deduplication systems.", "fields": ["torrent file", "fold", "exploit", "recipe", "file system fragmentation"], "abstract": "Data deduplication systems discover and exploit redundancies between different data blocks. The most common approach divides data into chunks and identifies redundancies via fingerprints. The file content can be rebuilt by combining the chunk fingerprints which are stored sequentially in a file recipe. The corresponding file recipe data can occupy a significant fraction of the total disk space, especially if the deduplication ratio is very high. We propose a combination of efficient and scalable compression schemes to shrink the file recipes' size. A trace-based simulation shows that these methods can compress file recipes by up to 93%.", "citation": "Citations (28)", "departments": ["University of Mainz", "University of Mainz", "University of Mainz"], "authors": ["Dirk Meister.....http://dblp.org/pers/hd/m/Meister:Dirk", "Andr\u00e9 Brinkmann.....http://dblp.org/pers/hd/b/Brinkmann:Andr=eacute=", "Tim S\u00fc\u00df.....http://dblp.org/pers/hd/s/S=uuml==szlig=:Tim"], "conf": "fast", "year": "2013", "pages": 8}