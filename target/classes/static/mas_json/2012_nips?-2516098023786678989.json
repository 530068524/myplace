{"title": "Algorithms for Learning Markov Field Policies.", "fields": ["grasp", "domain knowledge", "markov random field", "markov decision process", "markov model"], "abstract": "We use a graphical model for representing policies in Markov Decision Processes. This new representation can easily incorporate domain knowledge in the form of a state similarity graph that loosely indicates which states are supposed to have similar optimal actions. A bias is then introduced into the policy search process by sampling policies from a distribution that assigns high probabilities to policies that agree with the provided state similarity graph, i.e. smoother policies. This distribution corresponds to a Markov Random Field. We also present forward and inverse reinforcement learning algorithms for learning such policy distributions. We illustrate the advantage of the proposed approach on two problems: cart-balancing with swing-up, and teaching a robot to grasp unknown objects.", "citation": "Not cited", "departments": ["Max Planck Society", "Max Planck Society", "Max Planck Society"], "authors": ["Abdeslam Boularias.....http://dblp.org/pers/hd/b/Boularias:Abdeslam", "Oliver Kroemer.....http://dblp.org/pers/hd/k/Kroemer:Oliver", "Jan Peters.....http://dblp.org/pers/hd/p/Peters_0001:Jan"], "conf": "nips", "year": "2012", "pages": 9}