{"title": "Finding syntax in human encephalography with beam search.", "fields": ["beam search", "language model", "generative grammar", "recurrent neural network", "rule based machine translation"], "abstract": "Recurrent neural network grammars (RNNGs) are generative models of (tree,string) pairs that rely on neural networks to evaluate derivational choices. Parsing with them using beam search yields a variety of incremental complexity metrics such as word surprisal and parser action count. When used as regressors against human electrophysiological responses to naturalistic text, they derive two amplitude effects: an early peak and a P600-like later peak. By contrast, a non-syntactic neural language model yields no reliable effects. Model comparisons attribute the early peak to syntactic composition within the RNNG. This pattern of results recommends the RNNG+beam search combination as a mechanistic model of the syntactic processing that occurs during normal human language comprehension.", "citation": "Not cited", "year": "2018", "departments": ["Cornell University", "Carnegie Mellon University", "Google", "University of Michigan"], "conf": "acl", "authors": ["Chris Dyer.....http://dblp.org/pers/hd/d/Dyer:Chris", "Adhiguna Kuncoro.....http://dblp.org/pers/hd/k/Kuncoro:Adhiguna", "John Hale.....http://dblp.org/pers/hd/h/Hale:John", "Jonathan Brennan.....http://dblp.org/pers/hd/b/Brennan:Jonathan"], "pages": 10}