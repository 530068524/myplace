{"title": "Monte Carlo Value Iteration with Macro-Actions.", "fields": ["probabilistic logic", "macro", "abstraction", "partially observable markov decision process", "markov decision process"], "abstract": "POMDP planning faces two major computational challenges: large state spaces and long planning horizons. The recently introduced Monte Carlo Value Iteration (MCVI) can tackle POMDPs with very large discrete state spaces or continuous state spaces, but its performance degrades when faced with long planning horizons. This paper presents Macro-MCVI, which extends MCVI by exploiting macro-actions for temporal abstraction. We provide sufficient conditions for Macro-MCVI to inherit the good theoretical properties of MCVI. Macro-MCVI does not require explicit construction of probabilistic models for macro-actions and is thus easy to apply in practice. Experiments show that Macro-MCVI substantially improves the performance of MCVI with suitable macro-actions.", "citation": "Citations (25)", "departments": ["National University of Singapore", "National University of Singapore", "National University of Singapore"], "authors": ["Zhan Wei Lim.....http://dblp.org/pers/hd/l/Lim:Zhan_Wei", "David Hsu.....http://dblp.org/pers/hd/h/Hsu:David", "Wee Sun Lee.....http://dblp.org/pers/hd/l/Lee:Wee_Sun"], "conf": "nips", "year": "2011", "pages": 9}