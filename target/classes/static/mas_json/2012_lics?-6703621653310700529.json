{"title": "Approximate Verification of the Symbolic Dynamics of Markov Chains.", "fields": ["discretization", "string", "markov kernel", "tuple", "finite set", "temporal logic", "additive markov chain", "examples of markov chains", "discrete phase type distribution", "markov chain mixing time"], "abstract": "A finite-state Markov chain  M  can be regarded as a linear transform operating on the set of probability distributions over its node set. The iterative applications of  M  to an initial probability distribution \u03bc 0  will generate a trajectory of probability distributions. Thus, a set of initial distributions will induce a set of trajectories. It is an interesting and useful task to analyze the dynamics of  M  as defined by this set of trajectories. The novel idea here is to carry out this task in a  symbolic  framework. Specifically, we discretize the probability value space [0,1] into a finite set of intervals  I  = { I  1 ,  I 2  ,...,  I m  }. A concrete probability distribution \u03bc over the node set {1, 2,...,  n } of  M  is then symbolically represented as  D , a tuple of intervals drawn from  I  where the  i th component of  D  will be the interval in which \u03bc( i ) falls. The set of discretized distributions  D  is a finite alphabet. Hence, the trajectory, generated by repeated applications of  M  to an initial distribution, will induce an infinite string over this alphabet. Given a set of initial distributions, the symbolic dynamics of  M  will then consist of a language of infinite strings  L  over the alphabet  D .   Our main goal is to verify whether  L  meets a specification given as a linear-time temporal logic formula p. In our logic, an atomic proposition will assert that the current probability of a node falls in the interval  I  from  I . If  L  is an \u03c9-regular language, one can hope to solve our model-checking problem (whether  L  m pq) using standard techniques. However, we show that, in general, this is not the case. Consequently, we develop the notion of an e-approximation, based on the transient and long-term behaviors of the Markov chain  M . Briefly, the symbolic trajectory \u03be' is an e-approximation of the symbolic trajectory \u03be iff (1) \u03be' agrees with \u03be during its transient phase; and (2) both \u03be and \u03be' are within an e-neighborhood at all times after the transient phase. Our main results are that one can effectively check whether (i) for each infinite word in  L , at least one of its e-approximations satisfies the given specification; (ii) for each infinite word in  L , all its e-approximations satisfy the specification. These verification results are strong in that they apply to all finite state Markov chains.", "citation": "Citations (6)", "departments": ["Indian Institute of Technology Kanpur", "Indian Institute of Technology Bombay", "Centre national de la recherche scientifique", "National University of Singapore", "Indian Institute of Technology Kanpur", "\u00c9cole normale sup\u00e9rieure de Cachan", "Agency for Science, Technology and Research", "National University of Singapore"], "authors": ["Manindra Agrawal.....http://dblp.org/pers/hd/a/Agrawal:Manindra", "S. Akshay.....http://dblp.org/pers/hd/a/Akshay:S=", "Blaise Genest.....http://dblp.org/pers/hd/g/Genest:Blaise", "P. S. Thiagarajan.....http://dblp.org/pers/hd/t/Thiagarajan:P=_S="], "conf": "lics", "year": "2012", "pages": 10}