{"title": "PILCO: A Model-Based and Data-Efficient Approach to Policy Search.", "fields": ["scratch", "approximate inference", "probabilistic logic", "reinforcement learning", "machine learning"], "abstract": "In this paper, we introduce PILCO, a practical, data-efficient model-based policy search method. PILCO reduces model bias, one of the key problems of model-based reinforcement learning, in a principled way. By learning a probabilistic dynamics model and explicitly incorporating model uncertainty into long-term planning, PILCO can cope with very little data and facilitates learning from scratch in only a few trials. Policy evaluation is performed in closed form using state-of-the-art approximate inference. Furthermore, policy gradients are computed analytically for policy improvement. We report unprecedented learning efficiency on challenging and high-dimensional control tasks.", "citation": "Citations (421)", "year": "2011", "departments": ["University of Washington", "University of Cambridge"], "conf": "icml", "authors": ["Marc Peter Deisenroth.....http://dblp.org/pers/hd/d/Deisenroth:Marc_Peter", "Carl Edward Rasmussen.....http://dblp.org/pers/hd/r/Rasmussen:Carl_Edward"], "pages": 8}