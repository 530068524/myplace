{"title": "Asymptotically Optimal Regularization in Smooth Parametric Models.", "fields": ["asymptotically optimal algorithm", "parametric model", "regularization", "asymptotic analysis", "problem domain"], "abstract": "Many types of regularization schemes have been employed in statistical learning, each motivated by some assumption about the problem domain. In this paper, we present a unified asymptotic analysis of smooth regularizers, which allows us to see how the validity of these assumptions impacts the success of a particular regularizer. In addition, our analysis motivates an algorithm for optimizing regularization parameters, which in turn can be analyzed within our framework. We apply our analysis to several examples, including hybrid generative-discriminative learning and multi-task learning.", "citation": "Citations (11)", "year": "2009", "departments": ["University of California, Berkeley", "Xerox", "\u00c9cole Normale Sup\u00e9rieure", "University of California, Berkeley"], "conf": "nips", "authors": ["Percy Liang.....http://dblp.org/pers/hd/l/Liang:Percy", "Francis R. Bach.....http://dblp.org/pers/hd/b/Bach:Francis_R=", "Guillaume Bouchard.....http://dblp.org/pers/hd/b/Bouchard:Guillaume", "Michael I. Jordan.....http://dblp.org/pers/hd/j/Jordan:Michael_I="], "pages": 9}