{"title": "Interactive Topic Modeling.", "fields": ["expectation maximization algorithm", "pachinko allocation", "latent dirichlet allocation", "correctness", "topic model", "gibbs sampling", "inference", "dynamic topic model"], "abstract": "Topic models have been used extensively as a tool for corpus exploration, and a cottage industry has developed to tweak topic models to better encode human intuitions or to better model data. However, creating such extensions requires expertise in machine learning unavailable to potential end-users of topic modeling software. In this work, we develop a framework for allowing users to iteratively refine the topics discovered by models such as latent Dirichlet allocation (LDA) by adding constraints that enforce that sets of words must appear together in the same topic. We incorporate these constraints interactively by selectively removing elements in the state of a Markov Chain used for inference; we investigate a variety of methods for incorporating this information and demonstrate that these interactively added constraints improve topic usefulness for simulated and actual user sessions.", "citation": "Citations (214)", "year": "2011", "departments": ["University of Maryland, College Park", "University of Maryland, College Park", "University of Maryland, College Park"], "conf": "acl", "authors": ["Yuening Hu.....http://dblp.org/pers/hd/h/Hu:Yuening", "Jordan L. Boyd-Graber.....http://dblp.org/pers/hd/b/Boyd=Graber:Jordan_L=", "Brianna Satinoff.....http://dblp.org/pers/hd/s/Satinoff:Brianna"], "pages": 10}