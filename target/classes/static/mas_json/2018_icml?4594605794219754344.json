{"title": "Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV).", "fields": ["attribution", "deep learning", "interpretability", "obstacle", "contextual image classification"], "abstract": "The interpretation of deep learning models is a challenge due to their size, complexity, and often opaque internal state. In addition, many systems, such as image classifiers, operate on low-level features rather than high-level concepts. To address these challenges, we introduce Concept Activation Vectors (CAVs), which provide an interpretation of a neural net's internal state in terms of human-friendly concepts. The key idea is to view the high-dimensional internal state of a neural net as an aid, not an obstacle. We show how to use CAVs as part of a technique, Testing with CAVs (TCAV), that uses directional derivatives to quantify the degree to which a user-defined concept is important to a classification result--for example, how sensitive a prediction of \"zebra\" is to the presence of stripes. Using the domain of image classification as a testing ground, we describe how CAVs may be used to explore hypotheses and generate insights for a standard image classification network as well as a medical application.", "citation": "Citations (3)", "departments": ["Google", "Google", "Google", "Google"], "authors": ["Been Kim.....http://dblp.org/pers/hd/k/Kim:Been", "Martin Wattenberg.....http://dblp.org/pers/hd/w/Wattenberg:Martin", "Justin Gilmer.....http://dblp.org/pers/hd/g/Gilmer:Justin", "Carrie Cai.....http://dblp.org/pers/hd/c/Cai:Carrie", "James Wexler.....http://dblp.org/pers/hd/w/Wexler:James", "Fernanda B. Vi\u00e9gas.....http://dblp.org/pers/hd/v/Vi=eacute=gas:Fernanda_B=", "Rory Sayres.....http://dblp.org/pers/hd/s/Sayres:Rory"], "conf": "icml", "year": "2018", "pages": 10}