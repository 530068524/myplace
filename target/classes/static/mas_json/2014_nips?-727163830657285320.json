{"title": "Constant Nullspace Strong Convexity and Fast Convergence of Proximal Methods under High-Dimensional Settings.", "fields": ["proximal gradient methods", "estimator", "convexity", "hessian matrix", "newton s method"], "abstract": "State of the art statistical estimators for high-dimensional problems take the form of regularized, and hence non-smooth, convex programs. A key facet of these statistical estimation problems is that these are typically not strongly convex under a high-dimensional sampling regime when the Hessian matrix becomes rank-deficient. Under vanilla convexity however, proximal optimization methods attain only a sublinear rate. In this paper, we investigate a novel variant of strong convexity, which we call Constant Nullspace Strong Convexity (CNSC), where we require that the objective function be strongly convex only over a constant subspace. As we show, the CNSC condition is naturally satisfied by high-dimensional statistical estimators. We then analyze the behavior of proximal methods under this CNSC condition: we show global linear convergence of Proximal Gradient and local quadratic convergence of Proximal Newton Method, when the regularization function comprising the statistical estimator is decomposable. We corroborate our theory via numerical experiments, and show a qualitative difference in the convergence rates of the proximal algorithms when the loss function does satisfy the CNSC condition.", "citation": "Citations (14)", "year": "2014", "departments": ["University of Texas at Austin", "University of Texas at Austin", "University of Texas at Austin", "University of Texas at Austin"], "conf": "nips", "authors": ["Ian En-Hsu Yen.....http://dblp.org/pers/hd/y/Yen:Ian_En=Hsu", "Cho-Jui Hsieh.....http://dblp.org/pers/hd/h/Hsieh:Cho=Jui", "Pradeep Ravikumar.....http://dblp.org/pers/hd/r/Ravikumar:Pradeep", "Inderjit S. Dhillon.....http://dblp.org/pers/hd/d/Dhillon:Inderjit_S="], "pages": 9}