{"title": "Investigating the use of visual focus of attention for audio-visual speaker diarisation.", "fields": ["speech recognition", "computer vision", "speaker diarisation", "sensory cue", "artificial intelligence"], "abstract": "Audio-visual speaker diarisation is the task of estimating ``who spoke when'' using audio and visual cues.   In this paper we propose the combination of an audio diarisation system with psychology inspired visual features, reporting experiments on multiparty meetings, a challenging domain characterised by unconstrained interaction and participant movements.   More precisely the role of gaze in coordinating speaker turns was exploited by the use of Visual Focus of Attention features. Experiments were performed both with the reference and 3 automatic VFoA estimation systems, based on head pose and visual activity cues, of increasing complexity. VFoA features yielded consistent speaker diarisation improvements in combination with audio features using a multi-stream approach.", "citation": "Citations (4)", "departments": ["Idiap Research Institute", "Idiap Research Institute", "Idiap Research Institute", "Idiap Research Institute"], "authors": ["Giulia Garau.....http://dblp.org/pers/hd/g/Garau:Giulia", "Sileye O. Ba.....http://dblp.org/pers/hd/b/Ba:Sileye_O=", "Herv\u00e9 Bourlard.....http://dblp.org/pers/hd/b/Bourlard:Herv=eacute=", "Jean-Marc Odobez.....http://dblp.org/pers/hd/o/Odobez:Jean=Marc"], "conf": "mm", "year": "2009", "pages": 4}