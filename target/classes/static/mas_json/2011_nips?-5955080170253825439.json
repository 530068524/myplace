{"title": "Learning a Tree of Metrics with Disjoint Visual Features.", "fields": ["equivalence of metrics", "wordnet", "semantic memory", "disjoint sets", "subcategory"], "abstract": "We introduce an approach to learn discriminative visual representations while exploiting external semantic knowledge about object category relationships. Given a hierarchical taxonomy that captures semantic similarity between the objects, we learn a corresponding tree of metrics (ToM). In this tree, we have one metric for each non-leaf node of the object hierarchy, and each metric is responsible for discriminating among its immediate subcategory children. Specifically, a Mahalanobis metric learned for a given node must satisfy the appropriate (dis)similarity constraints generated only among its subtree members' training instances. To further exploit the semantics, we introduce a novel regularizer coupling the metrics that prefers a sparse disjoint set of features to be selected for each metric relative to its ancestor (supercategory) nodes' metrics. Intuitively, this reflects that visual cues most useful to distinguish the generic classes (e.g., feline vs. canine) should be different than those cues most useful to distinguish their component fine-grained classes (e.g., Persian cat vs. Siamese cat). We validate our approach with multiple image datasets using the WordNet taxonomy, show its advantages over alternative metric learning approaches, and analyze the meaning of attribute features selected by our algorithm.", "citation": "Citations (73)", "departments": ["University of Texas at Austin", "University of Southern California", "University of Texas at Austin"], "authors": ["Sung Ju Hwang.....http://dblp.org/pers/hd/h/Hwang:Sung_Ju", "Kristen Grauman.....http://dblp.org/pers/hd/g/Grauman:Kristen", "Fei Sha.....http://dblp.org/pers/hd/s/Sha:Fei"], "conf": "nips", "year": "2011", "pages": 9}