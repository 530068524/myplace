{"title": "Posterior vs Parameter Sparsity in Latent Variable Models.", "fields": ["discriminative model", "small number", "parametric statistics", "dirichlet distribution", "latent variable"], "abstract": "We address the problem of learning structured unsupervised models with moment sparsity typical in many natural language induction tasks. For example, in unsupervised part-of-speech (POS) induction using hidden Markov models, we introduce a bias for words to be labeled by a small number of tags. In order to express this bias of posterior sparsity as opposed to parametric sparsity, we extend the posterior regularization framework [7]. We evaluate our methods on three languages \u2014 English, Bulgarian and Portuguese \u2014 showing consistent and significant accuracy improvement over EM-trained HMMs, and HMMs with sparsity-inducing Dirichlet priors trained by variational EM. We increase accuracy with respect to EM by 2.3%-6.5% in a purely unsupervised setting as well as in a weakly-supervised setting where the closed-class words are provided. Finally, we show improvements using our method when using the induced clusters as features of a discriminative model in a semi-supervised setting.", "citation": "Citations (64)", "year": "2009", "departments": ["University of Pennsylvania", "University of Pennsylvania", "Google", "Google"], "conf": "nips", "authors": ["Jo\u00e3o Gra\u00e7a.....http://dblp.org/pers/hd/g/Gra=ccedil=a:Jo=atilde=o", "Kuzman Ganchev.....http://dblp.org/pers/hd/g/Ganchev:Kuzman", "Ben Taskar.....http://dblp.org/pers/hd/t/Taskar:Ben", "Fernando C. N. Pereira.....http://dblp.org/pers/hd/p/Pereira:Fernando_C=_N="], "pages": 9}