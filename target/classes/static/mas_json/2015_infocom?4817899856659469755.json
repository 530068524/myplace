{"title": "On the efficiency-optimal Markov chains for distributed networking applications.", "fields": ["rejection sampling", "stationary distribution", "search algorithm", "markov chain monte carlo", "markov model"], "abstract": "The Metropolis-Hastings (MH) algorithm, in addition to its application for Markov Chain Monte Carlo sampling or simulation, has been popularly used for constructing a random walk that achieves a given, desired stationary distribution over a graph. Applications include crawling-based sampling of large graphs or online social networks, statistical estimation or inference from massive scale of networked data, efficient searching algorithms in unstructured peer-to-peer networks, randomized routing and movement strategies in wireless sensor networks, to list a few. Despite its versatility, the MH algorithm often causes self-transitions of its resulting random walk at some nodes, which is not efficient in the sense of the Peskun ordering \u2014 a partial order between off-diagonal elements of transition matrices of two different Markov chains, and in turn results in deficient performance in terms of asymptotic variance of time averages and expected hitting times with slower speed of convergence. To alleviate this problem, we present simple yet effective distributed algorithms that are guaranteed to improve the MH algorithm over time when running on a graph, and eventually reach \u2018efficiency-optimality\u2019, while ensuring the same desired stationary distribution throughout.", "citation": "Not cited", "departments": ["Samsung", "North Carolina State University"], "authors": ["Chul-Ho Lee.....http://dblp.org/pers/hd/l/Lee:Chul=Ho", "Do Young Eun.....http://dblp.org/pers/hd/e/Eun:Do_Young"], "conf": "infocom", "year": "2015", "pages": 9}