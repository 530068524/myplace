{"title": "Limitations on Variance-Reduction and Acceleration Schemes for Finite Sums Optimization.", "fields": ["variance reduction", "regular polygon", "acceleration", "convexity", "tilde"], "abstract": "We study the conditions under which one is able to efficiently apply variance-reduction and acceleration schemes on finite sums problems. First, we show that perhaps surprisingly, the finite sum structure, by itself, is not sufficient for obtaining a complexity bound of $\\tilde{\\cO}((n+L/\\mu)\\ln(1/\\epsilon))$ for $L$-smooth and $\\mu$-strongly convex finite sums - one must also know exactly which individual function is being referred to by the oracle at each iteration. Next, we show that for a broad class of first-order and coordinate-descent finite sums algorithms (including, e.g., SDCA, SVRG, SAG), it is not possible to get an `accelerated' complexity bound of $\\tilde{\\cO}((n+\\sqrt{n L/\\mu})\\ln(1/\\epsilon))$, unless the strong convexity parameter is given explicitly. Lastly, we show that when this class of algorithms is used for minimizing $L$-smooth and non-strongly convex finite sums, the optimal complexity bound is $\\tilde{\\cO}(n+L/\\epsilon)$, assuming that (on average) the same update rule is used for any iteration, and $\\tilde{\\cO}(n+\\sqrt{nL/\\epsilon})$, otherwise.", "citation": "Not cited", "year": "2017", "departments": ["Weizmann Institute of Science"], "conf": "nips", "authors": ["Yossi Arjevani.....http://dblp.org/pers/hd/a/Arjevani:Yossi"], "pages": 10}