{"title": "Multitask Coactive Learning.", "fields": ["convergence", "data mining", "perceptron", "baseline", "machine learning"], "abstract": "In this paper we investigate the use of coactive learning in a multitask setting. In coactive learning, an expert presents the learner with a problem and the learner returns a candidate solution. The expert then improves on the solution if necessary and presents the improved solution to the learner. The goal for the learner is to learn to produce solutions which cannot be further improved by the expert while minimizing the average expert effort. In this paper, we consider the setting where there are multiple experts (tasks), and in each iteration one expert presents a problem to the learner. While the experts are expected to have different solution preferences, they are also assumed to share similarities, which should enable generalization across experts. We analyze several algorithms for this setting and derive bounds on the average expert effort during learning. Our main contribution is the balanced Perceptron algorithm, which is the first coactive learning algorithm that is both able to generalize across experts when possible, while also guaranteeing convergence to optimal solutions for individual experts. Our experiments in three domains confirm that this algorithm is effective in the multitask setting, compared to natural baselines.", "citation": "Citations (2)", "departments": ["Oregon State University", "Oregon State University", "Oregon State University"], "authors": ["Robby Goetschalckx.....http://dblp.org/pers/hd/g/Goetschalckx:Robby", "Alan Fern.....http://dblp.org/pers/hd/f/Fern:Alan", "Prasad Tadepalli.....http://dblp.org/pers/hd/t/Tadepalli:Prasad"], "conf": "ijcai", "year": "2015", "pages": 7}