{"title": "Anytime Exploration for Multi-armed Bandits using Confidence Information.", "fields": ["exploration problem", "sample complexity", "computer science", "artificial intelligence", "machine learning"], "abstract": "We introduce anytime Explore-m, a pure exploration problem for multi-armed bandits (MAB) that requires making a prediction of the top-m arms at every time step. Anytime Explore-m is more practical than fixed budget or fixed confidence formulations of the top-m problem, since many applications involve a finite, but unpredictable, budget. However, the development and analysis of anytime algorithms present many challenges. We propose AT-LUCB (AnyTime Lower and Upper Confidence Bound), the first nontrivial algorithm that provably solves anytime Explore-m. Our analysis shows that the sample complexity of AT-LUCB is competitive to anytime variants of existing algorithms. Moreover, our empirical evaluation on AT-LUCB shows that AT-LUCB performs as well as or better than state-of-the-art baseline methods for anytime Explore-m.", "citation": "Not cited", "year": "2016", "departments": ["Wisconsin Institutes for Discovery", "Wisconsin Institutes for Discovery"], "conf": "icml", "authors": ["Kwang-Sung Jun.....http://dblp.org/pers/hd/j/Jun:Kwang=Sung", "Robert D. Nowak.....http://dblp.org/pers/hd/n/Nowak:Robert_D="], "pages": 9}