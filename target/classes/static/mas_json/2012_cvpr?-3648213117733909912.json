{"title": "Learning the right model: Efficient max-margin learning in Laplacian CRFs.", "fields": ["approximation algorithm", "crfs", "inference", "conditional random field", "laplace operator"], "abstract": "An important modeling decision made while designing Conditional Random Fields (CRFs) is the choice of the potential functions over the cliques of variables. Laplacian potentials are useful because they are robust potentials and match image statistics better than Gaussians. Moreover, energies with Laplacian terms remain convex, which simplifies inference. This makes Laplacian potentials an ideal modeling choice for some applications. In this paper, we study max-margin parameter learning in CRFs with Laplacian potentials (LCRFs). We first show that structured hinge-loss [35] is non-convex for LCRFs and thus techniques used by previous works are not applicable. We then present the first approximate max-margin algorithm for LCRFs. Finally, we make our learning algorithm scalable in the number of training images by using dual-decomposition techniques. Our experiments on single-image depth estimation show that even with simple features, our approach achieves comparable to state-of-art results.", "citation": "Citations (13)", "year": "2012", "departments": ["Cornell University", "TTI-Chicago"], "conf": "cvpr", "authors": ["Dhruv Batra.....http://dblp.org/pers/hd/b/Batra:Dhruv", "Ashutosh Saxena.....http://dblp.org/pers/hd/s/Saxena:Ashutosh"], "pages": 8}