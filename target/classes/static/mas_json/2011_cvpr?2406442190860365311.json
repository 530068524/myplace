{"title": "TaylorBoost: First and second-order boosting algorithms with explicit margin control.", "fields": ["boosting", "logitboost", "adaboost", "gradient boosting", "brownboost"], "abstract": "A new family of boosting algorithms, denoted Taylor-Boost, is proposed. It supports any combination of loss function and first or second order optimization, and includes classical algorithms such as AdaBoost, Gradient-Boost, or LogitBoost as special cases. Its restriction to the set of canonical losses makes it possible to have boosting algorithms with explicit margin control. A new large family of losses with this property, based on the set of cumulative distributions of zero mean random variables, is then proposed. A novel loss function in this family, the Laplace loss, is finally derived. The combination of this loss and second order TaylorBoost produces a boosting algorithm with explicit margin control.", "citation": "Citations (21)", "year": "2011", "departments": ["University of California, San Diego", "University of California, San Diego", "University of California, San Diego"], "conf": "cvpr", "authors": ["Mohammad J. Saberian.....http://dblp.org/pers/hd/s/Saberian:Mohammad_J=", "Hamed Masnadi-Shirazi.....http://dblp.org/pers/hd/m/Masnadi=Shirazi:Hamed", "Nuno Vasconcelos.....http://dblp.org/pers/hd/v/Vasconcelos:Nuno"], "pages": 6}