{"title": "Generative Topic Embedding: a Continuous Representation of Documents.", "fields": ["word embedding", "document clustering", "document classification", "continuous embedding", "topic model"], "abstract": "Word embedding maps words into a lowdimensional continuous embedding space by exploiting the local word collocation patterns in a small context window. On the other hand, topic modeling maps documents onto a low-dimensional topic space, by utilizing the global word collocation patterns in the same document. These two types of patterns are complementary. In this paper, we propose a generative topic embedding model to combine the two types of patterns. In our model, topics are represented by embedding vectors, and are shared across documents. The probability of each word is influenced by both its local context and its topic. A variational inference method yields the topic embeddings as well as the topic mixing proportions for each document. Jointly they represent the document in a low-dimensional continuous space. In two document classification tasks, our method performs better than eight existing methods, with fewer features. In addition, we illustrate with an example that our method can generate coherent topics even based on only one document.", "citation": "Citations (22)", "year": "2016", "departments": ["Nanyang Technological University", "National University of Singapore", "Tsinghua University", "Nanyang Technological University"], "conf": "acl", "authors": ["Shaohua Li.....http://dblp.org/pers/hd/l/Li:Shaohua", "Tat-Seng Chua.....http://dblp.org/pers/hd/c/Chua:Tat=Seng", "Jun Zhu.....http://dblp.org/pers/hd/z/Zhu_0001:Jun", "Chunyan Miao.....http://dblp.org/pers/hd/m/Miao:Chunyan"], "pages": -1}