{"title": "Deep Multitask Learning for Semantic Dependency Parsing.", "fields": ["rotation formalisms in three dimensions", "dependency graph", "perceptron", "dependency grammar", "multi task learning"], "abstract": "We present a deep neural architecture that parses sentences into three semantic dependency graph formalisms. By using efficient, nearly arc-factored inference and a bidirectional-LSTM composed with a multi-layer perceptron, our base system is able to significantly improve the state of the art for semantic dependency parsing, without using hand-engineered features or syntax. We then explore two multitask learning approaches---one that shares parameters across formalisms, and one that uses higher-order structures to predict the graphs jointly. We find that both approaches improve performance across formalisms on average, achieving a new state of the art. Our code is open-source and available at this https URL", "citation": "Citations (5)", "year": "2017", "departments": ["Peking University", "Carnegie Mellon University", "University of Pittsburgh"], "conf": "acl", "authors": ["Hao Peng.....http://dblp.org/pers/hd/p/Peng:Hao", "Sam Thomson.....http://dblp.org/pers/hd/t/Thomson:Sam", "Noah A. Smith.....http://dblp.org/pers/hd/s/Smith:Noah_A="], "pages": 12}