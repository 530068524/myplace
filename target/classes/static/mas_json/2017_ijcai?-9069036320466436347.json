{"title": "DeepStory: Video Story QA by Deep Embedded Memory Networks.", "fields": ["recall", "machine learning", "video tracking", "embedding", "speech recognition"], "abstract": "Question-answering (QA) on video contents is a significant challenge for achieving human-level intelligence as it involves both vision and language in real-world settings. Here we demonstrate the possibility of an AI agent performing video story QA by learning from a large amount of cartoon videos. We develop a video-story learning model, i.e. Deep Embedded Memory Networks (DEMN), to reconstruct stories from a joint scene-dialogue video stream using a latent embedding space of observed data. The video stories are stored in a long-term memory component. For a given question, an LSTM-based attention model uses the long-term memory to recall the best question-story-answer triplet by focusing on specific words containing key information. We trained the DEMN on a novel QA dataset of children's cartoon video series, Pororo. The dataset contains 16,066 scene-dialogue pairs of 20.5-hour videos, 27,328 fine-grained sentences for scene description, and 8,913 story-related QA pairs. Our experimental results show that the DEMN outperforms other QA models. This is mainly due to 1) the reconstruction of video stories in a scene-dialogue combined form that utilize the latent embedding and 2) attention. DEMN also achieved state-of-the-art results on the MovieQA benchmark.", "citation": "Citations (6)", "departments": ["Hewlett-Packard", "Seoul National University", "Seoul National University"], "authors": ["Kyung-Min Kim.....http://dblp.org/pers/hd/k/Kim:Kyung=Min", "Min-Oh Heo.....http://dblp.org/pers/hd/h/Heo:Min=Oh", "Seong-Ho Choi.....http://dblp.org/pers/hd/c/Choi:Seong=Ho", "Byoung-Tak Zhang.....http://dblp.org/pers/hd/z/Zhang:Byoung=Tak"], "conf": "ijcai", "year": "2017", "pages": 7}