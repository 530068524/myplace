{"title": "Situation Recognition: Visual Semantic Role Labeling for Image Understanding.", "fields": ["framenet", "activity recognition", "clipping", "semantic role labeling", "structured prediction"], "abstract": "This paper introduces situation recognition, the problem of producing a concise summary of the situation an image depicts including: (1) the main activity (e.g., clipping), (2) the participating actors, objects, substances, and locations (e.g., man, shears, sheep, wool, and field) and most importantly (3) the roles these participants play in the activity (e.g., the man is clipping, the shears are his tool, the wool is being clipped from the sheep, and the clipping is in a field). We use FrameNet, a verb and role lexicon developed by linguists, to define a large space of possible situations and collect a large-scale dataset containing over 500 activities, 1,700 roles, 11,000 objects, 125,000 images, and 200,000 unique situations. We also introduce structured prediction baselines and show that, in activity-centric images, situation-driven prediction of objects and activities outperforms independent object and activity recognition.", "citation": "Citations (31)", "year": "2016", "departments": ["University of Washington", "University of Washington", "University of Washington"], "conf": "cvpr", "authors": ["Mark Yatskar.....http://dblp.org/pers/hd/y/Yatskar:Mark", "Luke S. Zettlemoyer.....http://dblp.org/pers/hd/z/Zettlemoyer:Luke_S=", "Ali Farhadi.....http://dblp.org/pers/hd/f/Farhadi:Ali"], "pages": 9}