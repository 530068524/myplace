{"title": "Probabilistic Differential Dynamic Programming.", "fields": ["variational integrator", "linear quadratic gaussian control", "trajectory optimization", "gaussian", "polynomial chaos", "differential dynamic programming", "probabilistic logic", "linearization", "approximate inference", "bellman equation", "parametric statistics"], "abstract": "We present a data-driven, probabilistic trajectory optimization framework for systems with unknown dynamics, called Probabilistic Differential Dynamic Programming (PDDP). PDDP takes into account uncertainty explicitly for dynamics models using Gaussian processes (GPs). Based on the second-order local approximation of the value function, PDDP performs Dynamic Programming around a nominal trajectory in Gaussian belief spaces. Different from typical gradient-based policy search methods, PDDP does not require a policy parameterization and learns a locally optimal, time-varying control policy. We demonstrate the effectiveness and efficiency of the proposed algorithm using two nontrivial tasks. Compared with the classical DDP and a state-of-the-art GP-based policy search method, PDDP offers a superior combination of data-efficiency, learning speed, and applicability.", "citation": "Not cited", "year": "2014", "departments": ["Georgia Institute of Technology", "Georgia Institute of Technology", "Technical University of Berlin", "Honda"], "conf": "nips", "authors": ["Yunpeng Pan.....http://dblp.org/pers/hd/p/Pan:Yunpeng", "Evangelos A. Theodorou.....http://dblp.org/pers/hd/t/Theodorou:Evangelos_A="], "pages": 9}