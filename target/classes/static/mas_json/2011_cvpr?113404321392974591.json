{"title": "Learning invariance through imitation.", "fields": ["exploit", "pose", "pairwise comparison", "imitation", "embedding"], "abstract": "Supervised methods for learning an embedding aim to map high-dimensional images to a space in which perceptually similar observations have high measurable similarity. Most approaches rely on binary similarity, typically defined by class membership where labels are expensive to obtain and/or difficult to define. In this paper we propose crowd-sourcing similar images by soliciting human imitations. We exploit temporal coherence in video to generate additional pairwise graded similarities between the user-contributed imitations. We introduce two methods for learning nonlinear, invariant mappings that exploit graded similarities. We learn a model that is highly effective at matching people in similar pose. It exhibits remarkable invariance to identity, clothing, background, lighting, shift and scale.", "citation": "Citations (22)", "year": "2011", "departments": ["Courant Institute of Mathematical Sciences", "Courant Institute of Mathematical Sciences", "Courant Institute of Mathematical Sciences", "Courant Institute of Mathematical Sciences"], "conf": "cvpr", "authors": ["Graham W. Taylor.....http://dblp.org/pers/hd/t/Taylor:Graham_W=", "Ian Spiro.....http://dblp.org/pers/hd/s/Spiro:Ian", "Christoph Bregler.....http://dblp.org/pers/hd/b/Bregler:Christoph", "Rob Fergus.....http://dblp.org/pers/hd/f/Fergus:Rob"], "pages": 8}