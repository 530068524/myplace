{"title": "Learning feed-forward one-shot learners.", "fields": ["deep learning", "active learning", "discriminative model", "visual objects", "feed forward"], "abstract": "One-shot learning is usually tackled by using generative models or discriminative embeddings. Discriminative methods based on deep learning, which are very effective in other learning scenarios, are ill-suited for one-shot learning as they need large amounts of training data. In this paper, we propose a method to learn the parameters of a deep model in one shot. We construct the learner as a second deep network, called a learnet, which predicts the parameters of a pupil network from a single exemplar. In this manner we obtain an efficient feed-forward one-shot learner, trained end-to-end by minimizing a one-shot classification objective in a learning to learn formulation. In order to make the construction feasible, we propose a number of factorizations of the parameters of the pupil network. We demonstrate encouraging results by learning characters from single exemplars in Omniglot, and by tracking visual objects from a single initial exemplar in the Visual Object Tracking benchmark.", "citation": "Citations (75)", "departments": ["University of Oxford", "University of Oxford", "Queensland University of Technology", "University of Oxford", "University of Oxford"], "authors": ["Luca Bertinetto.....http://dblp.org/pers/hd/b/Bertinetto:Luca", "Jo\u00e3o F. Henriques.....http://dblp.org/pers/hd/h/Henriques:Jo=atilde=o_F=", "Jack Valmadre.....http://dblp.org/pers/hd/v/Valmadre:Jack", "Philip H. S. Torr.....http://dblp.org/pers/hd/t/Torr:Philip_H=_S=", "Andrea Vedaldi.....http://dblp.org/pers/hd/v/Vedaldi:Andrea"], "conf": "nips", "year": "2016", "pages": 9}