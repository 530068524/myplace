{"title": "Learning Optimally Sparse Support Vector Machines.", "fields": ["kernel", "sample complexity", "pattern recognition", "support vector machine", "machine learning"], "abstract": "We show how to train SVMs with an optimal guarantee on the number of support vectors (up to constants), and with sample complexity and training runtime bounds matching the best known for kernel SVM optimization (i.e. without any additional asymptotic cost beyond standard SVM training). Our method is simple to implement and works well in practice.", "citation": "Citations (29)", "departments": ["Toyota Technological Institute at Chicago", "Hebrew University of Jerusalem", "Toyota Technological Institute at Chicago"], "authors": ["Andrew Cotter.....http://dblp.org/pers/hd/c/Cotter:Andrew", "Shai Shalev-Shwartz.....http://dblp.org/pers/hd/s/Shalev=Shwartz:Shai", "Nati Srebro.....http://dblp.org/pers/hd/s/Srebro:Nati"], "conf": "icml", "year": "2013", "pages": 9}