{"title": "An accelerated gradient method for trace norm minimization.", "fields": ["norm", "gradient method", "semidefinite programming", "matrix completion", "multi task learning"], "abstract": "We consider the minimization of a smooth loss function regularized by the trace norm of the matrix variable. Such formulation finds applications in many machine learning tasks including multi-task learning, matrix classification, and matrix completion. The standard semidefinite programming formulation for this problem is computationally expensive. In addition, due to the non-smooth nature of the trace norm, the optimal first-order black-box method for solving such class of problems converges as  O (1/\u221a k ), where  k  is the iteration counter. In this paper, we exploit the special structure of the trace norm, based on which we propose an extended gradient algorithm that converges as  O (1/ k ). We further propose an accelerated gradient algorithm, which achieves the optimal convergence rate of  O (1/ k  2 ) for smooth problems. Experiments on multi-task learning problems demonstrate the efficiency of the proposed algorithms.", "citation": "Citations (408)", "departments": ["Arizona State University", "Arizona State University"], "authors": ["Shuiwang Ji.....http://dblp.org/pers/hd/j/Ji:Shuiwang", "Jieping Ye.....http://dblp.org/pers/hd/y/Ye:Jieping"], "conf": "icml", "year": "2009", "pages": 8}