{"title": "MUTT: Metric Unit TesTing for Language Generation Tasks.", "fields": ["closed captioning", "passive voice", "unit testing", "strengths and weaknesses", "sentence"], "abstract": "Precise evaluation metrics are important for assessing progress in high-level language generation tasks such as machine translation or image captioning. Historically, these metrics have been evaluated using correlation with human judgment. However, human-derived scores are often alarmingly inconsistent and are also limited in their ability to identify precise areas of weakness. In this paper, we perform a case study for metric evaluation by measuring the effect that systematic sentence transformations (e.g. active to passive voice) have on the automatic metric scores. These sentence \u201ccorruptions\u201d serve as unit tests for precisely measuring the strengths and weaknesses of a given metric. We find that not only are human annotations heavily inconsistent in this study, but that the Metric Unit TesT analysis is able to capture precise shortcomings of particular metrics (e.g. comparing passive and active sentences) better than a simple correlation with human judgment can.", "citation": "Not cited", "year": "2016", "departments": ["University of Massachusetts Lowell", "University of Massachusetts Lowell", "University of Massachusetts Lowell", "University of Massachusetts Lowell"], "conf": "acl", "authors": ["William Boag.....http://dblp.org/pers/hd/b/Boag:William", "Renan Campos.....http://dblp.org/pers/hd/c/Campos:Renan", "Kate Saenko.....http://dblp.org/pers/hd/s/Saenko:Kate", "Anna Rumshisky.....http://dblp.org/pers/hd/r/Rumshisky:Anna"], "pages": -1}