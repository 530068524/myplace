{"title": "Fast, smooth and adaptive regression in metric spaces.", "fields": ["curse of dimensionality", "intrinsic dimension", "kernel regression", "binary logarithm", "smoothness"], "abstract": "It was recently shown that certain nonparametric regressors can escape the curse of dimensionality when the intrinsic dimension of data is low ([1, 2]). We prove some stronger results in more general settings. In particular, we consider a regressor which, by combining aspects of both tree-based regression and kernel regression, adapts to intrinsic dimension, operates on general metrics, yields a smooth function, and evaluates in time O(log n). We derive a tight convergence rate of the form n-2/(2+d) where d is the Assouad dimension of the input space.", "citation": "Citations (6)", "year": "2009", "departments": ["University of California, San Diego"], "conf": "nips", "authors": ["Samory Kpotufe.....http://dblp.org/pers/hd/k/Kpotufe:Samory"], "pages": 9}