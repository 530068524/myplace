{"title": "Estimating Mutual Information for Discrete-Continuous Mixtures.", "fields": ["variation of information", "conditional mutual information", "multivariate mutual information", "information bottleneck method", "pointwise mutual information"], "abstract": "Estimation of mutual information from observed samples is a basic primitive in machine learning, useful in several learning tasks including correlation mining, information bottleneck, Chow-Liu tree, and conditional independence testing in (causal) graphical models. While mutual information is a quantity well-defined for general probability spaces, estimators have been developed only in the special case of discrete or continuous pairs of random variables. Most of these estimators operate using the 3H -principle, i.e., by calculating the three (differential) entropies of X, Y and the pair (X,Y). However, in general mixture spaces, such individual entropies are not well defined, even though mutual information is. In this paper, we develop a novel estimator for estimating mutual information in discrete-continuous mixtures. We prove the consistency of this estimator theoretically as well as demonstrate its excellent empirical performance. This problem is relevant in a wide-array of applications, where some variables are discrete, some continuous, and others are a mixture between continuous and discrete components.", "citation": "Citations (4)", "year": "2017", "departments": ["University of Illinois at Urbana\u2013Champaign", "University of Washington", "University of Illinois at Urbana\u2013Champaign", "University of Illinois at Urbana\u2013Champaign"], "conf": "nips", "authors": ["Weihao Gao.....http://dblp.org/pers/hd/g/Gao:Weihao", "Sreeram Kannan.....http://dblp.org/pers/hd/k/Kannan:Sreeram", "Sewoong Oh.....http://dblp.org/pers/hd/o/Oh:Sewoong", "Pramod Viswanath.....http://dblp.org/pers/hd/v/Viswanath:Pramod"], "pages": 12}