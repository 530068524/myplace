{"title": "Human Rademacher Complexity.", "fields": ["overfitting", "rademacher complexity", "sampling error", "complexity index", "computational learning theory"], "abstract": "We propose to use Rademacher complexity, originally developed in computational learning theory, as a measure of human learning capacity. Rademacher complexity measures a learner's ability to fit random labels, and can be used to bound the learner's true error based on the observed training sample error. We first review the definition of Rademacher complexity and its generalization bound. We then describe a \"learning the noise\" procedure to experimentally measure human Rademacher complexities. The results from empirical studies showed that: (i) human Rademacher complexity can be successfully measured, (ii) the complexity depends on the domain and training sample size in intuitive ways, (iii) human learning respects the generalization bounds, (iv) the bounds can be useful in predicting the danger of overfitting in human learning. Finally, we discuss the potential applications of human Rademacher complexity in cognitive science.", "citation": "Citations (12)", "year": "2009", "departments": ["University of Wisconsin-Madison", "University of Wisconsin-Madison", "University of Wisconsin-Madison"], "conf": "nips", "authors": ["Xiaojin Zhu.....http://dblp.org/pers/hd/z/Zhu_0001:Xiaojin", "Timothy T. Rogers.....http://dblp.org/pers/hd/r/Rogers:Timothy_T=", "Bryan R. Gibson.....http://dblp.org/pers/hd/g/Gibson:Bryan_R="], "pages": 9}