{"title": "Knowledge Acquisition for Visual Question Answering via Iterative Querying.", "fields": ["knowledge acquisition", "memory bank", "interpretability", "question answering", "knowledge extraction"], "abstract": "Humans possess an extraordinary ability to learn new skills and new knowledge for problem solving. Such learning ability is also required by an automatic model to deal with arbitrary, open-ended questions in the visual world. We propose a neural-based approach to acquiring task-driven information for visual question answering (VQA). Our model proposes queries to actively acquire relevant information from external auxiliary data. Supporting evidence from either human-curated or automatic sources is encoded and stored into a memory bank. We show that acquiring task-driven evidence effectively improves model performance on both the Visual7W and VQA datasets, moreover, these queries offer certain level of interpretability in our iterative QA model.", "citation": "Citations (5)", "year": "2017", "departments": ["Stanford University", "Stanford University", "Stanford University"], "conf": "cvpr", "authors": ["Yuke Zhu.....http://dblp.org/pers/hd/z/Zhu:Yuke", "Joseph J. Lim.....http://dblp.org/pers/hd/l/Lim:Joseph_J=", "Li Fei-Fei.....http://dblp.org/pers/hd/f/Fei=Fei:Li"], "pages": 10}