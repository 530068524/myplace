{"title": "Semi-Supervised Multinomial Naive Bayes for Text Classification by Leveraging Word-Level Statistical Constraint.", "fields": ["naive bayes classifier", "machine learning", "semi supervised learning", "expectation maximization algorithm", "multinomial distribution"], "abstract": "Multinomial Naive Bayes with Expectation Maximization (MNB-EM) is a standard semi-supervised learning method to augment Multinomial Naive Bayes (MNB) for text classification. Despite its success, MNB-EM is not stable, and may succeed or fail to improve MNB. We believe that this is because MNB-EM lacks the ability to preserve the class distribution on words.\n\nIn this paper, we propose a novel method to augment MNB-EM by leveraging the word-level statistical constraint to preserve the class distribution on words. The word-level statistical constraints are further converted to constraints on document posteriors generated by MNB-EM. Experiments demonstrate that our method can consistently improve MNB-EM, and outperforms state-of-art baselines remarkably.", "citation": "Citations (2)", "departments": ["Tsinghua University", "Tsinghua University", "Tsinghua University", "Samsung", "Samsung"], "authors": ["Li Zhao.....http://dblp.org/pers/hd/z/Zhao:Li", "Minlie Huang.....http://dblp.org/pers/hd/h/Huang:Minlie", "Ziyu Yao.....http://dblp.org/pers/hd/y/Yao:Ziyu", "Rongwei Su.....http://dblp.org/pers/hd/s/Su:Rongwei", "Yingying Jiang.....http://dblp.org/pers/hd/j/Jiang:Yingying", "Xiaoyan Zhu.....http://dblp.org/pers/hd/z/Zhu:Xiaoyan"], "conf": "aaai", "year": "2016", "pages": 8}