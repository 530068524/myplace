{"title": "Learning to Predict Distributions of Words Across Domains.", "fields": ["computer science", "machine learning", "single domain", "artificial intelligence", "natural language processing"], "abstract": "Although the distributional hypothesis has been applied successfully in many natural language processing tasks, systems using distributional information have been limited to a single domain because the distribution of a word can vary between domains as the word\u2019s predominant meaning changes. However, if it were possible to predict how the distribution of a word changes from one domain to another, the predictions could be used to adapt a system trained in one domain to work in another. We propose an unsupervised method to predict the distribution of a word in one domain, given its distribution in another domain. We evaluate our method on two tasks: cross-domain partof-speech tagging and cross-domain sentiment classification. In both tasks, our method significantly outperforms competitive baselines and returns results that are statistically comparable to current stateof-the-art methods, while requiring no task-specific customisations.", "citation": "Citations (10)", "year": "2014", "departments": ["University of Liverpool", "University of Sussex", "University of Sussex"], "conf": "acl", "authors": ["Danushka Bollegala.....http://dblp.org/pers/hd/b/Bollegala:Danushka", "David J. Weir.....http://dblp.org/pers/hd/w/Weir:David_J=", "John A. Carroll.....http://dblp.org/pers/hd/c/Carroll:John_A="], "pages": 11}