{"title": "Committing Bandits.", "fields": ["commit", "mathematical optimization", "regret", "time horizon", "upper and lower bounds"], "abstract": "We consider a multi-armed bandit problem where there are two phases. The first phase is an experimentation phase where the decision maker is free to explore multiple options. In the second phase the decision maker has to commit to one of the arms and stick with it. Cost is incurred during both phases with a higher cost during the experimentation phase. We analyze the regret in this setup, and both propose algorithms and provide upper and lower bounds that depend on the ratio of the duration of the experimentation phase to the duration of the commitment phase. Our analysis reveals that if given the choice, it is optimal to experiment \u0398(ln T) steps and then commit, where T is the time horizon.", "citation": "Citations (3)", "departments": ["Stanford University", "Stanford University", "Technion \u2013 Israel Institute of Technology"], "authors": ["Loc Bui.....http://dblp.org/pers/hd/b/Bui:Loc", "Ramesh Johari.....http://dblp.org/pers/hd/j/Johari:Ramesh", "Shie Mannor.....http://dblp.org/pers/hd/m/Mannor:Shie"], "conf": "nips", "year": "2011", "pages": 9}