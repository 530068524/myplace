{"title": "Regularization and feature selection in least-squares temporal difference learning.", "fields": ["regularization", "least angle regression", "reinforcement learning", "bellman equation", "temporal difference learning"], "abstract": "We consider the task of reinforcement learning with linear value function approximation. Temporal difference algorithms, and in particular the Least-Squares Temporal Difference (LSTD) algorithm, provide a method for learning the parameters of the value function, but when the number of features is large this algorithm can over-fit to the data and is computationally expensive. In this paper, we propose a regularization framework for the LSTD algorithm that overcomes these difficulties. In particular, we focus on the case of  l  1  regularization, which is robust to irrelevant features and also serves as a method for feature selection. Although the  l  1  regularized LSTD solution cannot be expressed as a convex optimization problem, we present an algorithm similar to the Least Angle Regression (LARS) algorithm that can efficiently compute the optimal solution. Finally, we demonstrate the performance of the algorithm experimentally.", "citation": "Citations (187)", "departments": ["Stanford University", "Stanford University"], "authors": ["J. Zico Kolter.....http://dblp.org/pers/hd/k/Kolter:J=_Zico", "Andrew Y. Ng.....http://dblp.org/pers/hd/n/Ng:Andrew_Y="], "conf": "icml", "year": "2009", "pages": 8}