{"title": "Value Prediction Network.", "fields": ["machine learning", "artificial intelligence", "reinforcement learning", "artificial neural network", "architecture"], "abstract": "This paper proposes a novel deep reinforcement learning (RL) architecture, called Value Prediction Network (VPN), which integrates model-free and model-based RL methods into a single neural network. In contrast to typical model-based RL methods, VPN learns a dynamics model whose abstract states are trained to make option-conditional predictions of future values (discounted sum of rewards) rather than of future observations. Our experimental results show that VPN has several advantages over both model-free and model-based baselines in a stochastic environment where careful planning is required but building an accurate observation-prediction model is difficult. Furthermore, VPN outperforms Deep Q-Network (DQN) on several Atari games even with short-lookahead planning, demonstrating its potential as a new way of learning a good state representation.", "citation": "Citations (15)", "year": "2017", "departments": ["University of Michigan", "University of Michigan", "University of Michigan", "Google"], "conf": "nips", "authors": ["Junhyuk Oh.....http://dblp.org/pers/hd/o/Oh:Junhyuk", "Satinder Singh.....http://dblp.org/pers/hd/s/Singh:Satinder", "Honglak Lee.....http://dblp.org/pers/hd/l/Lee:Honglak"], "pages": 11}