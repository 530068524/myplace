{"title": "Flexible Spatio-Temporal Networks for Video Prediction.", "fields": ["optical imaging", "extrapolation", "video tracking", "modular design", "interpolation"], "abstract": "We describe a modular framework for video frame prediction. We refer to it as a Flexible Spatio-Temporal Network (FSTN) as it allows the extrapolation of a video sequence as well as the estimation of synthetic frames lying in between observed frames and thus the generation of slow-motion videos. By devising a customized objective function comprising decoding, encoding, and adversarial losses, we are able to mitigate the common problem of blurry predictions, managing to retain high frequency information even for relatively distant future predictions. We propose and analyse different training strategies to optimize our model. Extensive experiments on several challenging public datasets demonstrate both the versatility and validity of our model.", "citation": "Citations (5)", "year": "2017", "departments": ["Max Planck Society", "Max Planck Society", "Max Planck Society"], "conf": "cvpr", "authors": ["Chaochao Lu.....http://dblp.org/pers/hd/l/Lu:Chaochao", "Michael Hirsch.....http://dblp.org/pers/hd/h/Hirsch_0001:Michael", "Bernhard Sch\u00f6lkopf.....http://dblp.org/pers/hd/s/Sch=ouml=lkopf:Bernhard"], "pages": 9}