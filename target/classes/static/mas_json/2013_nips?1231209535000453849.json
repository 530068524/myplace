{"title": "New Subsampling Algorithms for Fast Least Squares Regression.", "fields": ["least squares", "covariance matrix", "big data", "hadamard transform", "ordinary least squares"], "abstract": "We address the problem of fast estimation of ordinary least squares (OLS) from large amounts of data (n \u226b p). We propose three methods which solve the big data problem by subsampling the covariance matrix using either a single or two stage estimation. All three run in the order of size of input i.e. O(np) and our best method, Uluru, gives an error bound of O(\u221ap/n) which is independent of the amount of subsampling as long as it is above a threshold. We provide theoretical bounds for our algorithms in the fixed design (with Randomized Hadamard preconditioning) as well as sub-Gaussian random design setting. We also compare the performance of our methods on synthetic and real-world datasets and show that if observations are i.i.d., sub-Gaussian then one can directly subsample without the expensive Randomized Hadamard preconditioning without loss of accuracy.", "citation": "Citations (19)", "departments": ["University of Pennsylvania", "University of Pennsylvania", "University of Pennsylvania", "University of Pennsylvania"], "authors": ["Paramveer S. Dhillon.....http://dblp.org/pers/hd/d/Dhillon:Paramveer_S=", "Yichao Lu.....http://dblp.org/pers/hd/l/Lu:Yichao", "Dean P. Foster.....http://dblp.org/pers/hd/f/Foster:Dean_P=", "Lyle H. Ungar.....http://dblp.org/pers/hd/u/Ungar:Lyle_H="], "conf": "nips", "year": "2013", "pages": 9}