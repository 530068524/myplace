{"title": "Feature selection in functional data classification with recursive maxima hunting.", "fields": ["conditional expectation", "recursion", "data classification", "curse of dimensionality", "maxima"], "abstract": "Dimensionality reduction is one of the key issues in the design of effective machine learning methods for automatic induction. In this work, we introduce recursive maxima hunting (RMH) for variable selection in classification problems with functional data. In this context, variable selection techniques are especially attractive because they reduce the dimensionality, facilitate the interpretation and can improve the accuracy of the predictive models. The method, which is a recursive extension of maxima hunting (MH), performs variable selection by identifying the maxima of a relevance function, which measures the strength of the correlation of the predictor functional variable with the class label. At each stage, the information associated with the selected variable is removed by subtracting the conditional expectation of the process. The results of an extensive empirical evaluation are used to illustrate that, in the problems investigated, RMH has comparable or higher predictive accuracy than standard simensionality reduction techniques, such as PCA and PLS, and state-of-the-art feature selection methods for functional data, such as maxima hunting.", "citation": "Not cited", "departments": ["Autonomous University of Madrid"], "authors": ["Jos\u00e9 L. Torrecilla.....http://dblp.org/pers/hd/t/Torrecilla:Jos=eacute=_L=", "Alberto Su\u00e1rez.....http://dblp.org/pers/hd/s/Su=aacute=rez_0001:Alberto"], "conf": "nips", "year": "2016", "pages": 9}