{"title": "Generative versus discriminative training of RBMs for classification of fMRI images.", "fields": ["overfitting", "discriminative model", "generative grammar", "small number", "generative model"], "abstract": "Neuroimaging datasets often have a very large number of voxels and a very small number of training cases, which means that overfitting of models for this data can become a very serious problem. Working with a set of fMRI images from a study on stroke recovery, we consider a classification task for which logistic regression performs poorly, even when L1- or L2- regularized. We show that much better discrimination can be achieved by fitting a generative model to each separate condition and then seeing which model is most likely to have generated the data. We compare discriminative training of exactly the same set of models, and we also consider convex blends of generative and discriminative training.", "citation": "Citations (78)", "year": "2008", "departments": ["University of Toronto", "University of Toronto", "University of Chicago", "University of Toronto", "The Rotman Rese ... oronto, Canada"], "conf": "nips", "authors": ["Tanya Schmah.....http://dblp.org/pers/hd/s/Schmah:Tanya", "Geoffrey E. Hinton.....http://dblp.org/pers/hd/h/Hinton:Geoffrey_E=", "Richard S. Zemel.....http://dblp.org/pers/hd/z/Zemel:Richard_S=", "Steven L. Small.....http://dblp.org/pers/hd/s/Small:Steven_L=", "Stephen C. Strother.....http://dblp.org/pers/hd/s/Strother:Stephen_C="], "pages": 8}