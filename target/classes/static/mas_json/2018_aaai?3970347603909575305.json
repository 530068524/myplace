{"title": "Efficient Large-Scale Multi-Modal Classification.", "fields": ["discretization", "interpretability", "convolutional neural network", "speedup", "fusion"], "abstract": "While the incipient internet was largely text-based, the modern digital world is becoming increasingly multi-modal. Here, we examine multi-modal classification where one modality is discrete, e.g. text, and the other is continuous, e.g. visual representations transferred from a convolutional neural network. In particular, we focus on scenarios where we have to be able to classify large quantities of data quickly. We investigate various methods for performing multi-modal fusion and analyze their trade-offs in terms of classification accuracy and computational efficiency. Our findings indicate that the inclusion of continuous information improves performance over text-only on a range of multi-modal classification tasks, even with simple fusion methods. In addition, we experiment with discretizing the continuous features in order to speed up and simplify the fusion process even further. Our results show that fusion with discretized features outperforms text-only classification, at a fraction of the computational cost of full multi-modal fusion, with the additional benefit of improved interpretability.", "citation": "Not cited", "departments": ["Facebook", "University of California, Berkeley", "Stanford University", "Google"], "authors": ["Douwe Kiela.....http://dblp.org/pers/hd/k/Kiela:Douwe", "Edouard Grave.....http://dblp.org/pers/hd/g/Grave:Edouard", "Armand Joulin.....http://dblp.org/pers/hd/j/Joulin:Armand", "Tomas Mikolov.....http://dblp.org/pers/hd/m/Mikolov:Tomas"], "conf": "aaai", "year": "2018", "pages": 7}