{"title": "On Interruptible Pure Exploration in Multi-Armed Bandits.", "fields": ["performance improvement", "decision problem", "discriminative model", "multi armed bandit", "search algorithm"], "abstract": "Interruptible pure exploration in multi-armed bandits (MABs) is a key component of Monte-Carlo tree search algorithms for sequential decision problems. We introduce Discriminative Bucketing (DB), a novel family of strategies for pure exploration in MABs, which allows for adapting recent advances in non-interruptible strategies to the interruptible setting, while guaranteeing exponential-rate performance improvement over time. Our experimental evaluation demonstrates that the corresponding instances of DB favorably compete both with the currently popular strategies UCB1 and e-Greedy, as well as with the conservative uniform sampling.", "citation": "Not cited", "departments": ["Technion \u2013 Israel Institute of Technology", "Czech Technical University in Prague", "Technion \u2013 Israel Institute of Technology"], "authors": ["Alexander Shleyfman.....http://dblp.org/pers/hd/s/Shleyfman:Alexander", "Anton\u00edn Komenda.....http://dblp.org/pers/hd/k/Komenda:Anton=iacute=n", "Carmel Domshlak.....http://dblp.org/pers/hd/d/Domshlak:Carmel"], "conf": "aaai", "year": "2015", "pages": 7}