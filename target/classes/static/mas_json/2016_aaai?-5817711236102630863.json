{"title": "A POMDP Formulation of Proactive Learning.", "fields": ["oracle", "correctness", "partially observable markov decision process", "proactive learning", "machine learning"], "abstract": "We cast the Proactive Learning (PAL) problem\u2014Active Learning (AL) with multiple reluctant, fallible, cost-varying oracles\u2014as a Partially Observable Markov Decision Process (POMDP). The agent selects an oracle at each time step to label a data point while it maintains a belief over the true underlying correctness of its current dataset's labels. The goal is to minimize labeling costs while considering the value of obtaining correct labels, thus maximizing final resultant classifier accuracy. We prove three properties that show our particular formulation leads to a structured and bounded-size set of belief points, enabling strong performance of point-based methods to solve the POMDP. Our method is compared with the original three algorithms proposed by Donmez and Carbonell and a simple baseline. We demonstrate that our approach matches or improves upon the original approach within five different oracle scenarios, each on two datasets. Finally, our algorithm provides a general, well-defined mathematical foundation to build upon.", "citation": "Not cited", "departments": ["University of Massachusetts Amherst", "University of Massachusetts Amherst"], "authors": ["Kyle Hollins Wray.....http://dblp.org/pers/hd/w/Wray:Kyle_Hollins", "Shlomo Zilberstein.....http://dblp.org/pers/hd/z/Zilberstein:Shlomo"], "conf": "aaai", "year": "2016", "pages": 7}