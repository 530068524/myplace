{"title": "Human activities recognition using depth images.", "fields": ["training set", "exploit", "discriminative model", "color image", "spatial analysis"], "abstract": "We present a new method to classify human activities by leveraging on the cues available from depth images alone. Towards this end, we propose a descriptor which couples depth and spatial information of the segmented body to describe a human pose. Unique poses (i.e. codewords) are then identified by a spatial-based clustering step. Given a video sequence of depth images, we segment humans from the depth images and represent these segmented bodies as a sequence of codewords. We exploit unique poses of an activity and the temporal ordering of these poses to learn subsequences of codewords which are strongly discriminative for the activity. Each discriminative subsequence acts as a classifier and we learn a boosted ensemble of discriminative subsequences to assign a confidence score for the activity label of the test sequence. Unlike existing methods which demand accurate tracking of 3D joint locations or couple depth with color image information as recognition cues, our method requires only the segmentation masks from depth images to recognize an activity. Experimental results on the publicly available Human Activity Dataset (which comprises 12 challenging activities) demonstrate the validity of our method, where we attain a precision/recall of 78.1%/75.4% when the person was not seen before in the training set, and 94.6%/93.1% when the person was seen before.", "citation": "Citations (31)", "departments": ["Nanyang Technological University", "Rakuten", "Nanyang Technological University"], "authors": ["Raj Kumar Gupta.....http://dblp.org/pers/hd/g/Gupta:Raj_Kumar", "Alex Yong Sang Chia.....http://dblp.org/pers/hd/c/Chia:Alex_Yong_Sang", "Deepu Rajan.....http://dblp.org/pers/hd/r/Rajan:Deepu"], "conf": "mm", "year": "2013", "pages": 10}