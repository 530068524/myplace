{"title": "MaskRNN: Instance Level Video Object Segmentation.", "fields": ["segmentation", "minimum bounding box", "video editing", "artificial neural network", "video tracking"], "abstract": "Instance level video object segmentation is an important technique for video editing and compression. To capture the temporal coherence, in this paper, we develop MaskRNN, a recurrent neural net approach which fuses in each frame the output of two deep nets for each object instance - a binary segmentation net providing a mask and a localization net providing a bounding box. Due to the recurrent component and the localization component, our method is able to take advantage of long-term temporal structures of the video data as well as rejecting outliers. We validate the proposed algorithm on three challenging benchmark datasets, the DAVIS-2016 dataset, the DAVIS-2017 dataset, and the Segtrack v2 dataset, achieving state-of-the-art performance on all of them.", "citation": "Citations (6)", "year": "2017", "departments": ["University of Illinois at Urbana\u2013Champaign", "Virginia Tech", "University of Illinois at Urbana\u2013Champaign"], "conf": "nips", "authors": ["Yuan-Ting Hu.....http://dblp.org/pers/hd/h/Hu:Yuan=Ting", "Jia-Bin Huang.....http://dblp.org/pers/hd/h/Huang:Jia=Bin", "Alexander G. Schwing.....http://dblp.org/pers/hd/s/Schwing:Alexander_G="], "pages": 10}