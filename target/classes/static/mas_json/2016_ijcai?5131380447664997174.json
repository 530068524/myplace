{"title": "Inference Machines for Nonparametric Filter Learning.", "fields": ["nonparametric statistics", "inference", "state space", "predictive state representation", "parametric statistics"], "abstract": "Data-driven approaches for learning dynamic models for Bayesian filtering often try to maximize the data likelihood given parametric forms for the transition and observation models. However, this objective is usually nonconvex in the parametrization and can only be locally optimized. Furthermore, learning algorithms typically do not provide performance guarantees on the desired Bayesian filtering task. In this work, we propose using inference machines to directly optimize the filtering performance. Our procedure is capable of learning partially-observable systems when the state space is either unknown or known in advance. To accomplish this, we adapt PREDICTIVE STATE INFERENCE MACHINES (PSIMS) by introducing the concept of hints, which incorporate prior knowledge of the state space to accompany the predictive state representation. This allows PSIM to be applied to the larger class of filtering problems which require prediction of a specific parameter or partial component of state. Our PSIM+HINTS adaptation enjoys theoretical advantages similar to the original PSIM algorithm, and we showcase its performance on a variety of robotics filtering problems.", "citation": "Citations (1)", "year": "2016", "departments": ["Carnegie Mellon University", "Carnegie Mellon University", "Carnegie Mellon University", "Georgia Institute of Technology", "Carnegie Mellon University"], "conf": "ijcai", "authors": ["Arun Venkatraman.....http://dblp.org/pers/hd/v/Venkatraman:Arun", "Wen Sun.....http://dblp.org/pers/hd/s/Sun_0002:Wen", "Martial Hebert.....http://dblp.org/pers/hd/h/Hebert:Martial", "Byron Boots.....http://dblp.org/pers/hd/b/Boots:Byron", "J. Andrew Bagnell.....http://dblp.org/pers/hd/b/Bagnell:J=_Andrew"], "pages": 8}