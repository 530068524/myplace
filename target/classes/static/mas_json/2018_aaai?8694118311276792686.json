{"title": "MixedPeds: Pedestrian Detection in Unannotated Videos Using Synthetically Generated Human-Agents for Training.", "fields": ["pattern recognition", "pedestrian detection", "mixed reality", "computer vision", "vanishing point"], "abstract": "We present a new method for training pedestrian detectors on an unannotated set of images. We produce a mixed reality dataset that is composed of real-world background images and synthetically generated static human-agents. Our approach is general, robust, and makes no other assumptions about the unannotated dataset regarding the number or location of pedestrians. We automatically extract from the dataset: i) the vanishing point to calibrate the virtual camera, and ii) the pedestrians' scales to generate a Spawn Probability Map, which is a novel concept that guides our algorithm to place the pedestrians at appropriate locations. After putting synthetic human-agents in the unannotated images, we use these augmented images to train a Pedestrian Detector, with the annotations generated along with the synthetic agents. We conducted our experiments using Faster R-CNN by comparing the detection results on the unannotated dataset performed by the detector trained using our approach and detectors trained with other manually labeled datasets. We showed that our approach improves the average precision by 5-13% over these detectors.", "citation": "Citations (2)", "departments": ["University of North Carolina at Chapel Hill", "University of North Carolina at Chapel Hill", "University of North Carolina at Chapel Hill"], "authors": ["Ernest Cheung.....http://dblp.org/pers/hd/c/Cheung:Ernest", "Anson Wong.....http://dblp.org/pers/hd/w/Wong:Anson", "Aniket Bera.....http://dblp.org/pers/hd/b/Bera:Aniket", "Dinesh Manocha.....http://dblp.org/pers/hd/m/Manocha:Dinesh"], "conf": "aaai", "year": "2018", "pages": 10}