{"title": "On the Expressive Power of Deep Neural Networks.", "fields": ["deep learning", "initialization", "expressivity", "mnist database", "expressive power"], "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "citation": "Citations (97)", "year": "2017", "departments": ["Cornell University", "Stanford University", "Cornell University", "Stanford University", "Google"], "conf": "icml", "authors": ["Maithra Raghu.....http://dblp.org/pers/hd/r/Raghu:Maithra", "Ben Poole.....http://dblp.org/pers/hd/p/Poole:Ben", "Jon M. Kleinberg.....http://dblp.org/pers/hd/k/Kleinberg:Jon_M=", "Surya Ganguli.....http://dblp.org/pers/hd/g/Ganguli:Surya", "Jascha Sohl-Dickstein.....http://dblp.org/pers/hd/s/Sohl=Dickstein:Jascha"], "pages": 8}