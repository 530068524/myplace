{"title": "On Deep Multi-View Representation Learning.", "fields": ["pattern recognition", "machine learning", "feature learning", "artificial neural network", "feed forward"], "abstract": "We consider learning representations (features) in the setting in which we have access to multiple unlabeled views of the data for representation learning while only one view is available at test time. Previous work on this problem has proposed several techniques based on deep neural networks, typically involving either autoencoder-like networks with a reconstruction objective or paired feedforward networks with a correlation-based objective. We analyze several techniques based on prior work, as well as new variants, and compare them experimentally on visual, speech, and language domains. To our knowledge this is the first head-to-head comparison of a variety of such techniques on multiple tasks. We find an advantage for correlation-based representation learning, while the best results on most tasks are obtained with our new variant, deep canonically correlated autoencoders (DCCAE).", "citation": "Citations (187)", "year": "2015", "departments": ["Toyota Technological Institute at Chicago", "Johns Hopkins University", "Toyota Technological Institute at Chicago", "University of Washington"], "conf": "icml", "authors": ["Weiran Wang.....http://dblp.org/pers/hd/w/Wang:Weiran", "Raman Arora.....http://dblp.org/pers/hd/a/Arora:Raman", "Karen Livescu.....http://dblp.org/pers/hd/l/Livescu:Karen", "Jeff A. Bilmes.....http://dblp.org/pers/hd/b/Bilmes:Jeff_A="], "pages": 10}