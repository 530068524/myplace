{"title": "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks.", "fields": ["semantic similarity", "treebank", "semeval", "recurrent neural network", "syntax"], "abstract": "A Long Short-Term Memory (LSTM) network is a type of recurrent neural network architecture which has recently obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. TreeLSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank).", "citation": "Citations (820)", "year": "2015", "departments": ["Stanford University", "University of Colorado Boulder", "Stanford University"], "conf": "acl", "authors": ["Kai Sheng Tai.....http://dblp.org/pers/hd/t/Tai:Kai_Sheng", "Richard Socher.....http://dblp.org/pers/hd/s/Socher:Richard", "Christopher D. Manning.....http://dblp.org/pers/hd/m/Manning:Christopher_D="], "pages": 11}