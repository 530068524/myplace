{"title": "Speech Act Modeling of Written Asynchronous Conversations with Task-Specific Embeddings and Conditional Structured Models.", "fields": ["long short term memory", "natural language processing", "graph", "asynchronous communication", "sentence"], "abstract": "This paper addresses the problem of speech act recognition in written asynchronous conversations (e.g., fora, emails). We propose a class of conditional structured models defined over arbitrary graph structures to capture the conversational dependencies between sentences. Our models use sentence representations encoded by a long short term memory (LSTM) recurrent neural model. Empirical evaluation shows the effectiveness of our approach over existing ones: (i) LSTMs provide better task-specific representations, and (ii) the global joint model improves over local models.", "citation": "Citations (1)", "year": "2016", "departments": ["Qatar Foundation", "University of British Columbia"], "conf": "acl", "authors": ["Shafiq R. Joty.....http://dblp.org/pers/hd/j/Joty:Shafiq_R=", "Enamul Hoque.....http://dblp.org/pers/hd/h/Hoque:Enamul"], "pages": -1}