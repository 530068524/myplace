{"title": "Randomized Pruning: Efficiently Calculating Expectations in Large Dynamic Programs.", "fields": ["principal variation search", "markov chain monte carlo", "pruning", "parsing"], "abstract": "Pruning can massively accelerate the computation of feature expectations in large models. However, any single pruning mask will introduce bias. We present a novel approach which employs a randomized sequence of pruning masks. Formally, we apply auxiliary variable MCMC sampling to generate this sequence of masks, thereby gaining theoretical guarantees about convergence. Because each mask is generally able to skip large portions of an underlying dynamic program, our approach is particularly compelling for high-degree algorithms. Empirically, we demonstrate our method on bilingual parsing, showing decreasing bias as more masks are incorporated, and outperforming fixed tic-tac-toe pruning.", "citation": "Citations (3)", "year": "2009", "departments": ["University of California, Berkeley", "University of California, Berkeley", "University of California, Berkeley"], "conf": "nips", "authors": ["Alexandre Bouchard-C\u00f4t\u00e9.....http://dblp.org/pers/hd/b/Bouchard=C=ocirc=t=eacute=:Alexandre", "Slav Petrov.....http://dblp.org/pers/hd/p/Petrov:Slav", "Dan Klein.....http://dblp.org/pers/hd/k/Klein:Dan"], "pages": 9}