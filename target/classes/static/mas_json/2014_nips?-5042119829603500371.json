{"title": "Feedforward Learning of Mixture Models.", "fields": ["experimental data", "mathematical proof", "learning rule", "generality", "feed forward"], "abstract": "We develop a biologically-plausible learning rule that provably converges to the class means of general mixture models. This rule generalizes the classical BCM neural rule within a tensor framework, substantially increasing the generality of the learning problem it solves. It achieves this by incorporating triplets of samples from the mixtures, which provides a novel information processing interpretation to spike-timing-dependent plasticity. We provide both proofs of convergence, and a close fit to experimental data on STDP.", "citation": "Citations (1)", "year": "2014", "departments": ["Yale University", "Yale University"], "conf": "nips", "authors": ["Matthew Lawlor.....http://dblp.org/pers/hd/l/Lawlor:Matthew", "Steven W. Zucker.....http://dblp.org/pers/hd/z/Zucker:Steven_W="], "pages": 9}