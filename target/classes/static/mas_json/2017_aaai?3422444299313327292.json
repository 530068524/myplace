{"title": "Associative Memory Using Dictionary Learning and Expander Decoding.", "fields": ["recall", "expander code", "content addressable memory", "associative property", "graphical model"], "abstract": "An associative memory is a framework of content-addressable memory that stores a collection of message vectors (or a dataset) over a neural network while enabling a neurally feasible mechanism to recover any message in the dataset from its noisy version. Designing an associative memory requires addressing two main tasks: 1) learning phase: given a dataset, learn a concise representation of the dataset in the form of a graphical model (or a neural network), 2) recall phase: given a noisy version of a message vector from the dataset, output the correct message vector via a neurally feasible algorithm over the network learnt during the learning phase. This paper studies the problem of designing a class of neural associative memories which learns a network representation for a large dataset that ensures correction against a large number of adversarial errors during the recall phase. Specifically, the associative memories designed in this paper can store dataset containing exp( n )  n -length message vectors over a network with  O ( n ) nodes and can tolerate \u03a9( n  / polylog) adversarial errors. This paper carries out this memory design by mapping the learning phase and recall phase to the tasks of dictionary learning with a square dictionary and iterative error correction in an expander code, respectively.", "citation": "Citations (4)", "departments": ["University of Massachusetts Amherst", "Massachusetts Institute of Technology"], "authors": ["Arya Mazumdar.....http://dblp.org/pers/hd/m/Mazumdar:Arya", "Ankit Singh Rawat.....http://dblp.org/pers/hd/r/Rawat:Ankit_Singh"], "conf": "aaai", "year": "2017", "pages": 7}