{"title": "Multi-Level Variational Autoencoder: Learning Disentangled Representations From Grouped Observations.", "fields": ["probabilistic logic", "independent and identically distributed random variables", "exploit", "autoencoder", "grouped data"], "abstract": "We would like to learn a representation of the data which decomposes an observation into factors of variation which we can independently control. Specifically, we want to use minimal supervision to learn a latent representation that reflects the semantics behind a specific grouping of the data, where within a group the samples share a common factor of variation. For example, consider a collection of face images grouped by identity. We wish to anchor the semantics of the grouping into a relevant and disentangled representation that we can easily exploit. However, existing deep probabilistic models often assume that the observations are independent and identically distributed. We present the Multi-Level Variational Autoencoder (ML-VAE), a new deep probabilistic model for learning a disentangled representation of a set of grouped observations. The ML-VAE separates the latent representation into semantically meaningful parts by working both at the group level and the observation level, while retaining efficient test-time inference. Quantitative and qualitative evaluations show that the ML-VAE model (i) learns a semantically meaningful disentanglement of grouped data, (ii) enables manipulation of the latent representation, and (iii) generalises to unseen groups.", "citation": "Citations (5)", "departments": ["CentraleSup\u00e9lec", "Microsoft", "Microsoft"], "authors": ["Diane Bouchacourt.....http://dblp.org/pers/hd/b/Bouchacourt:Diane", "Ryota Tomioka.....http://dblp.org/pers/hd/t/Tomioka:Ryota", "Sebastian Nowozin.....http://dblp.org/pers/hd/n/Nowozin:Sebastian"], "conf": "aaai", "year": "2018", "pages": 8}