{"title": "Temporal Convolutional Networks for Action Segmentation and Detection.", "fields": ["segmentation", "pooling", "upsampling", "recurrent neural network", "decoding methods"], "abstract": "The ability to identify and temporally segment fine-grained human actions throughout a video is crucial for robotics, surveillance, education, and beyond. Typical approaches decouple this problem by first extracting local spatiotemporal features from video frames and then feeding them into a temporal classifier that captures high-level temporal patterns. We describe a class of temporal models, which we call Temporal Convolutional Networks (TCNs), that use a hierarchy of temporal convolutions to perform fine-grained action segmentation or detection. Our Encoder-Decoder TCN uses pooling and upsampling to efficiently capture long-range temporal patterns whereas our Dilated TCN uses dilated convolutions. We show that TCNs are capable of capturing action compositions, segment durations, and long-range dependencies, and are over a magnitude faster to train than competing LSTM-based Recurrent Neural Networks. We apply these models to three challenging fine-grained datasets and show large improvements over the state of the art.", "citation": "Citations (19)", "year": "2017", "departments": ["Johns Hopkins University", "Johns Hopkins University", "Johns Hopkins University", "Johns Hopkins University", "Johns Hopkins University"], "conf": "cvpr", "authors": ["Colin Lea.....http://dblp.org/pers/hd/l/Lea:Colin", "Michael D. Flynn.....http://dblp.org/pers/hd/f/Flynn:Michael_D=", "Ren\u00e9 Vidal.....http://dblp.org/pers/hd/v/Vidal:Ren=eacute=", "Austin Reiter.....http://dblp.org/pers/hd/r/Reiter:Austin", "Gregory D. Hager.....http://dblp.org/pers/hd/h/Hager:Gregory_D="], "pages": 10}