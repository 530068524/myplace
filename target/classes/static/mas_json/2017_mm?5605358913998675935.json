{"title": "MANet: A Modal Attention Network for Describing Videos.", "fields": ["mobile ad hoc network", "computer vision", "closed captioning", "multimedia", "modalities"], "abstract": "Exploiting multimodal features has become a standard approach towards many video applications, including the video captioning task. One problem with the existing work is that it models the relevance of each type of features evenly, which neutralizes the impact of each individual modality to the word to be generated. In this paper, we propose a novel Modal Attention Network (MANet) to account for this issue. Our MANet extends the standard encoder-decoder network by adapting the attention mechanism to video modalities. As a result, MANet emphasizes the impact of each modality with respect to the word to be generated. Experimental results show that our MANet effectively utilizes multimodal features to generate better video descriptions. Especially, our MANet system was ranked among the top three systems at the 2nd Video to Language Challenge in both automatic metrics and human evaluations.", "citation": "Not cited", "departments": ["National Institute of Informatics", "National Institute of Informatics", "National Institute of Informatics"], "authors": ["Sang Phan.....http://dblp.org/pers/hd/p/Phan:Sang", "Yusuke Miyao.....http://dblp.org/pers/hd/m/Miyao:Yusuke", "Shin'ichi Satoh.....http://dblp.org/pers/hd/s/Satoh:Shin=ichi"], "conf": "mm", "year": "2017", "pages": 6}