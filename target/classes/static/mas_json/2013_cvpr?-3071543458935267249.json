{"title": "Watching Unlabeled Video Helps Learn New Human Actions from Very Few Labeled Snapshots.", "fields": ["snapshot", "training set", "small number", "computer vision", "pattern recognition"], "abstract": "We propose an approach to learn action categories from static images that leverages prior observations of generic human motion to augment its training process. Using unlabeled video containing various human activities, the system first learns how body pose tends to change locally in time. Then, given a small number of labeled static images, it uses that model to extrapolate beyond the given exemplars and generate \"synthetic\" training examples-poses that could link the observed images and/or immediately precede or follow them in time. In this way, we expand the training set without requiring additional manually labeled examples. We explore both example-based and manifold-based methods to implement our idea. Applying our approach to recognize actions in both images and video, we show it enhances a state-of-the-art technique when very few labeled training examples are available.", "citation": "Citations (29)", "year": "2013", "departments": ["University of Texas at Austin", "University of Texas at Austin"], "conf": "cvpr", "authors": ["Chao-Yeh Chen.....http://dblp.org/pers/hd/c/Chen:Chao=Yeh", "Kristen Grauman.....http://dblp.org/pers/hd/g/Grauman:Kristen"], "pages": 8}