{"title": "Neural Cache: Bit-Serial In-Cache Acceleration of Deep Neural Networks.", "fields": ["convolutional neural network", "xeon", "bit serial architecture", "cache only memory architecture", "cache"], "abstract": "This paper presents the  Neural Cache  architecture, which re-purposes cache structures to transform them into massively parallel compute units capable of running inferences for Deep Neural Networks. Techniques to do in-situ arithmetic in SRAM arrays, create efficient data mapping and reducing data movement are proposed. The  Neural Cache  architecture is capable of fully executing convolutional, fully connected, and pooling layers in-cache. The proposed architecture also supports quantization in-cache.   Our experimental results show that the proposed architecture can improve inference latency by 18.3X over state-of-art multi-core CPU (Xeon E5), 7.7X over server class GPU (Titan Xp), for Inception v3 model.  Neural Cache  improves inference throughput by 12.4X over CPU (2.2X over GPU), while reducing power consumption by 50% over CPU (53% over GPU).", "citation": "Not cited", "departments": ["University of Michigan", "University of Michigan", "University of Michigan", "University of Michigan", "Intel"], "authors": ["Charles Eckert.....http://dblp.org/pers/hd/e/Eckert:Charles", "Xiaowei Wang.....http://dblp.org/pers/hd/w/Wang:Xiaowei", "Jingcheng Wang.....http://dblp.org/pers/hd/w/Wang:Jingcheng", "Arun Subramaniyan.....http://dblp.org/pers/hd/s/Subramaniyan_0001:Arun", "Ravi R. Iyer.....http://dblp.org/pers/hd/i/Iyer:Ravi_R=", "Dennis Sylvester.....http://dblp.org/pers/hd/s/Sylvester:Dennis", "David T. Blaauw.....http://dblp.org/pers/hd/b/Blaauw:David_T=", "Reetuparna Das.....http://dblp.org/pers/hd/d/Das:Reetuparna"], "conf": "isca", "year": "2018", "pages": 14}