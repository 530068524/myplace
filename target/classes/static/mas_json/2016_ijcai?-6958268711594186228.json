{"title": "Budgeted Multi-Armed Bandits with Multiple Plays.", "fields": ["integer", "linear fractional programming", "special case", "sublinear function", "regret"], "abstract": "We study the multi-play budgeted multi-armed bandit (MP-BMAB) problem, in which pulling an arm receives both a random reward and a random cost, and a player pulls L(\u2265 1) arms at each round. The player targets at maximizing her total expected reward under a budget constraint B for the pulling costs. We present a multiple ratio confidence bound policy: At each round, we first calculate a truncated upper (lower) confidence bound for the expected reward (cost) of each arm, and then pull the L arms with the maximum ratio of the sum of the upper confidence bounds of rewards to the sum of the lower confidence bounds of costs. We design a 0- 1 integer linear fractional programming oracle that can pick such the L arms within polynomial time. We prove that the regret of our policy is sublinear in general and is log-linear for certain parameter settings. We further consider two special cases of MP-BMABs: (1) We derive a lower bound for any consistent policy for MP-BMABs with Bernoulli reward and cost distributions. (2) We show that the proposed policy can also solve conventional budgeted MAB problem (a special case of MP-BMABs with L = 1) and provides better theoretical results than existing UCB-based pulling policies.", "citation": "Citations (6)", "year": "2016", "departments": ["University of Science and Technology of China", "Microsoft", "Microsoft", "University of Science and Technology of China", "Microsoft"], "conf": "ijcai", "authors": ["Yingce Xia.....http://dblp.org/pers/hd/x/Xia:Yingce", "Tao Qin.....http://dblp.org/pers/hd/q/Qin:Tao", "Weidong Ma.....http://dblp.org/pers/hd/m/Ma:Weidong", "Nenghai Yu.....http://dblp.org/pers/hd/y/Yu:Nenghai", "Tie-Yan Liu.....http://dblp.org/pers/hd/l/Liu:Tie=Yan"], "pages": 7}