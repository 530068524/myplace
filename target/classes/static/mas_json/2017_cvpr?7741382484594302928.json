{"title": "The VQA-Machine: Learning How to Use Existing Vision Algorithms to Answer New Questions.", "fields": ["exploit", "ground truth", "question answering", "turing machine", "tuple"], "abstract": "One of the most intriguing features of the Visual Question Answering (VQA) challenge is the unpredictability of the questions. Extracting the information required to answer them demands a variety of image operations from detection and counting, to segmentation and reconstruction. To train a method to perform even one of these operations accurately from {image, question, answer} tuples would be challenging, but to aim to achieve them all with a limited set of such training data seems ambitious at best. Our method thus learns how to exploit a set of external off-the-shelf algorithms to achieve its goal, an approach that has something in common with the Neural Turing Machine [10]. The core of our proposed method is a new co-attention model. In addition, the proposed approach generates human-readable reasons for its decision, and can still be trained end-to-end without ground truth reasons being given. We demonstrate the effectiveness on two publicly available datasets, Visual Genome and VQA, and show that it produces the state-of-the-art results in both cases.", "citation": "Citations (10)", "year": "2017", "departments": ["Northwestern University", "University of Adelaide", "University of Adelaide", "Australian Cent ...  QLD, Australia"], "conf": "cvpr", "authors": ["Peng Wang.....http://dblp.org/pers/hd/w/Wang_0015:Peng", "Qi Wu.....http://dblp.org/pers/hd/w/Wu:Qi", "Chunhua Shen.....http://dblp.org/pers/hd/s/Shen:Chunhua", "Anton van den Hengel.....http://dblp.org/pers/hd/h/Hengel:Anton_van_den"], "pages": 10}