{"title": "Adaptivity and Optimism: An Improved Exponentiated Gradient Algorithm.", "fields": ["open problem", "path length", "regret", "optimism", "matrix"], "abstract": "We present an adaptive variant of the exponentiated gradient algorithm. Leveraging the optimistic learning framework of Rakhlin & Sridharan (2012), we obtain regret bounds that in the learning from experts setting depend on the variance and path length of the best expert, improving on results by Hazan & Kale (2008) and Chiang et al. (2012), and resolving an open problem posed by Kale (2012). Our techniques naturally extend to matrix-valued loss functions, where we present an adaptive matrix exponentiated gradient algorithm. To obtain the optimal regret bound in the matrix case, we generalize the Follow-the-Regularized-Leader algorithm to vector-valued payoffs, which may be of independent interest.", "citation": "Citations (16)", "year": "2014", "departments": ["Stanford University", "Stanford University"], "conf": "icml", "authors": ["Jacob Steinhardt.....http://dblp.org/pers/hd/s/Steinhardt:Jacob", "Percy Liang.....http://dblp.org/pers/hd/l/Liang:Percy"], "pages": 9}