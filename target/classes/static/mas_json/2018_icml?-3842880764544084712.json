{"title": "Learning to Act in Decentralized Partially Observable MDPs.", "fields": ["restrict", "open problem", "maximization", "markov decision process", "local optimum"], "abstract": "We address a long-standing open problem of reinforcement learning in decentralized partially\nobservable Markov decision processes. Previous attempts focussed on different forms of generalized policy\niteration, which at best led to local optima. In this paper, we restrict attention to plans, which are simpler\nto store and update than policies.  We derive, under certain conditions, the first near-optimal cooperative\nmulti-agent reinforcement learning algorithm. To achieve significant scalability gains, we replace the greedy\nmaximization by mixed-integer linear programming.  Experiments show our approach can learn to act\nnear-optimally in many finite domains from the literature.", "citation": "Not cited", "departments": ["French Institute for Research in Computer Science and Automation"], "authors": ["Jilles Steeve Dibangoye.....http://dblp.org/pers/hd/d/Dibangoye:Jilles_Steeve", "Olivier Buffet.....http://dblp.org/pers/hd/b/Buffet:Olivier"], "conf": "icml", "year": "2018", "pages": 10}