{"title": "An interior-point stochastic approximation method and an L1-regularized delta rule.", "fields": ["interior point method", "stochastic optimization", "continuous time stochastic process", "stochastic approximation", "stochastic neural network"], "abstract": "The stochastic approximation method is behind the solution to many important, actively-studied problems in machine learning. Despite its far-reaching application, there is almost no work on applying stochastic approximation to learning problems with general constraints. The reason for this, we hypothesize, is that no robust, widely-applicable stochastic approximation method exists for handling such problems. We propose that interior-point methods are a natural solution. We establish the stability of a stochastic interior-point approximation method both analytically and empirically, and demonstrate its utility by deriving an on-line learning algorithm that also performs feature selection via L1 regularization.", "citation": "Citations (9)", "year": "2008", "departments": ["University of British Columbia", "University of British Columbia", "University of British Columbia"], "conf": "nips", "authors": ["Peter Carbonetto.....http://dblp.org/pers/hd/c/Carbonetto:Peter", "Mark W. Schmidt.....http://dblp.org/pers/hd/s/Schmidt:Mark_W=", "Nando de Freitas.....http://dblp.org/pers/hd/f/Freitas:Nando_de"], "pages": 8}