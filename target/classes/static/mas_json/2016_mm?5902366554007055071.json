{"title": "ConTagNet: Exploiting User Context for Image Tag Recommendation.", "fields": ["contextual image classification", "computer vision", "convolutional neural network", "artificial neural network", "machine learning"], "abstract": "In recent years, deep convolutional neural networks have shown great success in single-label image classification. However, images usually have multiple labels associated with them which may correspond to different objects or actions present in the image. In addition, a user assigns tags to a photo not merely based on the visual content but also the context in which the photo has been captured. Inspired by this, we propose a deep neural network which can predict multiple tags for an image based on the content as well as the context in which the image is captured. The proposed model can be trained end-to-end and solves a multi-label classification problem. We evaluate the model on a dataset of 1,965,232 images which is drawn from the YFCC100M dataset provided by the organizers of Yahoo-Flickr Grand Challenge. We observe a significant improvement in the prediction accuracy after integrating user-context and the proposed model performs very well in the Grand Challenge.", "citation": "Citations (11)", "departments": ["National University of Singapore", "National University of Singapore"], "authors": ["Yogesh Singh Rawat.....http://dblp.org/pers/hd/r/Rawat:Yogesh_Singh", "Mohan S. Kankanhalli.....http://dblp.org/pers/hd/k/Kankanhalli:Mohan_S="], "conf": "mm", "year": "2016", "pages": 5}