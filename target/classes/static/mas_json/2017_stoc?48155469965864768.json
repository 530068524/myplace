{"title": "Efficient quantum tomography II.", "fields": ["longest increasing subsequence", "bounded function", "robinson schensted knuth correspondence", "special case", "majorization"], "abstract": "We continue our analysis of: (i) \u00e2  Quantum tomography\u00e2  , i.e., learning a quantum state, i.e., the quantum generalization of learning a discrete probability distribution; (ii)\ufffd The distribution of Young diagrams output by the RSK algorithm on random words. Regarding\ufffd (ii), we introduce two powerful new tools: first, a precise upper bound on the expected length of the longest union of  k  disjoint increasing subsequences in a random length- n  word with letter distribution I\ufffd 1  \u00e2 \ufffd I\ufffd 2  \u00e2 \ufffd \u00e2 \ufffd \u00e2 \ufffd I\ufffd  d  . Our bound has the correct main term and second-order term, and holds for  all \ufffd  n , not just in the large- n  limit. Second, a new majorization property of the RSK algorithm that allows one to analyze the Young diagram formed by the  lower  rows I\ufffd  k  , I\ufffd  k +1 , \u00e2 \ufffd of its output. These tools allow us to prove several new theorems concerning the distribution of random Young diagrams in the  nonasymptotic  regime, giving concrete error bounds that are optimal, or nearly so, in all parameters. As one example, we give a fundamentally new proof of the celebrated fact that the expected length of the longest increasing sequence in a random length- n  permutation is bounded by 2\u00e2   n . This is the  k  = 1, I\ufffd  i   \u00e2 \ufffd 1/ d ,  d  \u00e2   \u00e2   special case of a much more general result we prove: the expected length of the  k th Young diagram row produced by an I\ufffd-random word is I\ufffd  k    n  \u00b1 2\u00e2  I\ufffd  k   d   n .   From our new analyses of random Young diagrams we derive several new results in quantum tomography, including: (i) learning the eigenvalues of an unknown state to N -accuracy in Hellinger-squared, chi-squared, or KL distance, using  n  =  O ( d  2 /N ) copies; (ii) learning the top- k  eigenvalues of an unknown state to N -accuracy in Hellinger-squared or chi-squared distance using  n  =  O ( kd /N ) copies or in \u00e2   2  2  distance using  n  =  O ( k /N ) copies; (iii) learning the optimal rank- k  approximation of an unknown state to N -fidelity (Hellinger-squared distance) using  n  =  O ( kd /N ) copies. We believe our new techniques will lead to further advances in quantum learning; indeed, they have already subsequently been used for efficient von Neumann entropy estimation.", "citation": "Citations (9)", "year": "2017", "departments": ["Carnegie Mellon University", "Massachusetts Institute of Technology"], "conf": "stoc", "authors": ["Ryan O'Donnell.....http://dblp.org/pers/hd/o/O=Donnell:Ryan", "John Wright.....http://dblp.org/pers/hd/w/Wright:John"], "pages": 13}