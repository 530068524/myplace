{"title": "Hierarchical Phrase Table Combination for Machine Translation.", "fields": ["bleu", "phrase", "overhead", "machine translation", "rule based machine translation"], "abstract": "Typical statistical machine translation systems are batch trained with a given training data and their performances are largely influenced by the amount of data. With the growth of the available data across different domains, it is computationally demanding to perform batch training every time when new data comes. In face of the problem, we propose an efficient phrase table combination method. In particular, we train a Bayesian phrasal inversion transduction grammars for each domain separately. The learned phrase tables are hierarchically combined as if they are drawn from a hierarchical Pitman-Yor process. The performance measured by BLEU is at least as comparable to the traditional batch training method. Furthermore, each phrase table is trained separately in each domain, and while computational overhead is significantly reduced by training them in parallel.", "citation": "Citations (2)", "year": "2013", "departments": ["Harbin Institute of Technology", "Harbin Institute of Technology", "National Institute of Information and Communications Technology", "National Institute of Information and Communications Technology"], "conf": "acl", "authors": ["Conghui Zhu.....http://dblp.org/pers/hd/z/Zhu:Conghui", "Taro Watanabe.....http://dblp.org/pers/hd/w/Watanabe:Taro", "Eiichiro Sumita.....http://dblp.org/pers/hd/s/Sumita:Eiichiro", "Tiejun Zhao.....http://dblp.org/pers/hd/z/Zhao:Tiejun"], "pages": 9}