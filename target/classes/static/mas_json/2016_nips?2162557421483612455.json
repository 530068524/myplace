{"title": "Local Minimax Complexity of Stochastic Convex Optimization.", "fields": ["minimax", "fisher information", "modulus of continuity", "curvature", "subgradient method"], "abstract": "We extend the traditional worst-case, minimax analysis of stochastic convex optimization by introducing a localized form of minimax complexity for individual functions. Our main result gives function-specific lower and upper bounds on the number of stochastic subgradient evaluations needed to optimize either the function or its ``hardest local alternative'' to a given numerical precision. The bounds are expressed in terms of a localized and computational analogue of the modulus of continuity that is central to statistical minimax analysis. We show how the computational modulus of continuity can be explicitly calculated in concrete cases, and relates to the curvature of the function at the optimum. We also prove a superefficiency result that demonstrates it is a meaningful benchmark, acting as a computational analogue of the Fisher information in statistical estimation. The nature and practical implications of the results are demonstrated in simulations.", "citation": "Citations (4)", "departments": ["University of Chicago", "University of Chicago", "University of Pennsylvania", "University of Chicago", "University of Pennsylvania"], "authors": ["Sabyasachi Chatterjee.....http://dblp.org/pers/hd/c/Chatterjee:Sabyasachi", "John C. Duchi.....http://dblp.org/pers/hd/d/Duchi:John_C=", "John D. Lafferty.....http://dblp.org/pers/hd/l/Lafferty:John_D=", "Yuancheng Zhu.....http://dblp.org/pers/hd/z/Zhu:Yuancheng"], "conf": "nips", "year": "2016", "pages": 9}