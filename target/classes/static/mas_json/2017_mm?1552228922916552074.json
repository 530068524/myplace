{"title": "Video Visual Relation Detection.", "fields": ["predicate", "artificial intelligence", "baseline", "video tracking", "computer vision"], "abstract": "As a bridge to connect vision and language, visual relations between objects in the form of relation triplet $langle subject,predicate,object\\rangle$, such as \"person-touch-dog'' and \"cat-above-sofa'', provide a more comprehensive visual content understanding beyond objects. In this paper, we propose a novel vision task named Video Visual Relation Detection (VidVRD) to perform visual relation detection in videos instead of still images (ImgVRD). As compared to still images, videos provide a more natural set of features for detecting visual relations, such as the dynamic relations like \"A-follow-B'' and \"A-towards-B'', and temporally changing relations like \"A-chase-B'' followed by \"A-hold-B''. However, VidVRD is technically more challenging than ImgVRD due to the difficulties in accurate object tracking and diverse relation appearances in video domain. To this end, we propose a VidVRD method, which consists of object tracklet proposal, short-term relation prediction and greedy relational association. Moreover, we contribute the first dataset for VidVRD evaluation, which contains 1,000 videos with manually labeled visual relations, to validate our proposed method. On this dataset, our method achieves the best performance in comparison with the state-of-the-art baselines.", "citation": "Citations (1)", "departments": ["National University of Singapore", "Nanjing University", "Nanjing University", "Columbia University", "National University of Singapore"], "authors": ["Xindi Shang.....http://dblp.org/pers/hd/s/Shang:Xindi", "Tongwei Ren.....http://dblp.org/pers/hd/r/Ren:Tongwei", "Jingfan Guo.....http://dblp.org/pers/hd/g/Guo:Jingfan", "Hanwang Zhang.....http://dblp.org/pers/hd/z/Zhang:Hanwang", "Tat-Seng Chua.....http://dblp.org/pers/hd/c/Chua:Tat=Seng"], "conf": "mm", "year": "2017", "pages": 9}