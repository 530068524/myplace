{"title": "Random Features for Sparse Signal Classification.", "fields": ["kernel", "inference", "random function", "similarity matrix", "curse of dimensionality"], "abstract": "Random features is an approach for kernel-based inference on large datasets. In this paper, we derive performance guarantees for random features on signals, like images, that enjoy sparse representations and show that the number of random features required to achieve a desired approximation of the kernel similarity matrix can be significantly smaller for sparse signals. Based on this, we propose a scheme termed compressive random features that first obtains low-dimensional projections of a dataset and, subsequently, derives random features on the low-dimensional projections. This scheme provides significant improvements in signal dimensionality, computational time, and storage costs over traditional random features while enjoying similar theoretical guarantees for achieving inference performance. We support our claims by providing empirical results across many datasets.", "citation": "Citations (1)", "year": "2016", "departments": ["Carnegie Mellon University", "Carnegie Mellon University", "Carnegie Mellon University"], "conf": "cvpr", "authors": ["Jen-Hao Rick Chang.....http://dblp.org/pers/hd/c/Chang:Jen=Hao_Rick", "Aswin C. Sankaranarayanan.....http://dblp.org/pers/hd/s/Sankaranarayanan:Aswin_C=", "B. V. K. Vijaya Kumar.....http://dblp.org/pers/hd/k/Kumar:B=_V=_K=_Vijaya"], "pages": 9}