{"title": "MIXGAN: Learning Concepts from Different Domains for Mixture Generation.", "fields": ["computer science", "generative grammar", "artificial intelligence", "template", "machine learning"], "abstract": "In this work, we present an interesting attempt on mixture generation: absorbing different image concepts (e.g., content and style) from different domains and thus generating a new domain with learned concepts. In particular, we propose a mixture generative adversarial network (MIXGAN). MIXGAN learns concepts of content and style from two domains respectively, and thus can join them for mixture generation in a new domain, i.e., generating images with content from one domain and style from another. MIXGAN overcomes the limitation of current GAN-based models which either generate new images in the same domain as they observed in training stage, or require off-the-shelf content templates for transferring or translation. Extensive experimental results demonstrate the effectiveness of MIXGAN as compared to related state-of-the-art GAN-based models.", "citation": "Not cited", "departments": ["Sun Yat-sen University", "Sun Yat-sen University", "Sun Yat-sen University", "Chinese Ministry of Education"], "authors": ["Guang-Yuan Hao.....http://dblp.org/pers/hd/h/Hao:Guang=Yuan", "Hong-Xing Yu.....http://dblp.org/pers/hd/y/Yu:Hong=Xing", "Wei-Shi Zheng.....http://dblp.org/pers/hd/z/Zheng:Wei=Shi"], "conf": "ijcai", "year": "2018", "pages": 8}