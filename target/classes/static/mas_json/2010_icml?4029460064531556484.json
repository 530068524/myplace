{"title": "Fast boosting using adversarial bandits.", "fields": ["boosting", "classifier", "adaboost", "decision problem", "adversarial system"], "abstract": "In this paper we apply multi-armed bandits (MABs) to improve the computational complexity of AdaBoost. AdaBoost constructs a strong classifier in a stepwise fashion by selecting simple base classifiers and using their weighted \"vote\" to determine the final classification. We model this stepwise base classifier selection as a sequential decision problem, and optimize it with MABs where each arm represents a subset of the base classifier set. The MAB gradually learns the \"usefulness\" of the subsets, and selects one of the subsets in each iteration. AdaBoost then searches only this subset instead of optimizing the base classifier over the whole space. The main improvement of this paper over a previous approach is that we use an adversarial bandit algorithm instead of stochastic bandits. This choice allows us to prove a weak-to-strong-learning theorem, which means that the proposed technique remains a boosting algorithm in a formal sense. We demonstrate on benchmark datasets that our technique can achieve a generalization performance similar to standard AdaBoost for a computational cost that is an order of magnitude smaller.", "citation": "Citations (28)", "departments": ["Hungarian Academy of Sciences", "University of Paris-Sud"], "authors": ["R\u00f3bert Busa-Fekete.....http://dblp.org/pers/hd/b/Busa=Fekete:R=oacute=bert", "Bal\u00e1zs K\u00e9gl.....http://dblp.org/pers/hd/k/K=eacute=gl:Bal=aacute=zs"], "conf": "icml", "year": "2010", "pages": 8}