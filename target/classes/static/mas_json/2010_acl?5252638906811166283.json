{"title": "Learning 5000 Relational Extractors.", "fields": ["training set", "lexicon", "information extraction", "f1 score", "supervised learning"], "abstract": "Many researchers are trying to use information extraction (IE) to create large-scale knowledge bases from natural language text on the Web. However, the primary approach (supervised learning of relation-specific extractors) requires manually-labeled training data for each relation and doesn't scale to the thousands of relations encoded in Web text.\n\nThis paper presents LUCHS, a self-supervised, relation-specific IE system which learns 5025 relations --- more than an order of magnitude greater than any previous approach --- with an average F1 score of 61%. Crucial to LUCHS's performance is an automated system for dynamic lexicon learning, which allows it to learn accurately from heuristically-generated training data, which is often noisy and sparse.", "citation": "Citations (149)", "year": "2010", "departments": ["University of Washington", "University of Washington", "University of Washington"], "conf": "acl", "authors": ["Raphael Hoffmann.....http://dblp.org/pers/hd/h/Hoffmann:Raphael", "Congle Zhang.....http://dblp.org/pers/hd/z/Zhang:Congle", "Daniel S. Weld.....http://dblp.org/pers/hd/w/Weld:Daniel_S="], "pages": 10}