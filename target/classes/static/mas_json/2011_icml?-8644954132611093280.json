{"title": "Classification-based Policy Iteration with a Critic.", "fields": ["mathematical optimization", "machine learning", "bellman equation", "truncate", "reinforcement learning"], "abstract": "In this paper, we study the effect of adding a value function approximation component (critic) to rollout classification-based policy iteration (RCPI) algorithms. The idea is to use a critic to approximate the return after we truncate the rollout trajectories. This allows us to control the bias and variance of the rollout estimates of the action-value function. Therefore, the introduction of a critic can improve the accuracy of the rollout estimates, and as a result, enhance the performance of the RCPI algorithm. We present a new RCPI algorithm, called direct policy iteration with critic (DPI-Critic), and provide its finite-sample analysis when the critic is based on the LSTD method. We empirically evaluate the performance of DPI-Critic and compare it with DPI and LSPI in two benchmark reinforcement learning problems.", "citation": "Citations (16)", "year": "2011", "departments": ["French Institute for Research in Computer Science and Automation", "French Institute for Research in Computer Science and Automation", "French Institute for Research in Computer Science and Automation", "French Institute for Research in Computer Science and Automation"], "conf": "icml", "authors": ["Victor Gabillon.....http://dblp.org/pers/hd/g/Gabillon:Victor", "Alessandro Lazaric.....http://dblp.org/pers/hd/l/Lazaric:Alessandro", "Mohammad Ghavamzadeh.....http://dblp.org/pers/hd/g/Ghavamzadeh:Mohammad", "Bruno Scherrer.....http://dblp.org/pers/hd/s/Scherrer:Bruno"], "pages": 8}