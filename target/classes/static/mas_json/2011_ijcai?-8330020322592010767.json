{"title": "Short Text Conceptualization Using a Probabilistic Knowledgebase.", "fields": ["co occurrence networks", "bag of words model", "topic model", "wordnet", "noisy text analytics"], "abstract": "Most text mining tasks, including clustering and topic detection, are based on statistical methods that treat text as bags of words. Semantics in the text is largely ignored in the mining process, and mining results often have low interpretability. One particular challenge faced by such approaches lies in short text understanding, as short texts lack enough content from which statistical conclusions can be drawn easily. In this paper, we improve text understanding by using a probabilistic knowledgebase that is as rich as our mental world in terms of the concepts (of worldly facts) it contains. We then develop a Bayesian inference mechanism to conceptualize words and short text. We conducted comprehensive experiments on conceptualizing textual terms, and clustering short pieces of text such as Twitter messages. Compared to purely statistical methods such as latent semantic topic modeling or methods that use existing knowledge-bases (e.g., WordNet, Freebase and Wikipedia), our approach brings significant improvements in short text understanding as reflected by the clustering accuracy.", "citation": "Citations (174)", "year": "2011", "departments": ["Microsoft", "Microsoft", "Microsoft", "Microsoft", "Microsoft"], "conf": "ijcai", "authors": ["Yangqiu Song.....http://dblp.org/pers/hd/s/Song:Yangqiu", "Haixun Wang.....http://dblp.org/pers/hd/w/Wang:Haixun", "Zhongyuan Wang.....http://dblp.org/pers/hd/w/Wang:Zhongyuan", "Hongsong Li.....http://dblp.org/pers/hd/l/Li:Hongsong", "Weizhu Chen.....http://dblp.org/pers/hd/c/Chen:Weizhu"], "pages": 7}