{"title": "Learning to Attend via Word-Aspect Associative Fusion for Aspect-Based Sentiment Analysis.", "fields": ["sentence", "circular convolution", "differentiable function", "associative property", "open problem"], "abstract": "Aspect-based sentiment analysis (ABSA) tries to predict the polarity of a given document with respect to a given aspect entity. While neural network architectures have been successful in predicting the overall polarity of sentences, aspect-specific sentiment analysis still remains as an open problem. In this paper, we propose a novel method for integrating aspect information into the neural model. More specifically, we incorporate aspect information into the neural model by modeling word-aspect relationships. Our novel model, \\textit{Aspect Fusion LSTM} (AF-LSTM) learns to attend based on associative relationships between sentence words and aspect which allows our model to adaptively focus on the correct words given an aspect term. This ameliorates the flaws of other state-of-the-art models that utilize naive concatenations to model word-aspect similarity. Instead, our model adopts circular convolution and circular correlation to model the similarity between aspect and words and elegantly incorporates this within a differentiable neural attention framework. Finally, our model is end-to-end differentiable and highly related to convolution-correlation (holographic like) memories. Our proposed neural model achieves state-of-the-art performance on benchmark datasets, outperforming ATAE-LSTM by $4\\%-5\\%$ on average across multiple datasets.", "citation": "Citations (3)", "departments": ["Nanyang Technological University", "Agency for Science, Technology and Research", "Nanyang Technological University"], "authors": ["Yi Tay.....http://dblp.org/pers/hd/t/Tay:Yi", "Luu Anh Tuan.....http://dblp.org/pers/hd/t/Tuan:Luu_Anh", "Siu Cheung Hui.....http://dblp.org/pers/hd/h/Hui:Siu_Cheung"], "conf": "aaai", "year": "2018", "pages": 8}