{"title": "Large-Scale Sparse Inverse Covariance Estimation via Thresholding and Max-Det Matrix Completion.", "fields": ["estimation of covariance matrices", "inverse", "cholesky decomposition", "matrix completion", "lasso"], "abstract": "The sparse inverse covariance estimation problem is commonly solved using an $\\ell_{1}$-regularized Gaussian maximum likelihood estimator known as \"graphical lasso\", but its computational cost becomes prohibitive for large data sets. A recent line of results showed--under mild assumptions--that the graphical lasso estimator can be retrieved by soft-thresholding the sample covariance matrix and solving a maximum determinant matrix completion (MDMC) problem. This paper proves an extension of this result, and describes a Newton-CG algorithm to efficiently solve the MDMC problem. Assuming that the thresholded sample covariance matrix is sparse with a sparse Cholesky factorization, we prove that the algorithm converges to an $\\epsilon$-accurate solution in $O(n\\log(1/\\epsilon))$ time and $O(n)$ memory. The algorithm is highly efficient in practice: we solve the associated MDMC problems with as many as 200,000 variables to 7-9 digits of accuracy in less than an hour on a standard laptop computer running MATLAB.", "citation": "Not cited", "departments": ["University of California, Berkeley", "University of California, Berkeley", "University of California, Berkeley"], "authors": ["Richard Y. Zhang.....http://dblp.org/pers/hd/z/Zhang:Richard_Y=", "Salar Fattahi.....http://dblp.org/pers/hd/f/Fattahi:Salar", "Somayeh Sojoudi.....http://dblp.org/pers/hd/s/Sojoudi:Somayeh"], "conf": "icml", "year": "2018", "pages": 10}