{"title": "A Variance Analysis for POMDP Policy Evaluation.", "fields": ["empirical modelling", "observable", "partially observable markov decision process", "bellman equation", "markov decision process"], "abstract": "Partially Observable Markov Decision Processes have been studied widely as a model for decision making under uncertainty, and a number of methods have been developed to find the solutions for such processes. Such studies often involve calculation of the value function of a specific policy, given a model of the transition and observation probabilities, and the reward. These models can be learned using labeled samples of on-policy trajectories. However, when using empirical models, some bias and variance terms are introduced into the value function as a result of imperfect models. In this paper, we propose a method for estimating the bias and variance of the value function in terms of the statistics of the empirical transition and observation model. Such error terms can be used to meaningfully compare the value of different policies. This is an important result for sequential decision-making, since it will allow us to provide more formal guarantees about the quality of the policies we implement. To evaluate the precision of the proposed method, we provide supporting experiments on problems from the field of robotics and medical decision making.", "citation": "Citations (8)", "departments": ["McGill University", "McGill University", "Duke University"], "authors": ["Mahdi Milani Fard.....http://dblp.org/pers/hd/f/Fard:Mahdi_Milani", "Joelle Pineau.....http://dblp.org/pers/hd/p/Pineau:Joelle", "Peng Sun.....http://dblp.org/pers/hd/s/Sun:Peng"], "conf": "aaai", "year": "2008", "pages": 6}