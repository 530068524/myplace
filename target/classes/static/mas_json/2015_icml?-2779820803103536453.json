{"title": "Learning Word Representations with Hierarchical Sparse Coding.", "fields": ["ranking", "regularization", "neural coding", "sentence completion tests", "syntax"], "abstract": "We propose a new method for learning word representations using hierarchical regularization in sparse coding inspired by the linguistic study of word meanings. We show an efficient learning algorithm based on stochastic proximal methods that is significantly faster than previous approaches, making it possible to perform hierarchical sparse coding on a corpus of billions of word tokens. Experiments on various benchmark tasks--word similarity ranking, syntactic and semantic analogies, sentence completion, and sentiment analysis--demonstrate that the method out-performs or is competitive with state-of-the-art methods.", "citation": "Citations (22)", "year": "2015", "departments": ["Carnegie Mellon University", "Carnegie Mellon University", "Carnegie Mellon University", "Carnegie Mellon University"], "conf": "icml", "authors": ["Dani Yogatama.....http://dblp.org/pers/hd/y/Yogatama:Dani", "Manaal Faruqui.....http://dblp.org/pers/hd/f/Faruqui:Manaal", "Chris Dyer.....http://dblp.org/pers/hd/d/Dyer:Chris", "Noah A. Smith.....http://dblp.org/pers/hd/s/Smith:Noah_A="], "pages": 10}