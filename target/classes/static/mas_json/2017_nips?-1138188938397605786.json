{"title": "Label Efficient Learning of Transferable Representations acrosss Domains and Tasks.", "fields": ["embedding", "semi supervised learning", "labeled data", "transfer of learning", "source data"], "abstract": "We propose a framework that learns a representation transferable across different domains and tasks in a data efficient manner. Our approach battles domain shift with a domain adversarial loss, and generalizes the embedding to novel task using a metric learning-based approach. Our model is simultaneously optimized on labeled source data and unlabeled or sparsely labeled data in the target domain. Our method shows compelling results on novel classes within a new domain even when only a few labeled examples per class are available, outperforming the prevalent fine-tuning approach. In addition, we demonstrate the effectiveness of our framework on the transfer learning task from image object recognition to video action recognition.", "citation": "Citations (5)", "year": "2017", "departments": ["Stanford University", "Virginia Tech", "University of California, Berkeley", "Stanford University"], "conf": "nips", "authors": ["Zelun Luo.....http://dblp.org/pers/hd/l/Luo:Zelun", "Yuliang Zou.....http://dblp.org/pers/hd/z/Zou:Yuliang", "Judy Hoffman.....http://dblp.org/pers/hd/h/Hoffman:Judy", "Fei-Fei Li.....http://dblp.org/pers/hd/l/Li:Fei=Fei"], "pages": 13}