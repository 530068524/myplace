{"title": "Markov Latent Feature Models.", "fields": ["feature model", "probabilistic latent semantic analysis", "latent class model", "neural coding", "inference"], "abstract": "We introduce Markov latent feature models (MLFM), a sparse latent feature model that arises naturally from a simple sequential construction. The key idea is to interpret each state of a sequential process as corresponding to a latent feature, and the set of states visited between two null-state visits as picking out features for an observation. We show that, given some natural constraints, we can represent this stochastic process as a mixture of recurrent Markov chains. In this way we can perform correlated latent feature modeling for the sparse coding problem. We demonstrate two cases in which we define finite and infinite latent feature models constructed from first-order Markov chains, and derive their associated scalable inference algorithms. We show empirical results on a genome analysis task and an image denoising task.", "citation": "Not cited", "year": "2016", "departments": ["Columbia University", "Columbia University"], "conf": "icml", "authors": ["Aonan Zhang.....http://dblp.org/pers/hd/z/Zhang:Aonan", "John Paisley.....http://dblp.org/pers/hd/p/Paisley:John"], "pages": 9}