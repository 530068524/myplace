{"title": "Inductive Regularized Learning of Kernel Functions.", "fields": ["variable kernel density estimation", "string kernel", "tree kernel", "kernel embedding of distributions", "graph kernel"], "abstract": "In this paper we consider the problem of semi-supervised kernel function learning. We first propose a general regularized framework for learning a kernel matrix, and then demonstrate an equivalence between our proposed kernel matrix learning framework and a general linear transformation learning problem. Our result shows that the learned kernel matrices parameterize a linear transformation kernel function and can be applied inductively to new data points. Furthermore, our result gives a constructive method for kernelizing most existing Mahalanobis metric learning formulations. To make our results practical for large-scale data, we modify our framework to limit the number of parameters in the optimization process. We also consider the problem of kernelized inductive dimensionality reduction in the semi-supervised setting. To this end, we introduce a novel method for this problem by considering a special case of our general kernel learning framework where we select the trace norm function as the regularizer. We empirically demonstrate that our framework learns useful kernel functions, improving the k-NN classification accuracy significantly in a variety of domains. Furthermore, our kernelized dimensionality reduction technique significantly reduces the dimensionality of the feature space while achieving competitive classification accuracies.", "citation": "Citations (31)", "departments": ["Microsoft", "University of California, Berkeley", "University of Texas at Austin"], "authors": ["Prateek Jain.....http://dblp.org/pers/hd/j/Jain_0002:Prateek", "Brian Kulis.....http://dblp.org/pers/hd/k/Kulis:Brian", "Inderjit S. Dhillon.....http://dblp.org/pers/hd/d/Dhillon:Inderjit_S="], "conf": "nips", "year": "2010", "pages": 9}