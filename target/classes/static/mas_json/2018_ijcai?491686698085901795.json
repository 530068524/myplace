{"title": "Curriculum Adversarial Training.", "fields": ["generative grammar", "cardiac surgery", "cardiothoracic surgery", "modalities", "deep learning", "curriculum", "mnist database", "specialty", "adversarial system", "forgetting", "authentication", "discriminator", "conformity"], "abstract": "Recently, deep learning has been applied to many security-sensitive applications, such as facial authentication. The existence of adversarial examples hinders such applications. The state-of-the-art result on defense shows that adversarial training can be applied to train a robust model on MNIST against adversarial examples; but it fails to achieve a high empirical worst-case accuracy on a more complex task, such as CIFAR-10 and SVHN. In our work, we propose curriculum adversarial training (CAT) to resolve this issue. The basic idea is to develop a curriculum of adversarial examples generated by attacks with a wide range of strengths. With two techniques to mitigate the forgetting and the generalization issues, we demonstrate that CAT can improve the prior art's empirical worst-case accuracy by a large margin of 25% on CIFAR-10 and 35% on SVHN. At the same, the model's performance on non-adversarial inputs is comparable to the state-of-the-art models.", "citation": "Not cited", "departments": ["Nanjing University", "University of California, Berkeley", "University of California, Berkeley", "Harvard University"], "authors": ["Qi-Zhi Cai.....http://dblp.org/pers/hd/c/Cai:Qi=Zhi", "Chang Liu.....http://dblp.org/pers/hd/l/Liu:Chang", "Dawn Song.....http://dblp.org/pers/hd/s/Song:Dawn"], "conf": "ijcai", "year": "2018", "pages": 8}