{"title": "Deep Multimodal Embedding Model for Fine-grained Sketch-based Image Retrieval.", "fields": ["image retrieval", "exploit", "sketch", "embedding", "information retrieval"], "abstract": "Fine-grained Sketch-based Image Retrieval (Fine-grained SBIR), which uses hand-drawn sketches to search the target object images, has been an emerging topic over the last few years. The difficulties of this task not only come from the ambiguous and abstract characteristics of sketches with less useful information, but also the cross-modal gap at both visual and semantic level. However, images on the web are always exhibited with multimodal contents. In this paper, we consider Fine-grained SBIR as a cross-modal retrieval problem and propose a deep multimodal embedding model that exploits all the beneficial multimodal information sources in sketches and images. In our experiment with large quantity of public data, we show that the proposed method outperforms the state-of-the-art methods for Fine-grained SBIR.", "citation": "Citations (1)", "departments": ["Fudan University", "Fudan University", "Fudan University", "Fudan University", "Shanghai University of Finance and Economics"], "authors": ["Fei Huang.....http://dblp.org/pers/hd/h/Huang:Fei", "Yong Cheng.....http://dblp.org/pers/hd/c/Cheng:Yong", "Cheng Jin.....http://dblp.org/pers/hd/j/Jin:Cheng", "Yuejie Zhang.....http://dblp.org/pers/hd/z/Zhang:Yuejie", "Tao Zhang.....http://dblp.org/pers/hd/z/Zhang_0022:Tao"], "conf": "sigir", "year": "2017", "pages": 4}