{"title": "DESPOT: Online POMDP Planning with Regularization.", "fields": ["observable", "curse", "partially observable markov decision process", "anytime algorithm", "curse of dimensionality"], "abstract": "POMDPs provide a principled framework for planning under uncertainty, but are computationally intractable, due to the \"curse of dimensionality\" and the \"curse of history\". This paper presents an online POMDP algorithm that alleviates these difficulties by focusing the search on a set of randomly sampled scenarios. A Determinized Sparse Partially Observable Tree (DESPOT) compactly captures the execution of all policies on these scenarios. Our Regularized DESPOT (R-DESPOT) algorithm searches the DESPOT for a policy, while optimally balancing the size of the policy and its estimated value obtained under the sampled scenarios. We give an output-sensitive performance bound for all policies derived from a DESPOT, and show that R-DESPOT works well if a small optimal policy exists. We also give an anytime algorithm that approximates R-DESPOT. Experiments show strong results, compared with two of the fastest online POMDP algorithms. Source code along with experimental settings are available at http://bigbird.comp.nus.edu.sg/pmwiki/farm/appl/.", "citation": "Citations (127)", "departments": ["National University of Singapore", "National University of Singapore", "National University of Singapore", "National University of Singapore"], "authors": ["Adhiraj Somani.....http://dblp.org/pers/hd/s/Somani:Adhiraj", "Nan Ye.....http://dblp.org/pers/hd/y/Ye:Nan", "David Hsu.....http://dblp.org/pers/hd/h/Hsu:David", "Wee Sun Lee.....http://dblp.org/pers/hd/l/Lee:Wee_Sun"], "conf": "nips", "year": "2013", "pages": 9}