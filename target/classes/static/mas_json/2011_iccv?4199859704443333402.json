{"title": "Annotator rationales for visual recognition.", "fields": ["attractiveness", "contextual image classification", "categorization", "visual learning", "region of interest"], "abstract": "Traditional supervised visual learning simply asks annotators \u201cwhat\u201d label an image should have. We propose an approach for image classification problems requiring subjective judgment that also asks \u201cwhy\u201d, and uses that information to enrich the learned model. We develop two forms of visual annotator rationales: in the first, the annotator highlights the spatial region of interest he found most influential to the label selected, and in the second, he comments on the visual attributes that were most important. For either case, we show how to map the response to synthetic contrast examples, and then exploit an existing large-margin learning technique to refine the decision boundary accordingly. Results on multiple scene categorization and human attractiveness tasks show the promise of our approach, which can more accurately learn complex categories with the explanations behind the label choices.", "citation": "Citations (38)", "year": "2011", "departments": ["University of Texas at Austin", "University of Texas at Austin"], "conf": "iccv", "authors": ["Jeff Donahue.....http://dblp.org/pers/hd/d/Donahue:Jeff", "Kristen Grauman.....http://dblp.org/pers/hd/g/Grauman:Kristen"], "pages": 8}