{"title": "Spatial coding for large scale partial-duplicate web image search.", "fields": ["image texture", "bag of words model", "visual word", "scale invariant feature transform", "automatic image annotation"], "abstract": "The state-of-the-art image retrieval approaches represent images with a high dimensional vector of visual words by quantizing local features, such as SIFT, in the descriptor space. The geometric clues among visual words in an image is usually ignored or exploited for full geometric verification, which is computationally expensive. In this paper, we focus on partial-duplicate web image retrieval, and propose a novel scheme, spatial coding, to encode the spatial relationships among local features in an image. Our spatial coding is both efficient and effective to discover false matches of local features between images, and can greatly improve retrieval performance. Experiments in partial-duplicate web image search, using a database of one million images, reveal that our approach achieves a 53% improvement in mean average precision and 46% reduction in time cost over the baseline bag-of-words approach.", "citation": "Citations (250)", "departments": ["University of Science and Technology of China", "Texas State University", "University of Science and Technology of China", "University of Science and Technology of China", "University of Texas at San Antonio"], "authors": ["Wengang Zhou.....http://dblp.org/pers/hd/z/Zhou:Wengang", "Yijuan Lu.....http://dblp.org/pers/hd/l/Lu:Yijuan", "Houqiang Li.....http://dblp.org/pers/hd/l/Li:Houqiang", "Yibing Song.....http://dblp.org/pers/hd/s/Song:Yibing", "Qi Tian.....http://dblp.org/pers/hd/t/Tian_0001:Qi"], "conf": "mm", "year": "2010", "pages": 10}