{"title": "Multiple-Play Bandits in the Position-Based Model.", "fields": ["upper and lower bounds", "exploit", "regret", "artificial intelligence", "machine learning"], "abstract": "Sequentially learning to place items in multi-position displays or lists is a task that can be cast into the multiple-play semi-bandit setting. However, a major concern in this context is when the system cannot decide whether the user feedback for each item is actually exploitable. Indeed, much of the content may have been simply ignored by the user. The present work proposes to exploit available information regarding the display position bias under the so-called Position-based click model (PBM). We first discuss how this model differs from the Cascade model and its variants considered in several recent works on multiple-play bandits. We then provide a novel regret lower bound for this model as well as computationally efficient algorithms that display good empirical and theoretical performance.", "citation": "Citations (6)", "departments": ["UP11, LRI", "LTCI", "LTCI"], "authors": ["Paul Lagr\u00e9e.....http://dblp.org/pers/hd/l/Lagr=eacute=e:Paul", "Claire Vernade.....http://dblp.org/pers/hd/v/Vernade:Claire", "Olivier Capp\u00e9.....http://dblp.org/pers/hd/c/Capp=eacute=:Olivier"], "conf": "nips", "year": "2016", "pages": 9}