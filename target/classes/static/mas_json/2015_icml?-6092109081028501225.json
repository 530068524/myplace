{"title": "High Confidence Policy Improvement.", "fields": ["confidence interval", "digital marketing", "probabilistic logic", "reinforcement learning", "machine learning"], "abstract": "We present a batch reinforcement learning (RL) algorithm that provides probabilistic guarantees about the quality of each policy that it proposes, and which has no hyper-parameters that require expert tuning. The user may select any performance lower-bound, \u03c1-, and confidence level, \u03b4, and our algorithm will ensure that the probability that it returns a policy with performance below \u03c1- is at most \u03b4. We then propose an incremental algorithm that executes our policy improvement algorithm repeatedly to generate multiple policy improvements. We show the viability of our approach with a simple gridworld and the standard mountain car problem, as well as with a digital marketing application that uses real world data.", "citation": "Citations (7)", "year": "2015", "departments": ["University of Massachusetts Amherst", "Adobe Systems", "Adobe Systems"], "conf": "icml", "authors": ["Philip S. Thomas.....http://dblp.org/pers/hd/t/Thomas:Philip_S=", "Georgios Theocharous.....http://dblp.org/pers/hd/t/Theocharous:Georgios", "Mohammad Ghavamzadeh.....http://dblp.org/pers/hd/g/Ghavamzadeh:Mohammad"], "pages": 9}