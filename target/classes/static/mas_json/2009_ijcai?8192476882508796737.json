{"title": "Monte-Carlo Exploration for Deterministic Planning.", "fields": ["action selection", "forward chaining", "random walk", "local search", "general game playing"], "abstract": "Search methods based on Monte-Carlo simulation have recently led to breakthrough performance improvements in difficult game-playing domains such as Go and General Game Playing. Monte-Carlo Random Walk (MRW) planning applies Monte-Carlo ideas to deterministic classical planning. In the forward chaining planner ARVAND, Monte-Carlo random walks are used to explore the local neighborhood of a search state for action selection. In contrast to the stochastic local search approach used in the recent planner Identidem, random walks yield a larger and unbiased sample of the search neighborhood, and require state evaluations only at the endpoints of each walk. On IPC-4 competition problems, the performance of ARVAND is competitive with state of the art systems.", "citation": "Citations (105)", "departments": ["University of Alberta", "University of Alberta"], "authors": ["Hootan Nakhost.....http://dblp.org/pers/hd/n/Nakhost:Hootan", "Martin M\u00fcller.....http://dblp.org/pers/hd/m/M=uuml=ller_0003:Martin"], "conf": "ijcai", "year": "2009", "pages": 6}