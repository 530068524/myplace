{"title": "Metric embedding for kernel classification rules.", "fields": ["chebyshev distance", "variable kernel density estimation", "kernel embedding of distributions", "large margin nearest neighbor", "fisher information metric"], "abstract": "In this paper, we consider a smoothing kernel based classification rule and propose an algorithm for optimizing the performance of the rule by learning the bandwidth of the smoothing kernel along with a data-dependent distance metric. The data-dependent distance metric is obtained by learning a function that embeds an arbitrary metric space into a Euclidean space while minimizing an upper bound on the resubstitution estimate of the error probability of the kernel classification rule. By restricting this embedding function to a reproducing kernel Hilbert space, we reduce the problem to solving a semidefinite program and show the resulting kernel classification rule to be a variation of the  k -nearest neighbor rule. We compare the performance of the kernel rule (using the learned data-dependent distance metric) to state-of-the-art distance metric learning algorithms (designed for  k -nearest neighbor classification) on some benchmark datasets. The results show that the proposed rule has either better or as good classification accuracy as the other metric learning algorithms.", "citation": "Citations (6)", "year": "2008", "departments": ["University of California, San Diego", "University of California, San Diego", "University of California, San Diego"], "conf": "icml", "authors": ["Bharath K. Sriperumbudur.....http://dblp.org/pers/hd/s/Sriperumbudur:Bharath_K=", "Omer A. Lang.....http://dblp.org/pers/hd/l/Lang:Omer_A=", "Gert R. G. Lanckriet.....http://dblp.org/pers/hd/l/Lanckriet:Gert_R=_G="], "pages": 8}