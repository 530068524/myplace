{"title": "Multimodal Video Description.", "fields": ["encoding", "exploit", "natural language", "multimedia", "modalities"], "abstract": "Real-world web videos often contain cues to supplement visual information for generating natural language descriptions. In this paper we propose a sequence-to-sequence model which explores such auxiliary information. In particular, audio and the topic of the video are used in addition to the visual information in a multimodal framework to generate coherent descriptions of videos \"in the wild\". In contrast to current encoder-decoder based models which exploit visual information only during the encoding stage, our model fuses multiple sources of information judiciously, showing improvement over using the different modalities separately. We based our multimodal video description network on the state-of-the-art sequence to sequence video to text (S2VT) model and extended it to take advantage of multiple modalities. Extensive experiments on the challenging MSR-VTT dataset are carried out to show the superior performance of the proposed approach on natural videos found in the web.", "citation": "Citations (22)", "departments": ["University of Massachusetts Lowell", "University of Massachusetts Lowell", "University of California, Berkeley", "University of Texas at Austin", "University of California, Berkeley"], "authors": ["Vasili Ramanishka.....http://dblp.org/pers/hd/r/Ramanishka:Vasili", "Abir Das.....http://dblp.org/pers/hd/d/Das:Abir", "Dong Huk Park.....http://dblp.org/pers/hd/p/Park:Dong_Huk", "Subhashini Venugopalan.....http://dblp.org/pers/hd/v/Venugopalan:Subhashini", "Lisa Anne Hendricks.....http://dblp.org/pers/hd/h/Hendricks:Lisa_Anne", "Marcus Rohrbach.....http://dblp.org/pers/hd/r/Rohrbach:Marcus", "Kate Saenko.....http://dblp.org/pers/hd/s/Saenko:Kate"], "conf": "mm", "year": "2016", "pages": 5}