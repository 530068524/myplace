{"title": "Single image depth estimation from predicted semantic labels.", "fields": ["image segmentation", "semantics", "pixel", "3d reconstruction", "monocular"], "abstract": "We consider the problem of estimating the depth of each pixel in a scene from a single monocular image. Unlike traditional approaches [18, 19], which attempt to map from appearance features to depth directly, we first perform a semantic segmentation of the scene and use the semantic labels to guide the 3D reconstruction. This approach provides several advantages: By knowing the semantic class of a pixel or region, depth and geometry constraints can be easily enforced (e.g., \u201csky\u201d is far away and \u201cground\u201d is horizontal). In addition, depth can be more readily predicted by measuring the difference in appearance with respect to a given semantic class. For example, a tree will have more uniform appearance in the distance than it does close up. Finally, the incorporation of semantic features allows us to achieve state-of-the-art results with a significantly simpler model than previous works.", "citation": "Citations (309)", "year": "2010", "departments": ["Stanford University", "Stanford University", "Stanford University"], "conf": "cvpr", "authors": ["Beyang Liu.....http://dblp.org/pers/hd/l/Liu:Beyang", "Stephen Gould.....http://dblp.org/pers/hd/g/Gould:Stephen", "Daphne Koller.....http://dblp.org/pers/hd/k/Koller:Daphne"], "pages": 8}