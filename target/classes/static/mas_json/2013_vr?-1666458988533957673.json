{"title": "Navigation in a virtual environment by dichotic listening: Simultaneous audio cues for user-directed BCI classification.", "fields": ["dichotic listening", "virtual machine", "motor imagery", "brain computer interface", "oddball paradigm"], "abstract": "Our research is focused on the initial exploration of training a Brain Computer Interface (BCI) by using audio cues to navigate a virtual environment, instead of motor imagery. We have designed our BCI training and navigation to use audio cues that adhere to the dichotic listening (DL) mechanism so that users have an active choice for interaction or giving commands. We have implemented our Dichotic Listening BCI in a Virtual Environment so that it can be used to train users to apply those skills for a BCI to control a real-world assisted locomotive device or to simply navigate within the virtual environment. We hypothesized that the lateralization of the brain's response to music and speech will enhance the classification of a BCI. Unlike previous attempts in using the oddball paradigm, our results show that audio cues can be used simultaneously to elicit distinct EEG signals for BCI while still enabling an active choice for the user. We evaluated users' performance to actively input navigation tasks. Dichotic Listening BCI performs slightly better than Motor Imagery based BCI.", "citation": "Citations (1)", "departments": ["University of Wyoming", "University of Wyoming"], "authors": ["Ashish Dhital.....http://dblp.org/pers/hd/d/Dhital:Ashish", "Amy Ulinski Banic.....http://dblp.org/pers/hd/b/Banic:Amy_Ulinski"], "conf": "vr", "year": "2013", "pages": 2}