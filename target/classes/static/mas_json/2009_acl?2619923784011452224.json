{"title": "Capturing Salience with a Trainable Cache Model for Zero-anaphora Resolution.", "fields": ["machine learning", "cache", "salience", "artificial intelligence", "natural language processing"], "abstract": "This paper explores how to apply the notion of caching introduced by Walker (1996) to the task of zero-anaphora resolution. We propose a machine learning-based implementation of a cache model to reduce the computational cost of identifying an antecedent. Our empirical evaluation with Japanese newspaper articles shows that the number of candidate antecedents for each zero-pronoun can be dramatically reduced while preserving the accuracy of resolving it.", "citation": "Citations (10)", "year": "2009", "departments": ["Tokyo Institute of Technology", "Nara Institute of Science and Technology", "Nara Institute of Science and Technology"], "conf": "acl", "authors": ["Ryu Iida.....http://dblp.org/pers/hd/i/Iida:Ryu", "Kentaro Inui.....http://dblp.org/pers/hd/i/Inui:Kentaro", "Yuji Matsumoto.....http://dblp.org/pers/hd/m/Matsumoto_0001:Yuji"], "pages": 9}