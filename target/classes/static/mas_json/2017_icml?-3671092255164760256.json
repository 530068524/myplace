{"title": "Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability.", "fields": ["observability", "viewpoints", "reinforcement learning", "artificial intelligence", "machine learning"], "abstract": "Many real-world tasks involve multiple agents with partial observability and limited communication. Learning is challenging in these settings due to local viewpoints of agents, which perceive the world as non-stationary due to concurrently-exploring teammates. Approaches that learn specialized policies for individual tasks face problems when applied to the real world: not only do agents have to learn and store distinct policies for each task, but in practice identities of tasks are often non-observable, making these approaches inapplicable. This paper formalizes and addresses the problem of multi-task multi-agent reinforcement learning under partial observability. We introduce a decentralized single-task learning approach that is robust to concurrent interactions of teammates, and present an approach for distilling single-task policies into a unified policy that performs well across multiple related tasks, without explicit provision of task identity.", "citation": "Citations (15)", "year": "2017", "departments": ["Massachusetts Institute of Technology", "Duke University", "Northeastern University", "Massachusetts Institute of Technology", "Boeing Phantom Works"], "conf": "icml", "authors": ["Shayegan Omidshafiei.....http://dblp.org/pers/hd/o/Omidshafiei:Shayegan", "Jason Pazis.....http://dblp.org/pers/hd/p/Pazis:Jason", "Christopher Amato.....http://dblp.org/pers/hd/a/Amato:Christopher", "Jonathan P. How.....http://dblp.org/pers/hd/h/How:Jonathan_P=", "John Vian.....http://dblp.org/pers/hd/v/Vian:John"], "pages": 10}