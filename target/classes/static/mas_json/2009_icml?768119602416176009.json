{"title": "Boosting with structural sparsity.", "fields": ["coordinate descent", "regularization", "adaboost", "generalization", "boosting"], "abstract": "We derive generalizations of AdaBoost and related gradient-based coordinate descent methods that incorporate sparsity-promoting penalties for the norm of the predictor that is being learned. The end result is a family of coordinate descent algorithms that integrate forward feature induction and back-pruning through regularization and give an automatic stopping criterion for feature induction. We study penalties based on the  l  1 ,  l  2 , and  l \u221e norms of the predictor and introduce mixed-norm penalties that build upon the initial penalties. The mixed-norm regularizers facilitate structural sparsity in parameter space, which is a useful property in multiclass prediction and other related tasks. We report empirical results that demonstrate the power of our approach in building accurate and structurally sparse models.", "citation": "Citations (101)", "departments": ["University of California, Berkeley", "Google"], "authors": ["John C. Duchi.....http://dblp.org/pers/hd/d/Duchi:John_C=", "Yoram Singer.....http://dblp.org/pers/hd/s/Singer:Yoram"], "conf": "icml", "year": "2009", "pages": 8}