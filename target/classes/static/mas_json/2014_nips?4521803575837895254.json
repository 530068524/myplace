{"title": "Communication-Efficient Distributed Dual Coordinate Ascent.", "fields": ["implementation", "rate of convergence", "spark", "bottleneck", "computation"], "abstract": "Communication remains the most significant bottleneck in the performance of distributed optimization algorithms for large-scale machine learning. In this paper, we propose a communication-efficient framework, COCOA, that uses local computation in a primal-dual setting to dramatically reduce the amount of necessary communication. We provide a strong convergence rate analysis for this class of algorithms, as well as experiments on real-world distributed datasets with implementations in Spark. In our experiments, we find that as compared to state-of-the-art mini-batch versions of SGD and SDCA algorithms, COCOA converges to the same .001-accurate solution quality on average 25 \u00d7 as quickly.", "citation": "Citations (171)", "year": "2014", "departments": ["ETH Zurich", "University of California, Berkeley", "Lehigh University", "University of California, Berkeley", "University of California, Berkeley"], "conf": "nips", "authors": ["Martin Jaggi.....http://dblp.org/pers/hd/j/Jaggi:Martin", "Virginia Smith.....http://dblp.org/pers/hd/s/Smith:Virginia", "Martin Tak\u00e1c.....http://dblp.org/pers/hd/t/Tak=aacute=c:Martin", "Jonathan Terhorst.....http://dblp.org/pers/hd/t/Terhorst:Jonathan", "Sanjay Krishnan.....http://dblp.org/pers/hd/k/Krishnan:Sanjay", "Thomas Hofmann.....http://dblp.org/pers/hd/h/Hofmann:Thomas", "Michael I. Jordan.....http://dblp.org/pers/hd/j/Jordan:Michael_I="], "pages": 9}