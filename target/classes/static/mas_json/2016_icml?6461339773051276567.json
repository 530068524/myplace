{"title": "Group Equivariant Convolutional Networks.", "fields": ["convolutional neural network", "equivariant map", "sample complexity", "mnist database", "overhead"], "abstract": "We introduce Group equivariant Convolutional Neural Networks (G-CNNs), a natural generalization of convolutional neural networks that reduces sample complexity by exploiting symmetries. G-CNNs use G-convolutions, a new type of layer that enjoys a substantially higher degree of weight sharing than regular convolution layers. G-convolutions increase the expressive capacity of the network without increasing the number of parameters. Group convolution layers are easy to use and can be implemented with negligible computational overhead for discrete groups generated by translations, reflections and rotations. G-CNNs achieve state of the art results on CI- FAR10 and rotated MNIST.", "citation": "Citations (115)", "year": "2016", "departments": ["University of Amsterdam", "Canadian Institute for Advanced Research"], "conf": "icml", "authors": ["Taco Cohen.....http://dblp.org/pers/hd/c/Cohen:Taco", "Max Welling.....http://dblp.org/pers/hd/w/Welling:Max"], "pages": 10}