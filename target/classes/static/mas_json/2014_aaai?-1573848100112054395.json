{"title": "Encoding Tree Sparsity in Multi-Task Learning: A Probabilistic Framework.", "fields": ["restrict", "cauchy distribution", "probabilistic logic", "gaussian", "multi task learning"], "abstract": "Multi-task learning seeks to improve the generalization performance by sharing common information among multiple related tasks. A key assumption in most MTL algorithms is that all tasks are related, which, however, may not hold in many real-world applications. Existing techniques, which attempt to address this issue, aim to identify groups of related tasks using group sparsity. In this paper, we propose a probabilistic tree sparsity (PTS) model to utilize the tree structure to obtain the sparse solution instead of the group structure. Specifically, each model coefficient in the learning model is decomposed into a product of multiple component coefficients each of which corresponds to a node in the tree. Based on the decomposition, Gaussian and Cauchy distributions are placed on the component coefficients as priors to restrict the model complexity. We devise an efficient expectation maximization algorithm to learn the model parameters. Experiments conducted on both synthetic and real-world problems show the effectiveness of our model compared with state-of-the-art baselines.", "citation": "Citations (5)", "departments": ["Peking University", "Hong Kong Baptist University", "Peking University", "Peking University"], "authors": ["Lei Han.....http://dblp.org/pers/hd/h/Han_0001:Lei", "Yu Zhang.....http://dblp.org/pers/hd/z/Zhang_0006:Yu", "Guojie Song.....http://dblp.org/pers/hd/s/Song:Guojie", "Kunqing Xie.....http://dblp.org/pers/hd/x/Xie:Kunqing"], "conf": "aaai", "year": "2014", "pages": 7}