{"title": "Semi-supervised Learning using Sparse Eigenfunction Bases.", "fields": ["kernel principal component analysis", "semi supervised learning", "sparse approximation", "eigenfunction", "lasso"], "abstract": "We present a new framework for semi-supervised learning with sparse eigenfunction bases of kernel matrices. It turns out that when the cluster assumption holds, that is, when the high density regions are suf\ufb01ciently separated by low density valleys, each high density area corresponds to a unique representative eigenvector. Linear combination of such eigenvectors (or, more precisely, of their Nystrom extensions) provide good candidates for good classi\ufb01cation functions. By \ufb01rst choosing an appropriate basis of these eigenvectors from unlabeled data and then using labeled data with Lasso to select a classi\ufb01er in the span of these eigenvectors, we obtain a classi\ufb01er, which has a very sparse representation in this basis. Importantly, the sparsity appears naturally from the cluster assumption. Experimental results on a number of real-world datasets show that our method is competitive with the state of the art semi-supervised learning algorithms and out-performs the natural base-line algorithm (Lasso in the Kernel PCA basis).", "citation": "Not cited", "year": "2009", "departments": ["Ohio State University", "Ohio State University", "Ohio State University", "Ohio State University"], "conf": "nips", "authors": ["Kaushik Sinha.....http://dblp.org/pers/hd/s/Sinha:Kaushik", "Mikhail Belkin.....http://dblp.org/pers/hd/b/Belkin:Mikhail"], "pages": 9}