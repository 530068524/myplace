{"title": "On the Sample Complexity of Reinforcement Learning with a Generative Model .", "fields": ["sample complexity", "reinforcement learning", "generative model", "markov decision process", "bellman equation"], "abstract": "We consider the problem of learning the optimal action-value function in the discounted-reward Markov decision processes (MDPs). We prove a new PAC bound on the sample-complexity of model-based value iteration algorithm in the presence of the generative model, which indicates that for an MDP with N state-action pairs and the discount factor \u03b3 \u2208 [0, 1) only O(N log(N/\u03b4)/(1 - \u03b3)3e2)) samples are required to find an e-optimal estimation of the action-value function with the probability 1 - \u03b4. We also prove a matching lower bound of \u0398(N log(N/\u03b4)/((1 - \u03b3)3e2)) on the sample complexity of estimating the optimal action-value function by every RL algorithm. To the best of our knowledge, this is the first matching result on the sample complexity of estimating the optimal (action-) value function in which the upper bound matches the lower bound of RL in terms of N, e, \u03b4 and 1/(1-\u03b3). Also, both our lower bound and our upper bound significantly improve on the state-of-the-art in terms of 1/(1 - \u03b3).", "citation": "Citations (16)", "departments": ["Radboud University Nijmegen", "Radboud University Nijmegen", "French Institute for Research in Computer Science and Automation"], "authors": ["Mohammad Gheshlaghi Azar.....http://dblp.org/pers/hd/a/Azar:Mohammad_Gheshlaghi", "R\u00e9mi Munos.....http://dblp.org/pers/hd/m/Munos:R=eacute=mi", "Bert Kappen.....http://dblp.org/pers/hd/k/Kappen:Bert"], "conf": "icml", "year": "2012", "pages": -1}