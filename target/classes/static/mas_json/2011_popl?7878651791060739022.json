{"title": "Learning minimal abstractions.", "fields": ["pointer", "abstract interpretation", "allocation site", "abstraction", "abstract machine"], "abstract": "Static analyses are generally parametrized by an abstraction which is chosen from a family of abstractions. We are interested in flexible families of abstractions with many parameters, as these families can allow one to increase precision in ways tailored to the client without sacrificing scalability. For example, we consider k-limited points-to analyses where each call site and allocation site in a program can have a different k value. We then ask a natural question in this paper: What is the minimal (coarsest) abstraction in a given family which is able to prove a set of queries? In addressing this question, we make the following two contributions: (i) We introduce two machine learning algorithms for efficiently finding a minimal abstraction; and (ii) for a static race detector backed by a k-limited points-to analysis, we show empirically that minimal abstractions are actually quite coarse: It suffices to provide context/object sensitivity to a very small fraction (0.4-2.3%) of the sites to yield equally precise results as providing context/object sensitivity uniformly to all sites.", "citation": "Citations (22)", "departments": ["University of California, Berkeley", "Tel Aviv University", "University of California, Berkeley"], "authors": ["Percy Liang.....http://dblp.org/pers/hd/l/Liang:Percy", "Omer Tripp.....http://dblp.org/pers/hd/t/Tripp:Omer", "Mayur Naik.....http://dblp.org/pers/hd/n/Naik:Mayur"], "conf": "popl", "year": "2011", "pages": 12}