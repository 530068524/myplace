{"title": "A Better Way to Pretrain Deep Boltzmann Machines.", "fields": ["deep belief network", "machine learning", "mnist database", "artificial intelligence", "boltzmann constant"], "abstract": "We describe how the pretraining algorithm for Deep Boltzmann Machines (DBMs) is related to the pretraining algorithm for Deep Belief Networks and we show that under certain conditions, the pretraining procedure improves the variational lower bound of a two-hidden-layer DBM. Based on this analysis, we develop a different method of pretraining DBMs that distributes the modelling work more evenly over the hidden layers. Our results on the MNIST and NORB datasets demonstrate that the new pretraining algorithm allows us to learn better generative models.", "citation": "Citations (86)", "departments": ["University of Toronto", "University of Toronto"], "authors": ["Ruslan Salakhutdinov.....http://dblp.org/pers/hd/s/Salakhutdinov:Ruslan", "Geoffrey E. Hinton.....http://dblp.org/pers/hd/h/Hinton:Geoffrey_E="], "conf": "nips", "year": "2012", "pages": 9}