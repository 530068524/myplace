{"title": "Mind the Duality Gap: Logarithmic regret algorithms for online optimization.", "fields": ["proximal gradient methods", "random coordinate descent", "proper convex function", "stochastic gradient descent", "frank wolfe algorithm"], "abstract": "We describe a primal-dual framework for the design and analysis of online strongly convex optimization algorithms. Our framework yields the tightest known logarithmic regret bounds for Follow-The-Leader and for the gradient descent algorithm proposed in Hazan et al. [2006]. We then show that one can interpolate between these two extreme cases. In particular, we derive a new algorithm that shares the computational simplicity of gradient descent but achieves lower regret in many practical situations. Finally, we further extend our framework for generalized strongly convex functions.", "citation": "Citations (95)", "year": "2008", "departments": ["Toyota Technological Institute at Chicago", "Toyota Technological Institute at Chicago"], "conf": "nips", "authors": ["Shai Shalev-Shwartz.....http://dblp.org/pers/hd/s/Shalev=Shwartz:Shai", "Sham M. Kakade.....http://dblp.org/pers/hd/k/Kakade:Sham_M="], "pages": 8}