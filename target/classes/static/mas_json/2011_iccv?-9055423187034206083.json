{"title": "Actively selecting annotations among objects and attributes.", "fields": ["exploit", "passive learning", "discriminative model", "active learning", "automatic image annotation"], "abstract": "We present an active learning approach to choose image annotation requests among both object category labels and the objects' attribute labels. The goal is to solicit those labels that will best use human effort when training a multi-class object recognition model. In contrast to previous work in active visual category learning, our approach directly exploits the dependencies between human-nameable visual attributes and the objects they describe, shifting its requests in either label space accordingly. We adopt a discriminative latent model that captures object-attribute and attribute-attribute relationships, and then define a suitable entropy reduction selection criterion to predict the influence a new label might have throughout those connections. On three challenging datasets, we demonstrate that the method can more successfully accelerate object learning relative to both passive learning and traditional active learning approaches.", "citation": "Citations (71)", "year": "2011", "departments": ["University of Texas at Austin", "University of Texas at Austin", "University of Texas at Austin"], "conf": "iccv", "authors": ["Adriana Kovashka.....http://dblp.org/pers/hd/k/Kovashka:Adriana", "Sudheendra Vijayanarasimhan.....http://dblp.org/pers/hd/v/Vijayanarasimhan:Sudheendra", "Kristen Grauman.....http://dblp.org/pers/hd/g/Grauman:Kristen"], "pages": 8}