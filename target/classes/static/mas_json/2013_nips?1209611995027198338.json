{"title": "Reservoir Boosting : Between Online and Offline Ensemble Learning.", "fields": ["ensemble learning", "online and offline", "machine learning", "expectation maximization algorithm", "boosting"], "abstract": "We propose to train an ensemble with the help of a reservoir in which the learning algorithm can store a limited number of samples.\n\nThis novel approach lies in the area between offline and online ensemble approaches and can be seen either as a restriction of the former or an enhancement of the latter. We identify some basic strategies that can be used to populate this reservoir and present our main contribution, dubbed Greedy Edge Expectation Maximization (GEEM), that maintains the reservoir content in the case of Boosting by viewing the samples through their projections into the weak classifier response space. We propose an efficient algorithmic implementation which makes it tractable in practice, and demonstrate its efficiency experimentally on several compute-vision data-sets, on which it outperforms both online and offline methods in a memory constrained setting.", "citation": "Not cited", "departments": ["Idiap Research Institute", "Idiap Research Institute"], "authors": ["Leonidas Lefakis.....http://dblp.org/pers/hd/l/Lefakis:Leonidas", "Fran\u00e7ois Fleuret.....http://dblp.org/pers/hd/f/Fleuret:Fran=ccedil=ois"], "conf": "nips", "year": "2013", "pages": 9}