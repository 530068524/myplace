{"title": "Holistic 3D scene understanding from a single geo-tagged image.", "fields": ["rendering", "object detection", "pose", "solid modeling", "semantics"], "abstract": "In this paper we are interested in exploiting geographic priors to help outdoor scene understanding. Towards this goal we propose a holistic approach that reasons jointly about 3D object detection, pose estimation, semantic segmentation as well as depth reconstruction from a single image. Our approach takes advantage of large-scale crowd-sourced maps to generate dense geographic, geometric and semantic priors by rendering the 3D world. We demonstrate the effectiveness of our holistic model on the challenging KITTI dataset [13], and show significant improvements over the baselines in all metrics and tasks.", "citation": "Citations (33)", "year": "2015", "departments": ["University of Toronto", "University of Toronto", "University of Toronto"], "conf": "cvpr", "authors": ["Shenlong Wang.....http://dblp.org/pers/hd/w/Wang:Shenlong", "Sanja Fidler.....http://dblp.org/pers/hd/f/Fidler:Sanja", "Raquel Urtasun.....http://dblp.org/pers/hd/u/Urtasun:Raquel"], "pages": 9}