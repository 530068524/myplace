{"title": "Predicting Polarities of Tweets by Composing Word Embeddings with Long Short-Term Memory.", "fields": ["long short term memory", "special functions", "test set", "negation", "phrase"], "abstract": "In this paper, we introduce Long ShortTerm Memory (LSTM) recurrent network for twitter sentiment prediction. With the help of gates and constant error carousels in the memory block structure, the model could handle interactions between words through a flexible compositional function. Experiments on a public noisy labelled data show that our model outperforms several feature-engineering approaches, with the result comparable to the current best data-driven technique. According to the evaluation on a generated negation phrase test set, the proposed architecture doubles the performance of non-neural model based on bag-of-word features. Furthermore, words with special functions (such as negation and transition) are distinguished and the dissimilarities of words with opposite sentiment are magnified. An interesting case study on negation expression processing shows a promising potential of the architecture dealing with complex sentiment phrases.", "citation": "Citations (56)", "year": "2015", "departments": ["Harbin Institute of Technology", "Harbin Institute of Technology", "Harbin Institute of Technology", "Harbin Institute of Technology", "Microsoft"], "conf": "acl", "authors": ["Xin Wang.....http://dblp.org/pers/hd/w/Wang_0017:Xin", "Yuanchao Liu.....http://dblp.org/pers/hd/l/Liu:Yuanchao", "Chengjie Sun.....http://dblp.org/pers/hd/s/Sun:Chengjie", "Baoxun Wang.....http://dblp.org/pers/hd/w/Wang:Baoxun", "Xiaolong Wang.....http://dblp.org/pers/hd/w/Wang_0003:Xiaolong"], "pages": 11}