{"title": "Combining Speech and Sketch to Interpret Unconstrained Descriptions of Mechanical Devices.", "fields": ["sketch", "sketch recognition", "classifier", "gesture", "modalities"], "abstract": "Mechanical design tools would be considerably more useful if we could interact with them in the way that human designers communicate design ideas to one another, i.e., using crude sketches and informal speech. Those crude sketches frequently contain pen strokes of two different sorts, one type portraying device structure, the other denoting gestures, such as arrows used to indicate motion. We report here on techniques we developed that use information from both sketch and speech to distinguish gesture strokes from non-gestures -- a critical first step in understanding a sketch of a device. We collected and analyzed unconstrained device descriptions, which revealed six common types of gestures. Guided by this knowledge, we developed a classifier that uses both sketch and speech features to distinguish gesture strokes from nongestures. Experiments with our techniques indicate that the sketch and speech modalities alone produce equivalent classification accuracy, but combining them produces higher accuracy.", "citation": "Citations (10)", "departments": ["University of California, Riverside", "University of California, Riverside", "University of California, Riverside", "Massachusetts Institute of Technology", "Massachusetts Institute of Technology"], "authors": ["David Tyler Bischel.....http://dblp.org/pers/hd/b/Bischel:David_Tyler", "Thomas F. Stahovich.....http://dblp.org/pers/hd/s/Stahovich:Thomas_F=", "Eric Jeffrey Peterson.....http://dblp.org/pers/hd/p/Peterson:Eric_Jeffrey", "Randall Davis.....http://dblp.org/pers/hd/d/Davis:Randall", "Aaron Adler.....http://dblp.org/pers/hd/a/Adler:Aaron"], "conf": "ijcai", "year": "2009", "pages": 6}