{"title": "GPUDet: a deterministic GPU architecture.", "fields": ["nondeterministic algorithm", "massively parallel", "hardware architecture", "thread", "rendering"], "abstract": "Nondeterminism is a key challenge in developing multithreaded applications. Even with the same input, each execution of a multithreaded program may produce a different output. This behavior complicates debugging and limits one's ability to test for correctness. This non-reproducibility situation is aggravated on massively parallel architectures like graphics processing units (GPUs) with thousands of concurrent threads. We believe providing a deterministic environment to ease debugging and testing of GPU applications is essential to enable a broader class of software to use GPUs.   Many hardware and software techniques have been proposed for providing determinism on general-purpose multi-core processors. However, these techniques are designed for small numbers of threads. Scaling them to thousands of threads on a GPU is a major challenge. This paper proposes a scalable hardware mechanism, GPUDet, to provide determinism in GPU architectures. In this paper we characterize the existing deterministic and nondeterministic aspects of current GPU execution models, and we use these observations to inform GPUDet's design. For example, GPUDet leverages the inherent determinism of the SIMD hardware in GPUs to provide determinism within a wavefront at no cost. GPUDet also exploits the Z-Buffer Unit, an existing GPU hardware unit for graphics rendering, to allow parallel out-of-order memory writes to produce a deterministic output. Other optimizations in GPUDet include deterministic parallel execution of atomic operations and a workgroup-aware algorithm that eliminates unnecessary global synchronizations.   Our simulation results indicate that GPUDet incurs only 2X slowdown on average over a baseline nondeterministic architecture, with runtime overheads as low as 4% for compute-bound applications, despite running GPU kernels with thousands of threads. We also characterize the sources of overhead for deterministic execution on GPUs to provide insights for further optimizations.", "citation": "Citations (13)", "year": "2013", "departments": ["University of British Columbia", "University of British Columbia", "Advanced Micro Devices", "University of Washington", "University of British Columbia"], "conf": "asplos", "authors": ["Hadi Jooybar.....http://dblp.org/pers/hd/j/Jooybar:Hadi", "Wilson W. L. Fung.....http://dblp.org/pers/hd/f/Fung:Wilson_W=_L=", "Mike O'Connor.....http://dblp.org/pers/hd/o/O=Connor:Mike", "Joseph Devietti.....http://dblp.org/pers/hd/d/Devietti:Joseph", "Tor M. Aamodt.....http://dblp.org/pers/hd/a/Aamodt:Tor_M="], "pages": 12}