{"title": "Recycling Privileged Learning and Distribution Matching for Fairness.", "fields": ["distance measures", "odds", "operating point", "pareto principle", "conditional probability distribution"], "abstract": "Equipping machine learning models with ethical and legal constraints is a serious issue; without this, the future of machine learning is at risk. This paper takes a step forward in this direction and focuses on ensuring machine learning models deliver fair decisions. In legal scholarships, the notion of fairness itself is evolving and multi-faceted. We set an overarching goal to develop a unified machine learning framework that is able to handle any definitions of fairness, their combinations, and also new definitions that might be stipulated in the future. To achieve our goal, we recycle two well-established machine learning techniques, privileged learning and distribution matching, and harmonize them for satisfying multi-faceted fairness definitions. We consider protected characteristics such as race and gender as privileged information that is available at training but not at test time; this accelerates model training and delivers fairness through unawareness. Further, we cast demographic parity, equalized odds, and equality of opportunity as a classical two-sample problem of conditional distributions, which can be solved in a general form by using distance measures in Hilbert Space. We show several existing models are special cases of ours. Finally, we advocate returning the Pareto frontier of multi-objective minimization of error and unfairness in predictions. This will facilitate decision makers to select an operating point and to be accountable for it.", "citation": "Citations (2)", "year": "2017", "departments": ["National Research University \u2013 Higher School of Economics", "University of Sussex"], "conf": "nips", "authors": ["Novi Quadrianto.....http://dblp.org/pers/hd/q/Quadrianto:Novi", "Viktoriia Sharmanska.....http://dblp.org/pers/hd/s/Sharmanska:Viktoriia"], "pages": 12}