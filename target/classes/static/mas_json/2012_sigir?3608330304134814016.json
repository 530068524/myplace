{"title": "On per-topic variance in IR evaluation.", "fields": ["statistical significance", "statistics", "ir evaluation", "mixed model", "data mining"], "abstract": "We explore the notion, put forward by Cormack & Lynam and Robertson, that we should consider a document collection used for Cranfield-style experiments as a sample from some larger population of documents. In this view, any per-topic metric (such as average precision) should be regarded as an estimate of that metric's true value for that topic in the full population, and therefore as carrying its own per-topic variance or estimate precision or noise. As in the two mentioned papers, we explore this notion by simulating other samples from the same large population. We investigate different ways of performing this simulation. One use of this analysis is to refine the notion of statistical significance of a difference between two systems (in most such analyses, each per-topic measurement is treated as equally precise). We propose a mixed-effects model method to measure significance, and compare it experimentally with the traditional t-test.", "citation": "Citations (25)", "departments": ["Microsoft", "University of Sheffield"], "authors": ["Stephen E. Robertson.....http://dblp.org/pers/hd/r/Robertson:Stephen_E=", "Evangelos Kanoulas.....http://dblp.org/pers/hd/k/Kanoulas:Evangelos"], "conf": "sigir", "year": "2012", "pages": 10}