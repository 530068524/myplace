{"title": "On Lifting the Gibbs Sampling Algorithm.", "fields": ["gibbs sampling", "probabilistic analysis of algorithms", "probabilistic logic", "markov chain monte carlo", "graphical model"], "abstract": "First-order probabilistic models combine the power of first-order logic, the de facto tool for handling relational structure, with probabilistic graphical models, the de facto tool for handling uncertainty. Lifted probabilistic inference algorithms for them have been the subject of much recent research. The main idea in these algorithms is to improve the accuracy and scalability of existing graphical models' inference algorithms by exploiting symmetry in the first-order representation. In this paper, we consider blocked Gibbs sampling, an advanced MCMC scheme, and lift it to the first-order level. We propose to achieve this by partitioning the first-order atoms in the model into a set of disjoint clusters such that exact lifted inference is polynomial in each cluster given an assignment to all other atoms not in the cluster. We propose an approach for constructing the clusters and show how it can be used to trade accuracy with computational complexity in a principled manner. Our experimental evaluation shows that lifted Gibbs sampling is superior to the propositional algorithm in terms of accuracy, scalability and convergence.", "citation": "Citations (36)", "departments": ["University of Texas at Dallas", "University of Texas at Dallas"], "authors": ["Deepak Venugopal.....http://dblp.org/pers/hd/v/Venugopal:Deepak", "Vibhav Gogate.....http://dblp.org/pers/hd/g/Gogate:Vibhav"], "conf": "nips", "year": "2012", "pages": 9}