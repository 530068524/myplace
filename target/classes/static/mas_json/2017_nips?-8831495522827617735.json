{"title": "Neural Expectation Maximization.", "fields": ["expectation maximization algorithm", "inference", "parametrization", "mixture model", "differentiable function"], "abstract": "Many real world tasks such as reasoning and physical interaction require identification and manipulation of conceptual entities. A first step towards solving these tasks is the automated discovery of distributed symbol-like representations. In this paper, we explicitly formalize this problem as inference in a spatial mixture model where each component is parametrized by a neural network. Based on the Expectation Maximization framework we then derive a differentiable clustering method that simultaneously learns how to group and represent individual entities. We evaluate our method on the (sequential) perceptual grouping task and find that it is able to accurately recover the constituent objects. We demonstrate that the learned representations are useful for next-step prediction.", "citation": "Citations (5)", "year": "2017", "departments": ["Dalle Molle Institute for Artificial Intelligence Research", "Dalle Molle Institute for Artificial Intelligence Research", "Dalle Molle Institute for Artificial Intelligence Research"], "conf": "nips", "authors": ["Klaus Greff.....http://dblp.org/pers/hd/g/Greff:Klaus", "Sjoerd van Steenkiste.....http://dblp.org/pers/hd/s/Steenkiste:Sjoerd_van", "J\u00fcrgen Schmidhuber.....http://dblp.org/pers/hd/s/Schmidhuber:J=uuml=rgen"], "pages": 11}