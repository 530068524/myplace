{"title": "Lifelong Learning with Weighted Majority Votes.", "fields": ["lifelong learning", "sample complexity", "feature learning", "intelligent decision support system", "multi task learning"], "abstract": "Better understanding of the potential benefits of information transfer and representation learning is an important step towards the goal of building intelligent systems that are able to persist in the world and learn over time. In this work, we consider a setting where the learner encounters a stream of tasks but is able to retain only limited information from each encountered task, such as a learned predictor. In contrast to most previous works analyzing this scenario, we do not make any distributional assumptions on the task generating process. Instead, we formulate a complexity measure that captures the diversity of the observed tasks. We provide a lifelong learning algorithm with error guarantees for every observed task (rather than on average). We show sample complexity reductions in comparison to solving every task in isolation in terms of our task complexity measure. Further, our algorithmic framework can naturally be viewed as learning a representation from encountered tasks with a neural network.", "citation": "Citations (4)", "departments": ["Max Planck Society", "External Organizations"], "authors": ["Anastasia Pentina.....http://dblp.org/pers/hd/p/Pentina:Anastasia", "Ruth Urner.....http://dblp.org/pers/hd/u/Urner:Ruth"], "conf": "nips", "year": "2016", "pages": 9}