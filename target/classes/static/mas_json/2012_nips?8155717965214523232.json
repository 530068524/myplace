{"title": "Multimodal Learning with Deep Boltzmann Machines.", "fields": ["multimodal learning", "deep learning", "deep belief network", "boltzmann machine", "generative model", "multiple kernel learning"], "abstract": "Data often consists of multiple diverse modalities. For example, images are tagged with textual information and videos are accompanied by audio. Each modality is characterized by having distinct statistical properties. We propose a Deep Boltzmann Machine for learning a generative model of such multimodal data. We show that the model can be used to create fused representations by combining features across modalities. These learned representations are useful for classification and information retrieval. By sampling from the conditional distributions over each data modality, it is possible to create these representations even when some data modalities are missing. We conduct experiments on bimodal image-text and audio-video data. The fused representation achieves good classification results on the MIR-Flickr data set matching or outperforming other deep models as well as SVM based models that use Multiple Kernel Learning. We further demonstrate that this multimodal model helps classification and retrieval even when only unimodal data is available at test time.", "citation": "Citations (719)", "departments": ["University of Toronto", "University of Toronto", "University of Toronto", "University of Toronto"], "authors": ["Nitish Srivastava.....http://dblp.org/pers/hd/s/Srivastava:Nitish", "Ruslan Salakhutdinov.....http://dblp.org/pers/hd/s/Salakhutdinov:Ruslan"], "conf": "nips", "year": "2012", "pages": 9}