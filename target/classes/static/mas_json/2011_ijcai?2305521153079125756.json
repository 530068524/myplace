{"title": "Goal Recognition over POMDPs: Inferring the Intention of a POMDP Agent.", "fields": ["observable", "partially observable markov decision process", "bellman equation", "observer", "probability distribution"], "abstract": "Plan recognition is the problem of inferring the goals and plans of an agent from partial observations of her behavior. Recently, it has been shown that the problem can be formulated and solved using planners, reducing plan recognition to plan generation. In this work, we extend this model-based approach to plan recognition to the POMDP setting, where actions are stochastic and states are partially observable. The task is to infer a probability distribution over the possible goals of an agent whose behavior results from a POMDP model. The POMDP model is shared between agent and observer except for the true goal of the agent that is hidden to the observer. The observations are action sequences O that may contain gaps as some or even most of the actions done by the agent may not be observed. We show that the posterior goal distribution P(G|O) can be computed from the value function VG(b) over beliefs b generated by the POMDP planner for each possible goal G. Some extensions of the basic framework are discussed, and a number of experiments are reported.", "citation": "Citations (93)", "year": "2011", "departments": ["Pompeu Fabra University", "Pompeu Fabra University"], "conf": "ijcai", "authors": ["Miquel Ram\u00edrez.....http://dblp.org/pers/hd/r/Ram=iacute=rez:Miquel", "Hector Geffner.....http://dblp.org/pers/hd/g/Geffner:Hector"], "pages": 6}