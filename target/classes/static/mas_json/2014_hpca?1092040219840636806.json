{"title": "MRPB: Memory request prioritization for massively parallel processors.", "fields": ["page cache", "snoopy cache", "cache coloring", "smart cache", "cache pollution"], "abstract": "Massively parallel, throughput-oriented systems such as graphics processing units (GPUs) offer high performance for a broad range of programs. They are, however, complex to program, especially because of their intricate memory hierarchies with multiple address spaces. In response, modern GPUs have widely adopted caches, hoping to providing smoother reductions in memory access traffic and latency. Unfortunately, GPU caches often have mixed or unpredictable performance impact due to cache contention that results from the high thread counts in GPUs. We propose the memory request prioritization buffer (MRPB) to ease GPU programming and improve GPU performance. This hardware structure improves caching efficiency of massively parallel workloads by applying two prioritization methods\u2014request reordering and cache bypassing\u2014to memory requests before they access a cache. MRPB then releases requests into the cache in a more cache-friendly order. The result is drastically reduced cache contention and improved use of the limited per-thread cache capacity. For a simulated 16KB L1 cache, MRPB improves the average performance of the entire PolyBench and Rodinia suites by 2.65\u00d7 and 1.27\u00d7 respectively, outperforming a state-of-the-art GPU cache management technique.", "citation": "Citations (114)", "departments": ["Princeton University", "University of Richmond", "Princeton University"], "authors": ["Wenhao Jia.....http://dblp.org/pers/hd/j/Jia:Wenhao", "Kelly A. Shaw.....http://dblp.org/pers/hd/s/Shaw_0001:Kelly_A=", "Margaret Martonosi.....http://dblp.org/pers/hd/m/Martonosi:Margaret"], "conf": "hpca", "year": "2014", "pages": 12}