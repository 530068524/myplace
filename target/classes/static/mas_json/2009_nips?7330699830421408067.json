{"title": "STDP enables spiking neurons to detect hidden causes of their inputs.", "fields": ["hebbian theory", "streams", "winner take all", "dimensionality reduction", "network motif"], "abstract": "The principles by which spiking neurons contribute to the astounding computational power of generic cortical microcircuits, and how spike-timing-dependent plasticity (STDP) of synaptic weights could generate and maintain this computational function, are unknown. We show here that STDP, in conjunction with a stochastic soft winner-take-all (WTA) circuit, induces spiking neurons to generate through their synaptic weights implicit internal models for subclasses (or \"causes\") of the high-dimensional spike patterns of hundreds of pre-synaptic neurons. Hence these neurons will fire after learning whenever the current input best matches their internal model. The resulting computational function of soft WTA circuits, a common network motif of cortical microcircuits, could therefore be a drastic dimensionality reduction of information streams, together with the autonomous creation of internal models for the probability distributions of their input patterns. We show that the autonomous generation and maintenance of this computational function can be explained on the basis of rigorous mathematical principles. In particular, we show that STDP is able to approximate a stochastic online Expectation-Maximization (EM) algorithm for modeling the input data. A corresponding result is shown for Hebbian learning in artificial neural networks.", "citation": "Citations (94)", "year": "2009", "departments": ["Graz University of Technology", "Graz University of Technology", "Graz University of Technology"], "conf": "nips", "authors": ["Bernhard Nessler.....http://dblp.org/pers/hd/n/Nessler:Bernhard", "Michael Pfeiffer.....http://dblp.org/pers/hd/p/Pfeiffer:Michael", "Wolfgang Maass.....http://dblp.org/pers/hd/m/Maass_0001:Wolfgang"], "pages": 9}