{"title": "The power of absolute discounting: all-dimensional distribution estimation.", "fields": ["effective dimension", "categorical variable", "minimax", "estimator", "discounting"], "abstract": "Categorical models are a natural fit for many problems. When learning the distribution of categories from samples, high-dimensionality may dilute the data. Minimax optimality is too pessimistic to remedy this issue. A serendipitously discovered estimator, absolute discounting, corrects empirical frequencies by subtracting a constant from observed categories, which it then redistributes among the unobserved. It outperforms classical estimators empirically, and has been used extensively in natural language modeling. In this paper, we rigorously explain the prowess of this estimator using less pessimistic notions. We show that (1) absolute discounting recovers classical minimax KL-risk rates, (2) it is \\emph{adaptive} to an effective dimension rather than the true dimension, (3) it is strongly related to the Good-Turing estimator and inherits its \\emph{competitive} properties. We use power-law distributions as the cornerstone of these results. We validate the theory via synthetic data and an application to the Global Terrorism Database.", "citation": "Not cited", "year": "2017", "departments": ["University of California, San Diego", "Toyota Technological Institute at Chicago", "University of California, San Diego", "University of California, San Diego"], "conf": "nips", "authors": ["Moein Falahatgar.....http://dblp.org/pers/hd/f/Falahatgar:Moein", "Mesrob I. Ohannessian.....http://dblp.org/pers/hd/o/Ohannessian:Mesrob_I=", "Alon Orlitsky.....http://dblp.org/pers/hd/o/Orlitsky:Alon", "Venkatadheeraj Pichapati.....http://dblp.org/pers/hd/p/Pichapati:Venkatadheeraj"], "pages": 10}