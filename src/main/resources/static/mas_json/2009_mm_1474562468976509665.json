{"title": "Automated localization of affective objects and actions in images via caption text-cum-eye gaze analysis.", "fields": ["affect", "eye tracking", "gaze", "multimedia", "computer vision"], "abstract": "We propose a novel framework to localize and label affective objects and actions in images through a combination of text, visual and gaze-based analysis. Human gaze provides useful cues to infer locations and interactions of affective objects. While concepts (labels) associated with an image can be determined from its caption, we demonstrate localization of these concepts upon learning from a statistical affect model for world concepts. The affect model is derived from non-invasively acquired fixation patterns on labeled images, and guides localization of affective objects (faces, reptiles) and actions (look, read) from fixations in unlabeled images. Experimental results obtained on a database of 500 images confirm the effectiveness and promise of the proposed approach.", "citation": "Citations (17)", "departments": ["National University of Singapore", "National University of Singapore", "National University of Singapore", "National University of Singapore", "National University of Singapore"], "authors": ["Subramanian Ramanathan.....http://dblp.org/pers/hd/r/Ramanathan:Subramanian", "Harish Katti.....http://dblp.org/pers/hd/k/Katti:Harish", "Raymond Huang.....http://dblp.org/pers/hd/h/Huang:Raymond", "Tat-Seng Chua.....http://dblp.org/pers/hd/c/Chua:Tat=Seng", "Mohan S. Kankanhalli.....http://dblp.org/pers/hd/k/Kankanhalli:Mohan_S="], "conf": "mm", "year": "2009", "pages": 4}