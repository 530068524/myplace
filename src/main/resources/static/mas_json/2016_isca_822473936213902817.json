{"title": "MITTS: Memory Inter-arrival Time Traffic Shaping.", "fields": ["conventional memory", "uniform memory access", "memory bandwidth", "computing with memory", "interleaved memory"], "abstract": "Memory bandwidth severely limits the scalability and performance of multicore and manycore systems. Application performance can be very sensitive to both the delivered memory bandwidth and latency. In multicore systems, a memory channel is usually shared by multiple cores. Having the ability to precisely provision, schedule, and isolate memory bandwidth and latency on a per-core basis is particularly important when different memory guarantees are needed on a per-customer, per-application, or per-core basis. Infrastructure as a Service (IaaS) Cloud systems, and even general purpose multicores optimized for application throughput or fairness all benefit from the ability to control and schedule memory access on a fine-grain basis. In this paper, we propose MITTS (Memory Inter-arrival Time Traffic Shaping), a simple, distributed hardware mechanism which limits memory traffic at the source (Core or LLC). MITTS shapes memory traffic based on memory request inter-arrival time, enabling fine-grain bandwidth allocation. In an IaaS system, MITTS enables Cloud customers to express their memory distribution needs and pay commensurately. For instance, MITTS enables charging customers that have bursty memory traffic more than customers with uniform memory traffic for the same aggregate bandwidth. Beyond IaaS systems, MITTS can also be used to optimize for throughput or fairness in a general purpose multi-program workload. MITTS uses an online genetic algorithm to configure hardware bins, which can adapt for program phases and variable input sets. We have implemented MITTS in Verilog and have taped-out the design in a 25-core 32nm processor and find that MITTS requires less than 0.9% of core area. We evaluate across SPECint, PARSEC, Apache, and bhm Mail Server workloads, and find that MITTS achieves an average 1.18\u00d7 performance gain compared to the best static bandwidth allocation, a 2.69\u00d7 average performance/cost advantage in an IaaS setting, and up to 1.17\u00d7 better throughput and 1.52\u00d7 better fairness when compared to conventional memory bandwidth provisioning techniques.", "citation": "Citations (1)", "year": "2016", "departments": ["Princeton University", "Princeton University"], "conf": "isca", "authors": ["Yanqi Zhou.....http://dblp.org/pers/hd/z/Zhou:Yanqi", "David Wentzlaff.....http://dblp.org/pers/hd/w/Wentzlaff:David"], "pages": 13}