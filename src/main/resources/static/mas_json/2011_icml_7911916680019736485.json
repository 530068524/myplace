{"title": "Beat the Mean Bandit.", "fields": ["beat", "transitive relation", "pairwise comparison", "pattern recognition", "machine learning"], "abstract": "The Dueling Bandits Problem is an online learning framework in which actions are restricted to noisy comparisons between pairs of strategies (also called bandits). It models settings where absolute rewards are difficult to elicit but pairwise preferences are readily available. In this paper, we extend the Dueling Bandits Problem to a relaxed setting where preference magnitudes can violate transitivity. We present the first algorithm for this more general Dueling Bandits Problem and provide theoretical guarantees in both the online and the PAC settings. We also show that the new algorithm has stronger guarantees than existing results even in the original Dueling Bandits Problem, which we validate empirically.", "citation": "Citations (58)", "year": "2011", "departments": ["Carnegie Mellon University", "Cornell University"], "conf": "icml", "authors": ["Yisong Yue.....http://dblp.org/pers/hd/y/Yue:Yisong", "Thorsten Joachims.....http://dblp.org/pers/hd/j/Joachims:Thorsten"], "pages": 8}