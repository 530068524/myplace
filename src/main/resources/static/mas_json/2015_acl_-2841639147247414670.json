{"title": "Learning Word Representations by Jointly Modeling Syntagmatic and Paradigmatic Relations.", "fields": ["syntagmatic analysis", "feature learning", "artificial intelligence", "analogy", "natural language processing"], "abstract": "Vector space representation of words has been widely used to capture fine-grained linguistic regularities, and proven to be successful in various natural language processing tasks in recent years. However, existing models for learning word representations focus on either syntagmatic or paradigmatic relations alone. In this paper, we argue that it is beneficial to jointly modeling both relations so that we can not only encode different types of linguistic properties in a unified way, but also boost the representation learning due to the mutual enhancement between these two types of relations. We propose two novel distributional models for word representation using both syntagmatic and paradigmatic relations via a joint training objective. The proposed models are trained on a public Wikipedia corpus, and the learned representations are evaluated on word analogy and word similarity tasks. The results demonstrate that the proposed models can perform significantly better than all the state-of-the-art baseline methods on both tasks.", "citation": "Citations (16)", "year": "2015", "departments": ["Chinese Academy of Sciences", "Chinese Academy of Sciences", "Chinese Academy of Sciences", "Chinese Academy of Sciences", "Chinese Academy of Sciences"], "conf": "acl", "authors": ["Fei Sun.....http://dblp.org/pers/hd/s/Sun:Fei", "Jiafeng Guo.....http://dblp.org/pers/hd/g/Guo:Jiafeng", "Yanyan Lan.....http://dblp.org/pers/hd/l/Lan:Yanyan", "Jun Xu.....http://dblp.org/pers/hd/x/Xu_0001:Jun", "Xueqi Cheng.....http://dblp.org/pers/hd/c/Cheng:Xueqi"], "pages": 10}