{"title": "Submodular-Bregman and the Lov\u00e1sz-Bregman Divergences with Applications.", "fields": ["conditional mutual information", "bregman divergence", "square", "hamming code", "submodular set function"], "abstract": "We introduce a class of discrete divergences on sets (equivalently binary vectors) that we call the submodular-Bregman divergences. We consider two kinds, defined either from tight modular upper or tight modular lower bounds of a submodular function. We show that the properties of these divergences are analogous to the (standard continuous) Bregman divergence. We demonstrate how they generalize many useful divergences, including the weighted Hamming distance, squared weighted Hamming, weighted precision, recall, conditional mutual information, and a generalized KL-divergence on sets. We also show that the generalized Bregman divergence on the Lovasz extension of a submodular function, which we call the Lovasz-Bregman divergence, is a continuous extension of a submodular Bregman divergence. We point out a number of applications, and in particular show that a proximal algorithm defined through the submodular Bregman divergence provides a framework for many mirror-descent style algorithms related to submodular function optimization. We also show that a generalization of the k-means algorithm using the Lovasz Bregman divergence is natural in clustering scenarios where ordering is important. A unique property of this algorithm is that computing the mean ordering is extremely efficient unlike other order based distance measures.", "citation": "Citations (12)", "departments": ["University of Washington", "University of Washington"], "authors": ["Rishabh K. Iyer.....http://dblp.org/pers/hd/i/Iyer:Rishabh_K=", "Jeff A. Bilmes.....http://dblp.org/pers/hd/b/Bilmes:Jeff_A="], "conf": "nips", "year": "2012", "pages": 9}