{"title": "Iterative Nearest Neighbors for classification and dimensionality reduction.", "fields": ["contextual image classification", "approximation algorithm", "dimensionality reduction", "embedding", "sparse approximation"], "abstract": "Representative data in terms of a set of selected samples is of interest for various machine learning applications, e.g. dimensionality reduction and classification. The best-known techniques probably still are k-Nearest Neighbors (kNN) and its variants. Recently, richer representations have become popular. Examples are methods based on l 1 -regularized least squares (Sparse Representation (SR)) or l 2 -regularized least squares (Collaborative Representation (CR)), or on l 1 -constrained least squares (Local Linear Embedding (LLE)). We propose Iterative Nearest Neighbors (INN). This is a novel sparse representation that combines the power of SR and LLE with the computational simplicity of kNN. We test our method in terms of dimensionality reduction and classification, using standard benchmarks such as faces (AR), traffic signs (GTSRB), and PASCAL VOC 2007. INN performs better than NN and comparable with CR and SR, while being orders of magnitude faster than the latter.", "citation": "Citations (29)", "year": "2012", "departments": ["Katholieke Universiteit Leuven", "Katholieke Universiteit Leuven"], "conf": "cvpr", "authors": ["Radu Timofte.....http://dblp.org/pers/hd/t/Timofte:Radu", "Luc J. Van Gool.....http://dblp.org/pers/hd/g/Gool:Luc_J=_Van"], "pages": 8}