{"title": "Scalable Inference for Logistic-Normal Topic Models.", "fields": ["gibbs sampling", "inference", "topic model", "scalability", "multinomial distribution"], "abstract": "Logistic-normal topic models can effectively discover correlation structures among latent topics. However, their inference remains a challenge because of the non-conjugacy between the logistic-normal prior and multinomial topic mixing proportions. Existing algorithms either make restricting mean-field assumptions or are not scalable to large-scale applications. This paper presents a partially collapsed Gibbs sampling algorithm that approaches the provably correct distribution by exploring the ideas of data augmentation. To improve time efficiency, we further present a parallel implementation that can deal with large-scale applications and learn the correlation structures of thousands of topics from millions of documents. Extensive empirical results demonstrate the promise.", "citation": "Citations (58)", "departments": ["Tsinghua University", "Tsinghua University"], "authors": ["Jianfei Chen.....http://dblp.org/pers/hd/c/Chen_0001:Jianfei", "Jun Zhu.....http://dblp.org/pers/hd/z/Zhu_0001:Jun", "Zi Wang.....http://dblp.org/pers/hd/w/Wang:Zi", "Xun Zheng.....http://dblp.org/pers/hd/z/Zheng:Xun", "Bo Zhang.....http://dblp.org/pers/hd/z/Zhang_0010:Bo"], "conf": "nips", "year": "2013", "pages": 9}