{"title": "Reified Context Models.", "fields": ["random variable", "approximate inference", "expressivity", "inference", "graphical model"], "abstract": "A classic tension exists between exact inference in a simple model and approximate inference in a complex model. The latter offers expressivity and thus accuracy, but the former provides coverage of the space, an important property for confidence estimation and learning with indirect supervision. In this work, we introduce a new approach, reified context models, to reconcile this tension. Specifically, we let the choice of factors in a graphical model (the contexts) be random variables inside the model itself. In this sense, the contexts are reified and can be chosen in a data-dependent way. Empirically, we show that our approach obtains expressivity and coverage on three sequence modeling tasks.", "citation": "Not cited", "year": "2015", "departments": ["Stanford University", "Stanford University"], "conf": "icml", "authors": ["Jacob Steinhardt.....http://dblp.org/pers/hd/s/Steinhardt:Jacob", "Percy Liang.....http://dblp.org/pers/hd/l/Liang:Percy"], "pages": 10}