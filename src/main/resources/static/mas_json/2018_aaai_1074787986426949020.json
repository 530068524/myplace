{"title": "OptionGAN: Learning Joint Reward-Policy Options Using Generative Adversarial Inverse Reinforcement Learning.", "fields": ["generative grammar", "error driven learning", "transfer of learning", "learning classifier system", "adversarial system"], "abstract": "Reinforcement learning has shown promise in learning policies that can solve complex problems. However, manually specifying a good reward function can be difficult, especially for intricate tasks. Inverse reinforcement learning offers a useful paradigm to learn the underlying reward function directly from expert demonstrations. Yet in reality, the corpus of demonstrations may contain trajectories arising from a diverse set of underlying reward functions rather than a single one. Thus, in inverse reinforcement learning, it is useful to consider such a decomposition. The options framework in reinforcement learning is specifically designed to decompose policies in a similar light. We therefore extend the options framework and propose a method to simultaneously recover reward options in addition to policy options. We leverage adversarial methods to learn joint reward-policy options using only observed expert states. We show that this approach works well in both simple and complex continuous control tasks and shows significant performance increases in one-shot transfer learning.", "citation": "Citations (1)", "departments": ["McGill University", "McGill University", "McGill University", "McGill University"], "authors": ["Peter Henderson.....http://dblp.org/pers/hd/h/Henderson_0002:Peter", "Wei-Di Chang.....http://dblp.org/pers/hd/c/Chang:Wei=Di", "Pierre-Luc Bacon.....http://dblp.org/pers/hd/b/Bacon:Pierre=Luc", "David Meger.....http://dblp.org/pers/hd/m/Meger:David", "Joelle Pineau.....http://dblp.org/pers/hd/p/Pineau:Joelle", "Doina Precup.....http://dblp.org/pers/hd/p/Precup:Doina"], "conf": "aaai", "year": "2018", "pages": 8}