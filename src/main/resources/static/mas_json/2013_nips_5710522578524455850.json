{"title": "Approximate Inference in Continuous Determinantal Processes.", "fields": ["point process", "kernel", "approximate inference", "gibbs sampling", "eigendecomposition of a matrix"], "abstract": "Determinantal point processes (DPPs) are random point processes well-suited for modeling repulsion. In machine learning, the focus of DPP-based models has been on diverse subset selection from a discrete and finite base set. This discrete setting admits an efficient sampling algorithm based on the eigendecomposition of the defining kernel matrix. Recently, there has been growing interest in using DPPs defined on continuous spaces. While the discrete-DPP sampler extends formally to the continuous case, computationally, the steps required are not tractable in general. In this paper, we present two efficient DPP sampling schemes that apply to a wide range of kernel functions: one based on low rank approximations via Nystrom and random Fourier feature techniques and another based on Gibbs sampling. We demonstrate the utility of continuous DPPs in repulsive mixture modeling and synthesizing human poses spanning activity spaces.", "citation": "Citations (23)", "departments": ["University of Pennsylvania", "University of Washington", "University of Washington"], "authors": ["Raja Hafiz Affandi.....http://dblp.org/pers/hd/a/Affandi:Raja_Hafiz", "Emily B. Fox.....http://dblp.org/pers/hd/f/Fox:Emily_B=", "Ben Taskar.....http://dblp.org/pers/hd/t/Taskar:Ben"], "conf": "nips", "year": "2013", "pages": 9}