{"title": "A Representation Learning Framework for Multi-Source Transfer Parsing.", "fields": ["multi source", "feature learning", "dependency grammar", "s attributed grammar", "parsing"], "abstract": "Cross-lingual model transfer has been a promising approach for inducing dependency parsers for low-resource languages where annotated treebanks are not available. The major obstacles for the model transfer approach are two-fold: 1. Lexical features are not directly transferable across languages; 2. Target language-specific syntactic structures are difficult to be recovered. To address these two challenges, we present a novel representation learning framework for multi-source transfer parsing. Our framework allows multi-source transfer parsing using full lexical features straightforwardly. By evaluating on the Google universal dependency tree-banks (v2.0), our best models yield an absolute improvement of 6.53% in averaged labeled attachment score, as compared with delexicalized multi-source transfer models. We also significantly outperform the state-of-the-art transfer system proposed most recently.", "citation": "Citations (19)", "departments": ["Harbin Institute of Technology", "Harbin Institute of Technology", "Johns Hopkins University", "Baidu", "Harbin Institute of Technology"], "authors": ["Jiang Guo.....http://dblp.org/pers/hd/g/Guo:Jiang", "Wanxiang Che.....http://dblp.org/pers/hd/c/Che:Wanxiang", "David Yarowsky.....http://dblp.org/pers/hd/y/Yarowsky:David", "Haifeng Wang.....http://dblp.org/pers/hd/w/Wang:Haifeng", "Ting Liu.....http://dblp.org/pers/hd/l/Liu_0001:Ting"], "conf": "aaai", "year": "2016", "pages": 7}