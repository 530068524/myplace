{"title": "Cross-batch Reference Learning for Deep Classification and Retrieval.", "fields": ["contextual image classification", "discriminative model", "feature", "multimedia search", "visual word"], "abstract": "Learning feature representations for image retrieval is essential to multimedia search and mining applications. Recently, deep convolutional networks (CNNs) have gained much attention due to their impressive performance on object detection and image classification, and the feature representations learned from a large-scale generic dataset (e.g., ImageNet) can be transferred to or fine-tuned on the datasets of other domains. However, when the feature representations learned with a deep CNN are applied to image retrieval, the performance is still not as good as they are used for classification, which restricts their applicability to relevant image search. To ensure the retrieval capability of the learned feature space, we introduce a new idea called cross-batch reference (CBR) to enhance the stochastic-gradient-descent (SGD) training of CNNs. In each iteration of our training process, the network adjustment relies not only on the training samples in a single batch, but also on the information passed by the samples in the other batches. This inter-batches communication mechanism is formulated as a cross-batch retrieval process based on the mean average precision (MAP) criterion, where the relevant and irrelevant samples are encouraged to be placed on top and rear of the retrieval list, respectively. The learned feature space is not only discriminative to different classes, but the samples that are relevant to each other or of the same class are also enforced to be centralized. To maximize the cross-batch MAP, we design a loss function that is an approximated lower bound of the MAP on the feature layer of the network, which is differentiable and easier for optimization. By combining the intra-batch classification and inter-batch cross-reference losses, the learned features are effective for both classification and retrieval tasks. Experimental results on various benchmarks demonstrate the effectiveness of our approach.", "citation": "Not cited", "departments": ["Academia Sinica", "Academia Sinica", "Academia Sinica"], "authors": ["Huei-Fang Yang.....http://dblp.org/pers/hd/y/Yang:Huei=Fang", "Kevin Lin.....http://dblp.org/pers/hd/l/Lin:Kevin", "Chu-Song Chen.....http://dblp.org/pers/hd/c/Chen:Chu=Song"], "conf": "mm", "year": "2016", "pages": 10}