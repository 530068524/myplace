{"title": "Solving Stochastic Games.", "fields": ["approximation error", "approximation algorithm", "bellman equation", "polynomial", "reinforcement learning"], "abstract": "Solving multi-agent reinforcement learning problems has proven difficult because of the lack of tractable algorithms. We provide the first approximation algorithm which solves stochastic games with cheap-talk to within \u220a absolute error of the optimal game-theoretic solution, in time polynomial in 1/\u220a. Our algorithm extends Murray's and Gordon's (2007) modified Bellman equation which determines the set of all possible achievable utilities; this provides us a truly general framework for multi-agent learning. Further, we empirically validate our algorithm and find the computational cost to be orders of magnitude less than what the theory predicts.", "citation": "Citations (20)", "year": "2009", "departments": ["Georgia Institute of Technology", "Georgia Institute of Technology"], "conf": "nips", "authors": ["Liam Mac Dermed.....http://dblp.org/pers/hd/d/Dermed:Liam_Mac", "Charles L. Isbell.....http://dblp.org/pers/hd/i/Isbell:Charles_L="], "pages": 9}