{"title": "SEE: Syntax-Aware Entity Embedding for Neural Relation Extraction.", "fields": ["syntax", "plain text", "embedding", "relationship extraction", "sentence"], "abstract": "Distant supervised relation extraction is an efficient approach to scale relation extraction to very large corpora, and has been widely used to find novel relational facts from plain text. Recent studies on neural relation extraction have shown great progress on this task via modeling the sentences in low-dimensional spaces, but seldom considered syntax information to model the entities. In this paper, we propose to learn syntax-aware entity embedding for neural relation extraction. First, we encode the context of entities on a dependency tree as sentence-level entity embedding based on tree-GRU. Then, we utilize both intra-sentence and inter-sentence attentions to obtain sentence set-level entity embedding over all sentences containing the focus entity pair. Finally, we combine both sentence embedding and entity embedding for relation classification. We conduct experiments on a widely used real-world dataset and the experimental results show that our model can make full use of all informative instances and achieve state-of-the-art performance of relation extraction.", "citation": "Not cited", "departments": ["Soochow University", "Singapore University of Technology and Design", "Soochow University", "Central South University"], "authors": ["Zhengqiu He.....http://dblp.org/pers/hd/h/He:Zhengqiu", "Wenliang Chen.....http://dblp.org/pers/hd/c/Chen:Wenliang", "Zhenghua Li.....http://dblp.org/pers/hd/l/Li:Zhenghua", "Meishan Zhang.....http://dblp.org/pers/hd/z/Zhang:Meishan", "Wei Zhang.....http://dblp.org/pers/hd/z/Zhang:Wei", "Min Zhang.....http://dblp.org/pers/hd/z/Zhang_0005:Min"], "conf": "aaai", "year": "2018", "pages": 8}