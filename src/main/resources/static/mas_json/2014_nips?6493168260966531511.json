{"title": "On Iterative Hard Thresholding Methods for High-dimensional M-Estimation.", "fields": ["pattern recognition", "generalized linear model", "minimax", "thresholding", "scalability", "gradient descent", "mathematics", "balanced histogram thresholding", "artificial intelligence"], "abstract": "The use of M-estimators in generalized linear regression models in high dimensional settings requires risk minimization with hard L0 constraints. Of the known methods, the class of projected gradient descent (also known as iterative hard thresholding (IHT)) methods is known to offer the fastest and most scalable solutions. However, the current state-of-the-art is only able to analyze these methods in extremely restrictive settings which do not hold in high dimensional statistical models. In this work we bridge this gap by providing the first analysis for IHT-style methods in the high dimensional statistical setting. Our bounds are tight and match known minimax lower bounds. Our results rely on a general analysis framework that enables us to analyze several popular hard thresholding style algorithms (such as HTP, CoSaMP, SP) in the high dimensional regression setting. Finally, we extend our analysis to the problem of low-rank matrix recovery.", "citation": "Not cited", "year": "2014", "departments": ["Microsoft", "University of Michigan", "Microsoft", "Microsoft", "Microsoft", "Statistics"], "conf": "nips", "authors": ["Prateek Jain.....http://dblp.org/pers/hd/j/Jain_0002:Prateek", "Ambuj Tewari.....http://dblp.org/pers/hd/t/Tewari:Ambuj", "Purushottam Kar.....http://dblp.org/pers/hd/k/Kar:Purushottam"], "pages": 9}