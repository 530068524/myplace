{"title": "Stochastic Optimization for Multiview Representation Learning using Partial Least Squares.", "fields": ["bilinear interpolation", "feature learning", "stochastic gradient descent", "stochastic approximation", "stochastic optimization"], "abstract": "Partial Least Squares (PLS) is a ubiquitous statistical technique for bilinear factor analysis. It is used in many data analysis, machine learning, and information retrieval applications to model the covariance structure between a pair of data matrices. In this paper, we consider PLS for representation learning in a multiview setting where we have more than one view in data at training time. Furthermore, instead of framing PLS as a problem about a fixed given data set, we argue that PLS should be studied as a stochastic optimization problem, especially in a \"big data\" setting, with the goal of optimizing a population objective based on sample. This view suggests using Stochastic Approximation (SA) approaches, such as Stochastic Gradient Descent (SGD) and enables a rigorous analysis of their benefits. In this paper, we develop SA approaches to PLS and provide iteration complexity bounds for the proposed algorithms.", "citation": "Citations (5)", "year": "2016", "departments": ["Johns Hopkins University", "Johns Hopkins University", "University of Edinburgh"], "conf": "icml", "authors": ["Raman Arora.....http://dblp.org/pers/hd/a/Arora:Raman", "Poorya Mianjy.....http://dblp.org/pers/hd/m/Mianjy:Poorya", "Teodor V. Marinov.....http://dblp.org/pers/hd/m/Marinov:Teodor_V="], "pages": 9}