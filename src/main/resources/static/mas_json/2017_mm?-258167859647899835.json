{"title": "StructCap: Structured Semantic Embedding for Image Captioning.", "fields": ["deep learning", "closed captioning", "convolutional neural network", "visual objects", "automatic image annotation"], "abstract": "Image captioning has attracted ever-increasing research attention in multimedia and computer vision. To encode the visual content, existing approaches typically utilize the off-the-shelf deep Convolutional Neural Network (CNN) model to extract visual features, which are sent to Recurrent Neural Network (RNN) based textual generators to output word sequence. Some methods encode visual objects and scene information with attention mechanism more recently. Despite the promising progress, one distinct disadvantage lies in distinguishing and modeling key semantic entities and their relations, which are in turn widely regarded as the important cues for us to describe image content. In this paper, we propose a novel image captioning model, termed StructCap. It parses a given image into key entities and their relations organized in a visual parsing tree, which is transformed and embedded under an encoder-decoder framework via visual attention. We give an end-to-end formulation to facilitate joint training of visual tree parser, structured semantic attention and RNN-based captioning modules. Experimental results on two public benchmarks, Microsoft COCO and Flickr30K, show that the proposed StructCap model outperforms the state-of-the-art approaches under various standard evaluation metrics.", "citation": "Not cited", "departments": ["Xiamen University", "Xiamen University", "Xiamen University", "Tencent", "Tencent"], "authors": ["Fuhai Chen.....http://dblp.org/pers/hd/c/Chen:Fuhai", "Rongrong Ji.....http://dblp.org/pers/hd/j/Ji:Rongrong", "Jinsong Su.....http://dblp.org/pers/hd/s/Su:Jinsong", "Yongjian Wu.....http://dblp.org/pers/hd/w/Wu:Yongjian", "Yunsheng Wu.....http://dblp.org/pers/hd/w/Wu:Yunsheng"], "conf": "mm", "year": "2017", "pages": 9}