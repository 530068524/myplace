{"title": "Triangular Architecture for Rare Language Translation.", "fields": ["machine translation", "machine learning", "expectation maximization algorithm", "latent variable", "architecture"], "abstract": "Neural Machine Translation (NMT) performs poor on the low-resource language pair $(X,Z)$, especially when $Z$ is a rare language. By introducing another rich language $Y$, we propose a novel triangular training architecture (TA-NMT) to leverage bilingual data $(Y,Z)$ (may be small) and $(X,Y)$ (can be rich) to improve the translation performance of low-resource pairs. In this triangular architecture, $Z$ is taken as the intermediate latent variable, and translation models of $Z$ are jointly optimized with a unified bidirectional EM algorithm under the goal of maximizing the translation likelihood of $(X,Y)$. Empirical results demonstrate that our method significantly improves the translation quality of rare languages on MultiUN and IWSLT2012 datasets, and achieves even better performance combining back-translation methods.", "citation": "Not cited", "year": "2018", "departments": ["Microsoft", "Microsoft", "Microsoft"], "conf": "acl", "authors": ["Ming Zhou.....http://dblp.org/pers/hd/z/Zhou_0001:Ming", "Shujie Liu.....http://dblp.org/pers/hd/l/Liu_0001:Shujie", "Mu Li.....http://dblp.org/pers/hd/l/Li:Mu", "Shuo Ren.....http://dblp.org/pers/hd/r/Ren:Shuo", "Wenhu Chen.....http://dblp.org/pers/hd/c/Chen:Wenhu", "Shuai Ma.....http://dblp.org/pers/hd/m/Ma:Shuai"], "pages": 10}