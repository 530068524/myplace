{"title": "Cross-Modal Retrieval in the Cooking Context: Learning Semantic Text-Image Embeddings.", "fields": ["deep learning", "machine learning", "popularity", "natural language processing", "use case"], "abstract": "Designing powerful tools that support cooking activities has rapidly gained popularity due to the massive amounts of available data, as well as recent advances in machine learning that are capable of analyzing them. In this paper, we propose a cross-modal retrieval model aligning visual and textual data (like pictures of dishes and their recipes) in a shared representation space. We describe an effective learning scheme, capable of tackling large-scale problems, and validate it on the Recipe1M dataset containing nearly 1 million picture-recipe pairs. We show the effectiveness of our approach regarding previous state-of-the-art models and present qualitative results over computational cooking use cases.", "citation": "Citations (1)", "departments": ["University of Paris", "University of Paris", "University of Paris", "University of Paris", "Conservatoire national des arts et m\u00e9tiers"], "authors": ["Micael Carvalho.....http://dblp.org/pers/hd/c/Carvalho:Micael", "R\u00e9mi Cad\u00e8ne.....http://dblp.org/pers/hd/c/Cad=egrave=ne:R=eacute=mi", "David Picard.....http://dblp.org/pers/hd/p/Picard:David", "Laure Soulier.....http://dblp.org/pers/hd/s/Soulier:Laure", "Nicolas Thome.....http://dblp.org/pers/hd/t/Thome:Nicolas", "Matthieu Cord.....http://dblp.org/pers/hd/c/Cord:Matthieu"], "conf": "sigir", "year": "2018", "pages": 10}