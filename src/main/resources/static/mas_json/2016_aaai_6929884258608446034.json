{"title": "Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks.", "fields": ["feature engineering", "deep learning", "exploit", "robotics", "recurrent neural network"], "abstract": "This paper presents to the best of our knowledge the first end-to-end object tracking approach which directly maps from raw sensor input to object tracks in sensor space without requiring any feature engineering or system identification in the form of plant or sensor models. Specifically, our system accepts a stream of raw sensor data at one end and, in real-time, produces an estimate of the entire environment state at the output including even occluded objects. We achieve this by framing the problem as a deep learning task and exploit sequence models in the form of recurrent neural networks to learn a mapping from sensor measurements to object tracks. In particular, we propose a learning method based on a form of input dropout which allows learning in an unsupervised manner, only based on raw, occluded sensor data without access to ground-truth annotations. We demonstrate our approach using a synthetic dataset designed to mimic the task of tracking objects in 2D laser data \u2013 as commonly encountered in robotics applications \u2013 and show that it learns to track many dynamic objects despite occlusions and the presence of sensor noise.", "citation": "Citations (63)", "departments": ["University of Oxford", "University of Oxford"], "authors": ["Peter Ondruska.....http://dblp.org/pers/hd/o/Ondruska:Peter", "Ingmar Posner.....http://dblp.org/pers/hd/p/Posner:Ingmar"], "conf": "aaai", "year": "2016", "pages": 8}