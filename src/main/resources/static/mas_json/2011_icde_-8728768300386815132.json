{"title": "Mining large graphs: Algorithms, inference, and discoveries.", "fields": ["pathwidth", "hopcroft karp algorithm", "interval graph", "maximal independent set", "treewidth"], "abstract": "How do we find patterns and anomalies, on graphs with billions of nodes and edges, which do not fit in memory? How to use parallelism for such terabyte-scale graphs? In this work, we focus on inference, which often corresponds, intuitively, to \u201cguilt by association\u201d scenarios. For example, if a person is a drug-abuser, probably its friends are so, too; if a node in a social network is of male gender, his dates are probably females. We show how to do inference on such huge graphs through our proposed HAdoop Line graph Fixed Point (Ha-Lfp), an efficient parallel algorithm for sparse billion-scale graphs, using the Hadoop platform. Our contributions include (a) the design of Ha-Lfp, observing that it corresponds to a fixed point on a line graph induced from the original graph; (b) scalability analysis, showing that our algorithm scales up well with the number of edges, as well as with the number of machines; and (c) experimental results on two private, as well as two of the largest publicly available graphs \u2014 the Web Graphs from Yahoo! (6.6 billion edges and 0.24 Tera bytes), and the Twitter graph (3.7 billion edges and 0.13 Tera bytes). We evaluated our algorithm using M45, one of the top 50 fastest supercomputers in the world, and we report patterns and anomalies discovered by our algorithm, which would be invisible otherwise.", "citation": "Citations (69)", "departments": ["Carnegie Mellon University", "Carnegie Mellon University", "Carnegie Mellon University"], "authors": ["U. Kang.....http://dblp.org/pers/hd/k/Kang:U=", "Duen Horng Chau.....http://dblp.org/pers/hd/c/Chau:Duen_Horng", "Christos Faloutsos.....http://dblp.org/pers/hd/f/Faloutsos:Christos"], "conf": "icde", "year": "2011", "pages": 12}