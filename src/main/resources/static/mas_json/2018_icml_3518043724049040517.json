{"title": "Deep Linear Networks with Arbitrary Loss: All Local Minima Are Global.", "fields": ["maxima and minima", "mathematical optimization", "elementary proof", "mathematics", "differentiable function"], "abstract": "We consider deep linear networks with arbitrary differentiable loss. We provide a short and elementary proof of the following fact: all local minima are global minima if each hidden layer is wider than either the input or output layer.", "citation": "Citations (4)", "departments": ["Loyola Marymount University", "California State University, Long Beach"], "authors": ["Thomas Laurent.....http://dblp.org/pers/hd/l/Laurent:Thomas", "James von Brecht.....http://dblp.org/pers/hd/b/Brecht:James_von"], "conf": "icml", "year": "2018", "pages": 6}