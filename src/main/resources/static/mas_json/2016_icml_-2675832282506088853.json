{"title": "Smooth Imitation Learning for Online Sequence Prediction.", "fields": ["imitation", "convergence", "adaptive learning", "smoothness", "online machine learning"], "abstract": "We study the problem of smooth imitation learning for online sequence prediction, where the goal is to train a policy that can smoothly imitate demonstrated behavior in a dynamic and continuous environment in response to online, sequential context input. Since the mapping from context to behavior is often complex, we take a learning reduction approach to reduce smooth imitation learning to a regression problem using complex function classes that are regularized to ensure smoothness. We present a learning meta-algorithm that achieves fast and stable convergence to a good policy. Our approach enjoys several attractive properties, including being fully deterministic, employing an adaptive learning rate that can provably yield larger policy improvements compared to previous approaches, and the ability to ensure stable convergence. Our empirical results demonstrate significant performance gains over previous approaches.", "citation": "Citations (4)", "year": "2016", "departments": ["California Institute of Technology", "California Institute of Technology", "California Institute of Technology", "Disney Research"], "conf": "icml", "authors": ["Hoang Minh Le.....http://dblp.org/pers/hd/l/Le_0002:Hoang_Minh", "Andrew Kang.....http://dblp.org/pers/hd/k/Kang:Andrew", "Yisong Yue.....http://dblp.org/pers/hd/y/Yue:Yisong", "Peter Carr.....http://dblp.org/pers/hd/c/Carr_0001:Peter"], "pages": 9}