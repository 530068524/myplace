{"title": "NormFace: L", "fields": ["softmax function", "cosine similarity", "convolutional neural network", "hypersphere", "differentiable function"], "abstract": "Thanks to the recent developments of Convolutional Neural Networks, the performance of face verification methods has increased rapidly. In a typical face verification method, feature normalization is a critical step for boosting performance. This motivates us to introduce and study the effect of normalization during training. But we find this is non-trivial, despite normalization being differentiable. We identify and study four issues related to normalization through mathematical analysis, which yields understanding and helps with parameter settings. Based on this analysis we propose two strategies for training using normalized features. The first is a modification of softmax loss, which optimizes cosine similarity instead of inner-product. The second is a reformulation of metric learning by introducing an agent vector for each class. We show that both strategies, and small variants, consistently improve performance by between 0.2% to 0.4% on the LFW dataset based on two models. This is significant because the performance of the two models on LFW dataset is close to saturation at over 98%.", "citation": "Citations (14)", "departments": ["University of Electronic Science and Technology of China", "Johns Hopkins University", "University of Electronic Science and Technology of China", "Johns Hopkins University"], "authors": ["Feng Wang.....http://dblp.org/pers/hd/w/Wang_0015:Feng", "Xiang Xiang.....http://dblp.org/pers/hd/x/Xiang:Xiang", "Jian Cheng.....http://dblp.org/pers/hd/c/Cheng_0003:Jian", "Alan Loddon Yuille.....http://dblp.org/pers/hd/y/Yuille:Alan_Loddon"], "conf": "mm", "year": "2017", "pages": 9}