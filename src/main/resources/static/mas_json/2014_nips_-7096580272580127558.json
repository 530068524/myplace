{"title": "Learning the Learning Rate for Prediction with Expert Advice.", "fields": ["stability", "overfitting", "active learning", "instance based learning", "online machine learning"], "abstract": "Most standard algorithms for prediction with expert advice depend on a parameter called the learning rate. This learning rate needs to be large enough to fit the data well, but small enough to prevent overfitting. For the exponential weights algorithm, a sequence of prior work has established theoretical guarantees for higher and higher data-dependent tunings of the learning rate, which allow for increasingly aggressive learning. But in practice such theoretical tunings often still perform worse (as measured by their regret) than ad hoc tuning with an even higher learning rate. To close the gap between theory and practice we introduce an approach to learn the learning rate. Up to a factor that is at most (poly)logarithmic in the number of experts and the inverse of the learning rate, our method performs as well as if we would know the empirically best learning rate from a large range that includes both conservative small values and values that are much higher than those for which formal guarantees were previously available. Our method employs a grid of learning rates, yet runs in linear time regardless of the size of the grid.", "citation": "Citations (5)", "year": "2014", "departments": ["Queensland University of Technology", "Leiden University", "Centrum Wiskunde & Informatica"], "conf": "nips", "authors": ["Wouter M. Koolen.....http://dblp.org/pers/hd/k/Koolen:Wouter_M=", "Tim van Erven.....http://dblp.org/pers/hd/e/Erven:Tim_van", "Peter Gr\u00fcnwald.....http://dblp.org/pers/hd/g/Gr=uuml=nwald:Peter"], "pages": 9}