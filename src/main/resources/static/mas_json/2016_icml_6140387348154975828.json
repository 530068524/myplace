{"title": "Analysis of Deep Neural Networks with Extended Data Jacobian Matrix.", "fields": ["deep learning", "regularization", "network performance", "artificial neural network", "jacobian matrix and determinant"], "abstract": "Deep neural networks have achieved great success on a variety of machine learning tasks. There are many fundamental and open questions yet to be answered, however. We introduce the Extended Data Jacobian Matrix (EDJM) as an architecture-independent tool to analyze neural networks at the manifold of interest. The spectrum of the EDJM is found to be highly correlated with the complexity of the learned functions. After studying the effect of dropout, ensembles, and model distillation using EDJM, we propose a novel spectral regularization method, which improves network performance.", "citation": "Citations (4)", "year": "2016", "departments": ["University of Washington", "University of Toronto", "Microsoft", "University of Washington"], "conf": "icml", "authors": ["Shengjie Wang.....http://dblp.org/pers/hd/w/Wang:Shengjie", "Abdel-rahman Mohamed.....http://dblp.org/pers/hd/m/Mohamed:Abdel=rahman", "Rich Caruana.....http://dblp.org/pers/hd/c/Caruana:Rich", "Jeff A. Bilmes.....http://dblp.org/pers/hd/b/Bilmes:Jeff_A=", "Matthai Philipose.....http://dblp.org/pers/hd/p/Philipose:Matthai", "Matthew Richardson.....http://dblp.org/pers/hd/r/Richardson:Matthew", "Krzysztof Geras.....http://dblp.org/pers/hd/g/Geras:Krzysztof", "Gregor Urban.....http://dblp.org/pers/hd/u/Urban:Gregor", "\u00d6zlem Aslan.....http://dblp.org/pers/hd/a/Aslan:=Ouml=zlem"], "pages": 9}