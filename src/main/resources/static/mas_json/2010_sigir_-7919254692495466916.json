{"title": "Do user preferences and evaluation measures line up?", "fields": ["data mining", "learning to rank", "search engine", "information retrieval", "user experience design"], "abstract": "This paper presents results comparing user preference for search engine rankings with measures of effectiveness computed from a test collection. It establishes that preferences and evaluation measures correlate: systems measured as better on a test collection are preferred by users. This correlation is established for both \"conventional web retrieval\" and for retrieval that emphasizes diverse results. The nDCG measure is found to correlate best with user preferences compared to a selection of other well known measures. Unlike previous studies in this area, this examination involved a large population of users, gathered through crowd sourcing, exposed to a wide range of retrieval systems, test collections and search tasks. Reasons for user preferences were also gathered and analyzed. The work revealed a number of new results, but also showed that there is much scope for future work refining effectiveness measures to better capture user preferences.", "citation": "Citations (130)", "departments": ["University of Sheffield", "University of Sheffield", "University of Sheffield", "University of Sheffield"], "authors": ["Mark Sanderson.....http://dblp.org/pers/hd/s/Sanderson:Mark", "Monica Lestari Paramita.....http://dblp.org/pers/hd/p/Paramita:Monica_Lestari", "Paul D. Clough.....http://dblp.org/pers/hd/c/Clough:Paul_D=", "Evangelos Kanoulas.....http://dblp.org/pers/hd/k/Kanoulas:Evangelos"], "conf": "sigir", "year": "2010", "pages": 8}