{"title": "Efficient Sparse Matrix-Vector Multiplication on GPUs Using the CSR Storage Format.", "fields": ["linear algebra", "row", "sparse matrix vector multiplication", "sparse matrix", "scratchpad memory"], "abstract": "The performance of sparse matrix vector multiplication (SpMV) is important to computational scientists. Compressed sparse row (CSR) is the most frequently used format to store sparse matrices. However, CSR-based SpMV on graphics processing units (GPUs) has poor performance due to irregular memory access patterns, load imbalance, and reduced parallelism. This has led researchers to propose new storage formats. Unfortunately, dynamically transforming CSR into these formats has significant runtime and storage overheads.   We propose a novel algorithm, CSR-Adaptive, which keeps the CSR format intact and maps well to GPUs. Our implementation addresses the aforementioned challenges by (i) efficiently accessing DRAM by streaming data into the local scratchpad memory and (ii) dynamically assigning different numbers of rows to each parallel GPU compute unit. CSR-Adaptive achieves an average speedup of 14.7 \u00d7 over existing CSR-based algorithms and 2.3\u00d7 over clSpMV cocktail, which uses an assortment of matrix formats.", "citation": "Citations (99)", "departments": ["Advanced Micro Devices", "Advanced Micro Devices"], "authors": ["Joseph L. Greathouse.....http://dblp.org/pers/hd/g/Greathouse:Joseph_L=", "Mayank Daga.....http://dblp.org/pers/hd/d/Daga:Mayank"], "conf": "sc", "year": "2014", "pages": 12}