{"title": "Algorithms for Infinitely Many-Armed Bandits.", "fields": ["logarithm", "upper and lower bounds", "regret", "multi armed bandit", "machine learning"], "abstract": "We consider multi-armed bandit problems where the number of arms is larger than the possible number of experiments. We make a stochastic assumption on the mean-reward of a new selected arm which characterizes its probability of being a near-optimal arm. Our assumption is weaker than in previous works. We describe algorithms based on upper-confidence-bounds applied to a restricted set of randomly selected arms and provide upper-bounds on the resulting expected regret. We also derive a lower-bound which matches (up to a logarithmic factor) the upper-bound in some cases.", "citation": "Citations (121)", "year": "2008", "departments": ["University of Michigan", "\u00c9cole des ponts ParisTech", "French Institute for Research in Computer Science and Automation"], "conf": "nips", "authors": ["Yizao Wang.....http://dblp.org/pers/hd/w/Wang:Yizao", "Jean-Yves Audibert.....http://dblp.org/pers/hd/a/Audibert:Jean=Yves", "R\u00e9mi Munos.....http://dblp.org/pers/hd/m/Munos:R=eacute=mi"], "pages": 8}