{"title": "Distributionally Robust Markov Decision Processes.", "fields": ["confidence region", "partially observable markov decision process", "optimal decision", "exploit", "probabilistic logic", "time complexity", "markov decision process"], "abstract": "We consider Markov decision processes where the values of the parameters are uncertain. This uncertainty is described by a sequence of nested sets (that is, each set contains the previous one), each of which corresponds to a probabilistic guarantee for a different confidence level. Consequently, a set of admissible probability distributions of the unknown parameters is specified. This formulation models the case where the decision maker is aware of and wants to exploit some (yet imprecise) a priori information of the distribution of parameters, and it arises naturally in practice where methods for estimating the confidence region of parameters abound. We propose a decision criterion based on distributional robustness: the optimal strategy maximizes the expected total reward under the most adversarial admissible probability distributions. We show that finding the optimal distributionally robust strategy can be reduced to the standard robust MDP where parameters are known to belong to a single uncertainty set; hence, it can be computed in polynomial time under mild technical conditions.", "citation": "Citations (71)", "departments": ["National University of Singapore", "Technion \u2013 Israel Institute of Technology", "University of Texas at Austin", "Technion \u2013 Israel Institute of Technology"], "authors": ["Huan Xu.....http://dblp.org/pers/hd/x/Xu:Huan", "Shie Mannor.....http://dblp.org/pers/hd/m/Mannor:Shie"], "conf": "nips", "year": "2010", "pages": 9}