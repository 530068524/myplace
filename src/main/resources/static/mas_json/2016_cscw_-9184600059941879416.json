{"title": "Learnersourcing Personalized Hints.", "fields": ["crowdsourcing", "human computer interaction", "collective intelligence", "computation", "workflow"], "abstract": "We introduce a theoretical framework called precision crowdsourcing whose goal is to help turn online information consumers into information contributors. The framework looks at the timing and nature of the requests made of users and the feedback provided to users with the goal of increasing long-term contribution and engagement in the site or system. We present the results of a field experiment in which almost 3000 users were asked to tag movies (plus a null control group) as we varied the selection of task (popular/obscure), timing of requests (immediate or varying delays), and relational rhetoric (neutral, system reciprocal, other users reciprocal) of the requests. We found that asking increases tags provided overall, though asking generally decreases the provision of unprompted tags. Users were more likely to comply with our request when we asked them to tag obscure movies and when we used reciprocal request rhetoric.", "citation": "Not cited", "departments": ["University of Minnesota", "University of Minnesota", "University of Minnesota", "University of Minnesota", "University of Minnesota"], "authors": ["Elena L. Glassman.....http://dblp.org/pers/hd/g/Glassman:Elena_L=", "Aaron Lin.....http://dblp.org/pers/hd/l/Lin:Aaron", "Carrie J. Cai.....http://dblp.org/pers/hd/c/Cai:Carrie_J=", "Robert C. Miller.....http://dblp.org/pers/hd/m/Miller:Robert_C="], "conf": "cscw", "year": "2016", "pages": 11}