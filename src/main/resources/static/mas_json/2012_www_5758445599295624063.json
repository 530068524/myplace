{"title": "Mr. LDA: a flexible large scale topic modeling package using variational inference in MapReduce.", "fields": ["implementation", "prior probability", "topic model", "dynamic topic model", "latent dirichlet allocation"], "abstract": "Latent Dirichlet Allocation (LDA) is a popular topic modeling technique for exploring document collections. Because of the increasing prevalence of large datasets, there is a need to improve the scalability of inference for LDA. In this paper, we introduce a novel and flexible large scale topic modeling package in MapReduce (Mr. LDA). As opposed to other techniques which use Gibbs sampling, our proposed framework uses variational inference, which easily fits into a distributed environment. More importantly, this variational implementation, unlike highly tuned and specialized implementations based on Gibbs sampling, is easily extensible. We demonstrate two extensions of the models possible with this scalable framework: informed priors to guide topic discovery and extracting topics from a multilingual corpus. We compare the scalability of Mr. LDA against Mahout, an existing large scale topic modeling package. Mr. LDA out-performs Mahout both in execution speed and held-out likelihood.", "citation": "Citations (148)", "departments": ["University of Maryland, College Park", "University of Maryland, College Park", "University of Maryland, College Park", "University of Maryland, College Park"], "authors": ["Ke Zhai.....http://dblp.org/pers/hd/z/Zhai_0001:Ke", "Jordan L. Boyd-Graber.....http://dblp.org/pers/hd/b/Boyd=Graber:Jordan_L=", "Nima Asadi.....http://dblp.org/pers/hd/a/Asadi_0001:Nima", "Mohamad L. Alkhouja.....http://dblp.org/pers/hd/a/Alkhouja:Mohamad_L="], "conf": "www", "year": "2012", "pages": 10}