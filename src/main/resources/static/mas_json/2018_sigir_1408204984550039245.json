{"title": "Privacy-aware Ranking with Tree Ensembles on the Cloud.", "fields": ["ranking", "open research", "test data", "gradient boosting", "random forest"], "abstract": "Tree-based ensembles are widely used for document ranking but supporting such a method efficiently under a privacy-preserving constraint on the cloud is an open research problem. The main challenge is that letting the cloud server perform ranking computation may unsafely reveal privacy-sensitive information. To address privacy with tree-based server-side ranking, this paper proposes to reduce the learning-to-rank model dependence on composite features as a trade-off, and develops comparison-preserving mapping to hide feature values and tree thresholds. To justify the above approach, the presented analysis shows that a decision tree with simplifiable composite features can be transformed into another tree using raw features without increasing the training accuracy loss. This paper analyzes the privacy properties of the proposed scheme, and compares the relevance of gradient boosting regression trees, LambdaMART, and random forests using raw features for several test data sets under the privacy consideration, and assesses the competitiveness of a hybrid model based on these algorithms.", "citation": "Not cited", "departments": ["University of California, Santa Barbara", "University of California, Santa Barbara", "University of California, Santa Barbara", "University of California, Santa Barbara"], "authors": ["Shiyu Ji.....http://dblp.org/pers/hd/j/Ji:Shiyu", "Jinjin Shao.....http://dblp.org/pers/hd/s/Shao:Jinjin", "Daniel Agun.....http://dblp.org/pers/hd/a/Agun:Daniel", "Tao Yang.....http://dblp.org/pers/hd/y/Yang_0009:Tao"], "conf": "sigir", "year": "2018", "pages": 10}