{"title": "A Characterisation of Strategy-Proofness for Grounded Argumentation Semantics.", "fields": ["machine learning", "argumentation theory", "artificial intelligence", "semantics", "mechanism design"], "abstract": "Recently, Argumentation Mechanism Design (ArgMD) was introduced as a new paradigm for studying argumentation among self-interested agents using game-theoretic techniques. Preliminary results showed a condition under which a direct mechanism based on Dung's grounded semantics is strategy-proof (i.e. truth enforcing). But these early results dealt with a highly restricted form of agent preferences, and assumed agents can only hide, but not lie about, arguments. In this paper, we characterise strategy-proofness under grounded semantics for a more realistic preference class (namely, focal arguments). We also provide the first analysis of the case where agents can lie.", "citation": "Citations (68)", "departments": ["British University in Dubai", "University of Waterloo", "Universidad Nacional del Sur"], "authors": ["Iyad Rahwan.....http://dblp.org/pers/hd/r/Rahwan:Iyad", "Kate Larson.....http://dblp.org/pers/hd/l/Larson:Kate", "Fernando A. Tohm\u00e9.....http://dblp.org/pers/hd/t/Tohm=eacute=:Fernando_A="], "conf": "ijcai", "year": "2009", "pages": 6}