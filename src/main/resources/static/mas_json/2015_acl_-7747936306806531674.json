{"title": "Feature Selection in Kernel Space: A Case Study on Dependency Parsing.", "fields": ["radial basis function kernel", "top down parsing", "kernel embedding of distributions", "tree kernel", "bottom up parsing"], "abstract": "Given a set of basic binary features, we propose a new L1 norm SVM based feature selection method that explicitly selects the features in their polynomial or tree kernel spaces. The efficiency comes from the anti-monotone property of the subgradients: the subgradient with respect to a combined feature can be bounded by the subgradient with respect to each of its component features, and a feature can be pruned safely without further consideration if its corresponding subgradient is not steep enough. We conduct experiments on the English dependency parsing task with a third order graph-based parser. Benefiting from the rich features selected in the tree kernel space, our model achieved the best reported unlabeled attachment score of 93.72 without using any additional resource.", "citation": "Citations (1)", "year": "2015", "departments": ["University of Texas at Dallas", "Computer Science"], "conf": "acl", "authors": ["Xian Qian.....http://dblp.org/pers/hd/q/Qian:Xian", "Yang Liu.....http://dblp.org/pers/hd/l/Liu_0004:Yang"], "pages": 11}