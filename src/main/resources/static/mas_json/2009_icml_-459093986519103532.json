{"title": "Stochastic search using the natural gradient.", "fields": ["fitness approximation", "evolution strategy", "fisher information", "natural evolution strategy", "machine learning"], "abstract": "To optimize unknown 'fitness' functions, we present Natural Evolution Strategies, a novel algorithm that constitutes a principled alternative to standard stochastic search methods. It maintains a multinormal distribution on the set of solution candidates. The Natural Gradient is used to update the distribution's parameters in the direction of higher expected fitness, by efficiently calculating the inverse of the exact Fisher information matrix whereas previous methods had to use approximations. Other novel aspects of our method include optimal fitness baselines and importance mixing, a procedure adjusting batches with minimal numbers of fitness evaluations. The algorithm yields competitive results on a number of benchmarks.", "citation": "Citations (74)", "departments": ["Dalle Molle Institute for Artificial Intelligence Research", "Dalle Molle Institute for Artificial Intelligence Research", "Dalle Molle Institute for Artificial Intelligence Research", "Dalle Molle Institute for Artificial Intelligence Research"], "authors": ["Yi Sun.....http://dblp.org/pers/hd/s/Sun_0003:Yi", "Daan Wierstra.....http://dblp.org/pers/hd/w/Wierstra:Daan", "Tom Schaul.....http://dblp.org/pers/hd/s/Schaul:Tom", "J\u00fcrgen Schmidhuber.....http://dblp.org/pers/hd/s/Schmidhuber:J=uuml=rgen"], "conf": "icml", "year": "2009", "pages": 8}