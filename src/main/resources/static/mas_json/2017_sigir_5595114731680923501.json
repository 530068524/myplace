{"title": "Personalized Response Generation via Domain adaptation.", "fields": ["domain adaptation", "data mining", "gradient method", "reinforcement learning", "machine learning"], "abstract": "In this paper, we propose a novel personalized response generation model via domain adaptation (PRG-DM). First, we learn the human responding style from large general data (without user-specific information). Second, we fine tune the model on a small size of personalized data to generate personalized responses with a dual learning mechanism. Moreover, we propose three new rewards to characterize good conversations that are personalized, informative and grammatical. We employ the policy gradient method to generate highly rewarded responses. Experimental results show that our model can generate better personalized responses for different users.", "citation": "Citations (1)", "departments": ["Tencent", "Zhejiang University", "Tencent", "Shenzhen University", "South China Normal University"], "authors": ["Min Yang.....http://dblp.org/pers/hd/y/Yang_0007:Min", "Zhou Zhao.....http://dblp.org/pers/hd/z/Zhao:Zhou", "Wei Zhao.....http://dblp.org/pers/hd/z/Zhao:Wei", "Xiaojun Chen.....http://dblp.org/pers/hd/c/Chen_0006:Xiaojun", "Jia Zhu.....http://dblp.org/pers/hd/z/Zhu:Jia", "Lianqiang Zhou.....http://dblp.org/pers/hd/z/Zhou:Lianqiang", "Zigang Cao.....http://dblp.org/pers/hd/c/Cao:Zigang"], "conf": "sigir", "year": "2017", "pages": 4}