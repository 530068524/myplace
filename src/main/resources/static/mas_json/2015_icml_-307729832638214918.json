{"title": "Universal Value Function Approximators.", "fields": ["embedding", "universal value", "reinforcement learning", "machine learning", "mathematical analysis", "mathematics", "supervised learning"], "abstract": "Value functions are a core component of reinforcement learning systems. The main idea is to to construct a single function approximator V (s; \u03b8) that estimates the long-term reward from any state s, using parameters \u03b8. In this paper we introduce universal value function approximators (UVFAs) V (s, g; \u03b8) that generalise not just over states s but also over goals g. We develop an efficient technique for supervised learning of UVFAs, by factoring observed values into separate embedding vectors for state and goal, and then learning a mapping from s and g to these factored embedding vectors. We show how this technique may be incorporated into a reinforcement learning algorithm that updates the UVFA solely from observed rewards. Finally, we demonstrate that a UVFA can successfully generalise to previously unseen goals.", "citation": "Not cited", "year": "2015", "departments": ["Google", "Google", "Google", "Google"], "conf": "icml", "authors": ["Tom Schaul.....http://dblp.org/pers/hd/s/Schaul:Tom", "Daniel Horgan.....http://dblp.org/pers/hd/h/Horgan:Daniel", "Karol Gregor.....http://dblp.org/pers/hd/g/Gregor:Karol", "David Silver.....http://dblp.org/pers/hd/s/Silver:David"], "pages": 9}