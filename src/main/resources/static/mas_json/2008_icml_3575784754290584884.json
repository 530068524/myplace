{"title": "SVM optimization: inverse dependence on training set size.", "fields": ["training set", "inverse", "stochastic gradient descent", "gradient descent", "subgradient method"], "abstract": "We discuss how the runtime of SVM optimization should  decrease  as the size of the training data increases. We present theoretical and empirical results demonstrating how a simple subgradient descent approach indeed displays such behavior, at least for linear kernels.", "citation": "Citations (253)", "year": "2008", "departments": ["Toyota Technological Institute at Chicago", "Toyota Technological Institute at Chicago"], "conf": "icml", "authors": ["Shai Shalev-Shwartz.....http://dblp.org/pers/hd/s/Shalev=Shwartz:Shai", "Nathan Srebro.....http://dblp.org/pers/hd/s/Srebro:Nathan"], "pages": 8}