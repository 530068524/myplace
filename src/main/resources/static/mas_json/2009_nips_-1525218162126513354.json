{"title": "Improving Existing Fault Recovery Policies.", "fields": ["data center", "controller", "downtime", "partially observable markov decision process", "policy learning"], "abstract": "An automated recovery system is a key component in a large data center. Such a system typically employs a hand-made controller created by an expert. While such controllers capture many important aspects of the recovery process, they are often not systematically optimized to reduce costs such as server downtime. In this paper we describe a passive policy learning approach for improving existing recovery policies without exploration. We explain how to use data gathered from the interactions of the hand-made controller with the system, to create an improved controller. We suggest learning an indefinite horizon Partially Observable Markov Decision Process, a model for decision making under uncertainty, and solve it using a point-based algorithm. We describe the complete process, starting with data gathering, model learning, model checking procedures, and computing a policy.", "citation": "Citations (5)", "year": "2009", "departments": ["Ben-Gurion University of the Negev", "Microsoft"], "conf": "nips", "authors": ["Guy Shani.....http://dblp.org/pers/hd/s/Shani:Guy", "Christopher Meek.....http://dblp.org/pers/hd/m/Meek:Christopher"], "pages": 9}