{"title": "Natural Language Acquisition and Grounding for Embodied Robotic Systems.", "fields": ["clips", "graph", "spatial relation", "probabilistic logic", "parsing"], "abstract": "We present a cognitively plausible novel framework capable of learning the grounding in visual semantics and the grammar of natural language commands given to a robot in a table top environment. The input to the system consists of video clips of a manually controlled robot arm, paired with natural language commands describing the action. No prior knowledge is assumed about the meaning of words, or the structure of the language, except that there are different classes of words (corresponding to observable actions, spatial relations, and objects and their observable properties). The learning process automatically clusters the continuous perceptual spaces into concepts corresponding to linguistic input. A novel relational graph representation is used to build connections between language and vision. As well as the grounding of language to perception, the system also induces a set of probabilistic grammar rules. The knowledge learned is used to parse new commands involving previously unseen objects.", "citation": "Citations (9)", "departments": ["University of Leeds", "University of Leeds", "University of Leeds", "University of Leeds"], "authors": ["Muhannad Al-Omari.....http://dblp.org/pers/hd/a/Al=Omari:Muhannad", "Paul Duckworth.....http://dblp.org/pers/hd/d/Duckworth:Paul", "David C. Hogg.....http://dblp.org/pers/hd/h/Hogg:David_C=", "Anthony G. Cohn.....http://dblp.org/pers/hd/c/Cohn:Anthony_G="], "conf": "aaai", "year": "2017", "pages": 8}