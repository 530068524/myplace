{"title": "Multi-view Domain Generalization for Visual Recognition.", "fields": ["machine learning", "exploit", "support vector machine", "domain adaptation", "matrix"], "abstract": "In this paper, we propose a new multi-view domain generalization (MVDG) approach for visual recognition, in which we aim to use the source domain samples with multiple types of features (i.e., multi-view features) to learn robust classifiers that can generalize well to any unseen target domain. Considering the recent works show the domain generalization capability can be enhanced by fusing multiple SVM classifiers, we build upon exemplar SVMs to learn a set of SVM classifiers by using one positive sample and all negative samples in the source domain each time. When the source domain samples come from multiple latent domains, we expect the weight vectors of exemplar SVM classifiers can be organized into multiple hidden clusters. To exploit such cluster structure, we organize the weight vectors learnt on each view as a weight matrix and seek the low-rank representation by reconstructing this weight matrix using itself as the dictionary. To enforce the consistency of inherent cluster structures discovered from the weight matrices learnt on different views, we introduce a new regularizer to minimize the mismatch between any two representation matrices on different views. We also develop an efficient alternating optimization algorithm and further extend our MVDG approach for domain adaptation by exploiting the manifold structure of unlabeled target domain samples. Comprehensive experiments for visual recognition clearly demonstrate the effectiveness of our approaches for domain generalization and domain adaptation.", "citation": "Citations (8)", "year": "2015", "departments": ["Nanyang Technological University", "ETH Zurich", "Nanyang Technological University"], "conf": "iccv", "authors": ["Li Niu.....http://dblp.org/pers/hd/n/Niu_0002:Li", "Wen Li.....http://dblp.org/pers/hd/l/Li_0001:Wen", "Dong Xu.....http://dblp.org/pers/hd/x/Xu_0001:Dong"], "pages": 9}