{"title": "Gradient boosted feature selection.", "fields": ["data set", "scalability", "minimum redundancy feature selection", "gradient boosting", "feature"], "abstract": "A feature selection algorithm should ideally satisfy four conditions: reliably extract relevant features; be able to identify non-linear feature interactions; scale linearly with the number of features and dimensions; allow the incorporation of known sparsity structure. In this work we propose a novel feature selection algorithm, Gradient Boosted Feature Selection (GBFS), which satisfies all four of these requirements. The algorithm is flexible, scalable, and surprisingly straight-forward to implement as it is based on a modification of Gradient Boosted Trees. We evaluate GBFS on several real world data sets and show that it matches or outperforms other state of the art feature selection algorithms. Yet it scales to larger data set sizes and naturally allows for domain-specific side information.", "citation": "Citations (25)", "departments": ["Washington University in St. Louis", "Tsinghua University", "Washington University in St. Louis", "GraphLab, Seattle, USA"], "authors": ["Zhixiang Eddie Xu.....http://dblp.org/pers/hd/x/Xu:Zhixiang_Eddie", "Gao Huang.....http://dblp.org/pers/hd/h/Huang:Gao", "Kilian Q. Weinberger.....http://dblp.org/pers/hd/w/Weinberger:Kilian_Q=", "Alice X. Zheng.....http://dblp.org/pers/hd/z/Zheng:Alice_X="], "conf": "kdd", "year": "2014", "pages": 10}