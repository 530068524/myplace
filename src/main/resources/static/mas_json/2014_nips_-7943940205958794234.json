{"title": "Sampling for Inference in Probabilistic Models with Fast Bayesian Quadrature.", "fields": ["importance sampling", "probabilistic logic", "markov chain monte carlo", "marginal likelihood", "variable elimination"], "abstract": "We propose a novel sampling framework for inference in probabilistic models: an active learning approach that converges more quickly (in wall-clock time) than Markov chain Monte Carlo (MCMC) benchmarks. The central challenge in probabilistic inference is numerical integration, to average over ensembles of models or unknown (hyper-)parameters (for example to compute the marginal likelihood or a partition function). MCMC has provided approaches to numerical integration that deliver state-of-the-art inference, but can suffer from sample inefficiency and poor convergence diagnostics. Bayesian quadrature techniques offer a model-based solution to such problems, but their uptake has been hindered by prohibitive computation costs. We introduce a warped model for probabilistic integrands (likelihoods) that are known to be non-negative, permitting a cheap active learning scheme to optimally select sample locations. Our algorithm is demonstrated to offer faster convergence (in seconds) relative to simple Monte Carlo and annealed importance sampling on both synthetic and real-world examples.", "citation": "Citations (22)", "year": "2014", "departments": ["University of Oxford", "University of Oxford", "University of Bonn", "Max Planck Society", "University of Oxford"], "conf": "nips", "authors": ["Tom Gunter.....http://dblp.org/pers/hd/g/Gunter:Tom", "Michael A. Osborne.....http://dblp.org/pers/hd/o/Osborne:Michael_A=", "Roman Garnett.....http://dblp.org/pers/hd/g/Garnett:Roman", "Philipp Hennig.....http://dblp.org/pers/hd/h/Hennig:Philipp", "Stephen J. Roberts.....http://dblp.org/pers/hd/r/Roberts:Stephen_J="], "pages": 9}