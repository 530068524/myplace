{"title": "Parallel exhaustive search without coordination.", "fields": ["division", "workload", "linear search", "brute force search", "peek"], "abstract": "We analyse parallel algorithms in the context of  exhaustive search  over totally ordered sets. Imagine an infinite list of \u201cboxes\u201d, with a \u201ctreasure\u201d hidden in one of them, where the boxes\u2019 order reflects the importance of finding the treasure in a given box. At each time step, a search protocol executed by a searcher has the ability to peek into one box, and see whether the treasure is present or not. Clearly, the best strategy of a single searcher would be to open the boxes one by one, in increasing order. Moreover, by equally dividing the workload between them,  k \u00a0searchers can trivially find the treasure  k  times faster than one searcher. However, this straightforward strategy is very sensitive to failures ( e.g.,  crashes of processors), and overcoming this issue seems to require a large amount of communication. We therefore address the question of designing parallel search algorithms maximizing their  speed-up  and maintaining high levels of  robustness , while minimizing the amount of resources for coordination. Based on the observation that algorithms that avoid communication are inherently robust, we focus our attention on identifying the best running time performance of  non-coordinating  algorithms. Specifically, we devise non-coordinating algorithms that achieve a speed-up of 9/8 for two searchers, a speed-up of 4/3 for three searchers, and in general, a speed-up of  k /4(1+1/ k ) 2  for any  k \u2265 1 searchers. Thus, asymptotically, the speed-up is only four times worse compared to the case of full coordination. Moreover, these bounds are tight in a strong sense as no non-coordinating search algorithm can achieve better speed-ups. Our algorithms are surprisingly simple and hence applicable. However they are memory intensive and so we suggest a practical, memory efficient version, with a speed-up of ( k  2  \u2212 1)/4 k . That is, it is only a factor of ( k +1)/( k \u22121) slower than the optimal algorithm. Overall, we highlight that, in faulty contexts in which coordination between the searchers is technically difficult to implement, intrusive with respect to privacy, and/or costly in term of resources, it might well be worth giving up on coordination, and simply run our non-coordinating exhaustive search algorithms.", "citation": "Citations (4)", "year": "2016", "departments": ["University of Paris", "University of Paris", "Weizmann Institute of Science"], "conf": "stoc", "authors": ["Pierre Fraigniaud.....http://dblp.org/pers/hd/f/Fraigniaud:Pierre", "Amos Korman.....http://dblp.org/pers/hd/k/Korman:Amos", "Yoav Rodeh.....http://dblp.org/pers/hd/r/Rodeh:Yoav"], "pages": 12}