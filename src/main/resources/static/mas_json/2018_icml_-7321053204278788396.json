{"title": "Representation Tradeoffs for Hyperbolic Embeddings.", "fields": ["multidimensional scaling", "metric space", "curse of dimensionality", "embedding", "hyperbolic space"], "abstract": "Hyperbolic embeddings offer excellent quality with few dimensions when embedding hierarchical data structures like synonym or type hierarchies. Given a tree, we give a combinatorial construction that embeds the tree in hyperbolic space with arbitrarily low distortion without using optimization. On WordNet, our combinatorial embedding obtains a mean-average-precision of 0.989 with only two dimensions, while Nickel et al.'s recent construction obtains 0.87 using 200 dimensions. We provide upper and lower bounds that allow us to characterize the precision-dimensionality tradeoff inherent in any hyperbolic embedding. To embed general metric spaces, we propose a hyperbolic generalization of multidimensional scaling (h-MDS). We show how to perform exact recovery of hyperbolic points from distances, provide a perturbation analysis, and give a recovery result that allows us to reduce dimensionality. The h-MDS approach offers consistently low distortion even with few dimensions across several datasets. Finally, we extract lessons from the algorithms and theory above to design a PyTorch-based implementation that can handle incomplete information and is scalable.", "citation": "Citations (2)", "departments": ["Cornell University", "Stanford University", "Stanford University"], "authors": ["Frederic Sala.....http://dblp.org/pers/hd/s/Sala:Frederic", "Christopher De Sa.....http://dblp.org/pers/hd/s/Sa:Christopher_De", "Albert Gu.....http://dblp.org/pers/hd/g/Gu:Albert", "Christopher R\u00e9.....http://dblp.org/pers/hd/r/R=eacute=:Christopher"], "conf": "icml", "year": "2018", "pages": 10}