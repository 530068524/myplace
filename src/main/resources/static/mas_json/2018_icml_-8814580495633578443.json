{"title": "Subspace Embedding and Linear Regression with Orlicz Norm.", "fields": ["embedding", "binary logarithm", "low rank approximation", "subspace topology", "norm"], "abstract": "We consider a generalization of the classic linear regression problem to the case when the loss is an Orlicz norm. An Orlicz norm is parameterized by a non-negative convex function $G:\\mathbb{R}_+\\rightarrow\\mathbb{R}_+$ with $G(0)=0$: the Orlicz norm of a vector $x\\in\\mathbb{R}^n$ is defined as $ \\|x\\|_G=\\inf\\left\\{\\alpha>0\\large\\mid\\sum_{i=1}^n G(|x_i|/\\alpha)\\leq 1\\right\\}. $ We consider the cases where the function $G(\\cdot)$ grows subquadratically. Our main result is based on a new oblivious embedding which embeds the column space of a given matrix $A\\in\\mathbb{R}^{n\\times d}$ with Orlicz norm into a lower dimensional space with $\\ell_2$ norm. Specifically, we show how to efficiently find an embedding matrix $S\\in\\mathbb{R}^{m\\times n},m", "citation": "Not cited", "departments": ["Columbia University", "Columbia University", "Columbia University", "Columbia University"], "authors": ["Alexandr Andoni.....http://dblp.org/pers/hd/a/Andoni:Alexandr", "Chengyu Lin.....http://dblp.org/pers/hd/l/Lin:Chengyu", "Ying Sheng.....http://dblp.org/pers/hd/s/Sheng:Ying", "Peilin Zhong.....http://dblp.org/pers/hd/z/Zhong:Peilin", "Ruiqi Zhong.....http://dblp.org/pers/hd/z/Zhong:Ruiqi"], "conf": "icml", "year": "2018", "pages": 10}