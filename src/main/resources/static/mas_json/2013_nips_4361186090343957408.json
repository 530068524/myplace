{"title": "Variational Planning for Graph-based MDPs.", "fields": ["graph bandwidth", "kullback leibler divergence", "moral graph", "markov decision process", "belief propagation"], "abstract": "Markov Decision Processes (MDPs) are extremely useful for modeling and solving sequential decision making problems. Graph-based MDPs provide a compact representation for MDPs with large numbers of random variables. However, the complexity of exactly solving a graph-based MDP usually grows exponentially in the number of variables, which limits their application. We present a new variational framework to describe and solve the planning problem of MDPs, and derive both exact and approximate planning algorithms. In particular, by exploiting the graph structure of graph-based MDPs, we propose a factored variational value iteration algorithm in which the value function is first approximated by the multiplication of local-scope value functions, then solved by minimizing a Kullback-Leibler (KL) divergence. The KL divergence is optimized using the belief propagation algorithm, with complexity exponential in only the cluster size of the graph. Experimental comparison on different models shows that our algorithm outperforms existing approximation algorithms at finding good policies.", "citation": "Citations (9)", "departments": ["Tsinghua University", "University of California, Irvine", "Tsinghua University", "University of California, Irvine"], "authors": ["Qiang Cheng.....http://dblp.org/pers/hd/c/Cheng:Qiang", "Qiang Liu.....http://dblp.org/pers/hd/l/Liu_0001:Qiang", "Feng Chen.....http://dblp.org/pers/hd/c/Chen_0007:Feng", "Alexander T. Ihler.....http://dblp.org/pers/hd/i/Ihler:Alexander_T="], "conf": "nips", "year": "2013", "pages": 9}