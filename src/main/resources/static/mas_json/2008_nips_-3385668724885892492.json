{"title": "Fast Rates for Regularized Objectives.", "fields": ["oracle", "convex function", "regularization", "inequality", "convexity"], "abstract": "We study convergence properties of empirical minimization of a stochastic strongly convex objective, where the stochastic component is linear. We show that the value attained by the empirical minimizer converges to the optimal value with rate 1/n. The result applies, in particular, to the SVM objective. Thus, we obtain a rate of 1/n on the convergence of the SVM objective (with fixed regularization parameter) to its infinite data limit. We demonstrate how this is essential for obtaining certain type of oracle inequalities for SVMs. The results extend also to approximate minimization as well as to strong convexity with respect to an arbitrary norm, and so also to objectives regularized using other lp norms.", "citation": "Citations (98)", "year": "2008", "departments": ["Toyota Technological Institute", "Toyota Technological Institute", "Toyota Technological Institute"], "conf": "nips", "authors": ["Karthik Sridharan.....http://dblp.org/pers/hd/s/Sridharan:Karthik", "Shai Shalev-Shwartz.....http://dblp.org/pers/hd/s/Shalev=Shwartz:Shai", "Nathan Srebro.....http://dblp.org/pers/hd/s/Srebro:Nathan"], "pages": 8}