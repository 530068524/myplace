{"title": "Independent factor topic models.", "fields": ["perplexity", "latent class model", "topic model", "dynamic topic model", "latent dirichlet allocation"], "abstract": "Topic models such as Latent Dirichlet Allocation (LDA) and Correlated Topic Model (CTM) have recently emerged as powerful statistical tools for text document modeling. In this paper, we improve upon CTM and propose Independent Factor Topic Models (IFTM) which use linear latent variable models to uncover the hidden sources of correlation between topics. There are 2 main contributions of this work. First, by using a sparse source prior model, we can directly visualize sparse patterns of topic correlations. Secondly, the conditional independence assumption implied in the use of latent source variables allows the objective function to factorize, leading to a fast Newton-Raphson based variational inference algorithm. Experimental results on synthetic and real data show that IFTM runs on average 3--5 times faster than CTM, while giving competitive performance as measured by perplexity and loglikelihood of held-out data.", "citation": "Citations (17)", "departments": ["University of California, San Diego", "University of California, San Francisco", "Golden Metallic ... n Francisco, CA"], "authors": ["Duangmanee Putthividhya.....http://dblp.org/pers/hd/p/Putthividhya:Duangmanee", "Hagai Thomas Attias.....http://dblp.org/pers/hd/a/Attias:Hagai_Thomas", "Srikantan S. Nagarajan.....http://dblp.org/pers/hd/n/Nagarajan:Srikantan_S="], "conf": "icml", "year": "2009", "pages": 8}