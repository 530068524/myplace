{"title": "An analysis of reinforcement learning with function approximation.", "fields": ["function approximation", "reinforcement learning", "decision problem", "stochastic control", "q learning"], "abstract": "We address the problem of computing the optimal Q-function in Markov decision problems with infinite state-space. We analyze the convergence properties of several variations of  Q -learning when combined with function approximation, extending the analysis of TD-learning in (Tsitsiklis & Van Roy, 1996a) to stochastic control settings. We identify conditions under which such approximate methods converge with probability 1. We conclude with a brief discussion on the general applicability of our results and compare them with several related works.", "citation": "Citations (113)", "year": "2008", "departments": ["Carnegie Mellon University", "University of Illinois at Urbana\u2013Champaign", "Institute for S ... isboa, Portugal"], "conf": "icml", "authors": ["Francisco S. Melo.....http://dblp.org/pers/hd/m/Melo:Francisco_S=", "Sean P. Meyn.....http://dblp.org/pers/hd/m/Meyn:Sean_P=", "M. Isabel Ribeiro.....http://dblp.org/pers/hd/r/Ribeiro:M=_Isabel"], "pages": 8}