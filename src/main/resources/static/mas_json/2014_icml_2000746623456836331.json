{"title": "Fast Stochastic Alternating Direction Method of Multipliers.", "fields": ["rate of convergence", "mathematical optimization", "mathematics", "lasso"], "abstract": "We propose a new stochastic alternating direction method of multipliers (ADMM) algorithm, which incrementally approximates the full gradient in the linearized ADMM formulation. Besides having a low per-iteration complexity as existing stochastic ADMM algorithms, it improves the convergence rate on convex problems from O(1/\u221aT) to O(1/T ), where T is the number of iterations. This matches the convergence rate of the batch ADMM algorithm, but without the need to visit all the samples in each iteration. Experiments on the graph-guided fused lasso demonstrate that the new algorithm is significantly faster than state-of-the-art stochastic and batch ADMM algorithms.", "citation": "Citations (68)", "year": "2014", "departments": ["Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology"], "conf": "icml", "authors": ["Wenliang Zhong.....http://dblp.org/pers/hd/z/Zhong:Wenliang", "James Tin-Yau Kwok.....http://dblp.org/pers/hd/k/Kwok:James_Tin=Yau"], "pages": 9}