{"title": "Learning Sums of Independent Integer Random Variables.", "fields": ["illustration of the central limit theorem", "independent and identically distributed random variables", "indecomposable distribution", "pairwise independence", "exchangeable random variables", "algebra of random variables", "sum of normally distributed random variables"], "abstract": "Let S = X 1 +\u00b7\u00b7\u00b7+X n  be a sum of n independent integer random variables X i , where each X i  is supported on {0, 1, ..., k - 1} but otherwise may have an arbitrary distribution (in particular the Xi's need not be identically distributed). How many samples are required to learn the distribution S to high accuracy? In this paper we show that the answer is completely independent of n, and moreover we give a computationally efficient algorithm which achieves this low sample complexity. More precisely, our algorithm learns any such S to e-accuracy (with respect to the total variation distance between distributions) using poly(k, 1/e) samples, independent of n. Its running time is poly(k, 1/e) in the standard word RAM model. Thus we give a broad generalization of the main result of [DDS12b] which gave a similar learning result for the special case k = 2 (when the distribution S is a Poisson Binomial Distribution). Prior to this work, no nontrivial results were known for learning these distributions even in the case k = 3. A key difficulty is that, in contrast to the case of k = 2, sums of independent {0, 1, 2}-valued random variables may behave very differently from (discretized) normal distributions, and in fact may be rather complicated - they are not log-concave, they can be \u0398(n)-modal, there is no relationship between Kolmogorov distance and total variation distance for the class, etc. Nevertheless, the heart of our learning result is a new limit theorem which characterizes what the sum of an arbitrary number of arbitrary independent {0, 1, ... , k-1}-valued random variables may look like. Previous limit theorems in this setting made strong assumptions on the \u201cshift invariance\u201d of the random variables Xi in order to force a discretized normal limit. We believe that our new limit theorem, as the first result for truly arbitrary sums of independent {0, 1, ... , k-1}-valued random variables, is of independent interest.", "citation": "Not cited", "year": "2013", "departments": ["Massachusetts Institute of Technology", "Carnegie Mellon University", "Columbia University", "Columbia University", "School of Informatics"], "conf": "focs", "authors": ["Constantinos Daskalakis.....http://dblp.org/pers/hd/d/Daskalakis:Constantinos", "Ilias Diakonikolas.....http://dblp.org/pers/hd/d/Diakonikolas:Ilias", "Ryan O'Donnell.....http://dblp.org/pers/hd/o/O=Donnell:Ryan", "Rocco A. Servedio.....http://dblp.org/pers/hd/s/Servedio:Rocco_A=", "Li-Yang Tan.....http://dblp.org/pers/hd/t/Tan:Li=Yang"], "pages": 10}