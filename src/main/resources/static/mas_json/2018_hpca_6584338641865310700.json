{"title": "LATTE-CC: Latency Tolerance Aware Adaptive Cache Compression Management for Energy Efficient GPUs.", "fields": ["latency", "exploit", "cache", "general purpose computing on graphics processing units", "compression"], "abstract": "General-purpose GPU applications are significantly constrained by the efficiency of the memory subsystem and the availability of data cache capacity on GPUs. Cache compression, while is able to expand the effective cache capacity and improve cache efficiency, comes with the cost of increased hit latency. This has constrained the application of cache compression to mostly lower level caches, leaving it unexplored for L1 caches and for GPUs. Directly applying state-of-the-art high performance cache compression schemes on GPUs results in a wide performance variation from -52% to 48%. To maximize the performance and energy benefits of cache compression for GPUs, we propose a new compression management scheme, called LATTE-CC. LATTE-CC is designed to exploit the dynamically-varying latency tolerance feature of GPUs. LATTE-CC compresses cache lines based on its prediction of the degree of latency tolerance of GPU streaming multiprocessors and by choosing between three distinct compression modes: no compression, low-latency, and high-capacity. LATTE-CC improves the performance of cache sensitive GPGPU applications by as much as 48.4% and by an average of 19.2%, outperforming the static application of compression algorithms. LATTE-CC also reduces GPU energy consumption by an average of 10%, which is twice as much as that of the state-of-the-art compression scheme.", "citation": "Not cited", "departments": ["Arizona State University", "Arizona State University", "Arizona State University", "Arizona State University"], "authors": ["Akhil Arunkumar.....http://dblp.org/pers/hd/a/Arunkumar:Akhil", "Shin-Ying Lee.....http://dblp.org/pers/hd/l/Lee:Shin=Ying", "Vignesh Soundararajan.....http://dblp.org/pers/hd/s/Soundararajan:Vignesh", "Carole-Jean Wu.....http://dblp.org/pers/hd/w/Wu:Carole=Jean"], "conf": "hpca", "year": "2018", "pages": 14}