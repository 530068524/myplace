{"title": "LaVAN: Localized and Visible Adversarial Noise.", "fields": ["computer science", "pattern recognition", "pixel", "artificial intelligence", "adversarial system"], "abstract": "Most works on adversarial examples for deep-learning based image classifiers use noise that, while small, covers the entire image. We explore the case where the noise is allowed to be visible but confined to a small, localized patch of the image, without covering any of the main object(s) in the image. We show that it is possible to generate localized adversarial noises that cover only 2% of the pixels in the image, none of them over the main object, and that are transferable across images and locations, and successfully fool a state-of-the-art Inception v3 model with very high success rates.", "citation": "Not cited", "departments": ["Bar-Ilan University", "Bar-Ilan University", "DeepMind"], "authors": ["Danny Karmon.....http://dblp.org/pers/hd/k/Karmon:Danny", "Daniel Zoran.....http://dblp.org/pers/hd/z/Zoran:Daniel", "Yoav Goldberg.....http://dblp.org/pers/hd/g/Goldberg:Yoav"], "conf": "icml", "year": "2018", "pages": 9}