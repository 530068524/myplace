{"title": "Better Approximation and Faster Algorithm Using the Proximal Average.", "fields": ["convex analysis", "smoothing", "linearity", "discrete mathematics", "lasso"], "abstract": "It is a common practice to approximate \"complicated\" functions with more friendly ones. In large-scale machine learning applications, nonsmooth losses/regularizers that entail great computational challenges are usually approximated by smooth functions. We re-examine this powerful methodology and point out a nonsmooth approximation which simply pretends the linearity of the proximal map. The new approximation is justified using a recent convex analysis tool\u2014 proximal average, and yields a novel proximal gradient algorithm that is strictly better than the one based on smoothing, without incurring any extra overhead. Numerical experiments conducted on two important applications, overlapping group lasso and graph-guided fused lasso, corroborate the theoretical claims.", "citation": "Citations (18)", "departments": ["University of Alberta"], "authors": ["Yaoliang Yu.....http://dblp.org/pers/hd/y/Yu:Yaoliang"], "conf": "nips", "year": "2013", "pages": 9}