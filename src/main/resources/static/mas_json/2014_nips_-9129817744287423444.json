{"title": "Robust Classification Under Sample Selection Bias.", "fields": ["binary classification", "selection bias", "minimax", "probabilistic classification", "source data"], "abstract": "In many important machine learning applications, the source distribution used to estimate a probabilistic classifier differs from the target distribution on which the classifier will be used to make predictions. Due to its asymptotic properties, sample reweighted empirical loss minimization is a commonly employed technique to deal with this difference. However, given finite amounts of labeled source data, this technique suffers from significant estimation errors in settings with large sample selection bias. We develop a framework for learning a robust bias-aware (RBA) probabilistic classifier that adapts to different sample selection biases using a minimax estimation formulation. Our approach requires only accurate estimates of statistics under the source distribution and is otherwise as robust as possible to unknown properties of the conditional label distribution, except when explicit generalization assumptions are incorporated. We demonstrate the behavior and effectiveness of our approach on binary classification tasks.", "citation": "Citations (20)", "year": "2014", "departments": ["University of Illinois at Chicago", "University of Illinois at Chicago"], "conf": "nips", "authors": ["Anqi Liu.....http://dblp.org/pers/hd/l/Liu:Anqi", "Brian D. Ziebart.....http://dblp.org/pers/hd/z/Ziebart:Brian_D="], "pages": 9}