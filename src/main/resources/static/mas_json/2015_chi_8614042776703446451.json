{"title": "Comparing Person- and Process-centric Strategies for Obtaining Quality Data on Amazon Mechanical Turk.", "fields": ["truth serum", "amazon rainforest", "coding", "annotation", "cognition"], "abstract": "In the past half-decade, Amazon Mechanical Turk has radically changed the way many scholars do research. The availability of a massive, distributed, anonymous crowd of individuals willing to perform general human-intelligence micro-tasks for micro-payments is a valuable resource for researchers and practitioners. This paper addresses the challenges of obtaining quality annotations for subjective judgment oriented tasks of varying difficulty. We design and conduct a large, controlled experiment (N=68,000) to measure the efficacy of selected strategies for obtaining high quality data annotations from non-experts. Our results point to the advantages of person-oriented strategies over process-oriented strategies. Specifically, we find that screening workers for requisite cognitive aptitudes and providing training in qualitative coding techniques is quite effective, significantly outperforming control and baseline conditions. Interestingly, such strategies can improve coder annotation accuracy above and beyond common benchmark strategies such as Bayesian Truth Serum (BTS).", "citation": "Citations (27)", "year": "2015", "departments": ["Georgia Institute of Technology", "Georgia Institute of Technology", "Georgia Institute of Technology"], "conf": "chi", "authors": ["Tanushree Mitra.....http://dblp.org/pers/hd/m/Mitra:Tanushree", "Clayton J. Hutto.....http://dblp.org/pers/hd/h/Hutto:Clayton_J=", "Eric Gilbert.....http://dblp.org/pers/hd/g/Gilbert:Eric"], "pages": 10}