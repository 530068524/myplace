{"title": "Maximizing CNN Accelerator Efficiency Through Resource Partitioning.", "fields": ["throughput", "convolutional neural network", "field programmable gate array", "convolutional code", "theoretical computer science"], "abstract": "Convolutional neural networks (CNNs) are revolutionizing machine learning, but they present significant computational challenges. Recently, many FPGA-based accelerators have been proposed to improve the performance and efficiency of CNNs. Current approaches construct a single processor that computes the CNN layers one at a time; the processor is optimized to maximize the throughput at which the collection of layers is computed. However, this approach leads to inefficient designs because the same processor structure is used to compute CNN layers of radically varying dimensions.   We present a new CNN accelerator paradigm and an accompanying automated design methodology that partitions the available FPGA resources into multiple processors, each of which is tailored for a different subset of the CNN convolutional layers. Using the same FPGA resources as a single large processor, multiple smaller specialized processors increase computational efficiency and lead to a higher overall throughput. Our design methodology achieves 3.8x higher throughput than the state-of-the-art approach on evaluating the popular AlexNet CNN on a Xilinx Virtex-7 FPGA. For the more recent SqueezeNet and GoogLeNet, the speedups are 2.2x and 2.0x.", "citation": "Citations (7)", "departments": ["Stony Brook University", "Stony Brook University", "Stony Brook University"], "authors": ["Yongming Shen.....http://dblp.org/pers/hd/s/Shen:Yongming", "Michael Ferdman.....http://dblp.org/pers/hd/f/Ferdman:Michael", "Peter Milder.....http://dblp.org/pers/hd/m/Milder:Peter"], "conf": "isca", "year": "2017", "pages": 13}