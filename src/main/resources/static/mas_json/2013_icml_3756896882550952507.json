{"title": "Revisiting Frank-Wolfe: Projection-Free Sparse Convex Optimization.", "fields": ["subderivative", "conic optimization", "convex analysis", "proper convex function", "frank wolfe algorithm"], "abstract": "We provide stronger and more general primal-dual convergence results for Frank-Wolfe-type algorithms (a.k.a. conditional gradient) for constrained convex optimization, enabled by a simple framework of duality gap certificates. Our analysis also holds if the linear subproblems are only solved approximately (as well as if the gradients are inexact), and is proven to be worst-case optimal in the sparsity of the obtained solutions.\n\nOn the application side, this allows us to unify a large variety of existing sparse greedy methods, in particular for optimization over convex hulls of an atomic set, even if those sets can only be approximated, including sparse (or structured sparse) vectors or matrices, low-rank matrices, permutation matrices, or max-norm bounded matrices.\n\nWe present a new general framework for convex optimization over matrix factorizations, where every Frank-Wolfe iteration will consist of a low-rank update, and discuss the broad application areas of this approach.", "citation": "Citations (526)", "departments": ["\u00c9cole Polytechnique"], "authors": ["Martin Jaggi.....http://dblp.org/pers/hd/j/Jaggi:Martin"], "conf": "icml", "year": "2013", "pages": 9}