{"title": "Strategyproof Classification with Shared Inputs.", "fields": ["machine learning", "classifier", "degenerate energy levels", "strategyproof", "binary number"], "abstract": "Strategy proof classification deals with a setting where a decision-maker must classify a set of input points with binary labels, while minimizing the expected error. The labels of the input points are reported by self-interested agents, who might lie in order to obtain a classifier that more closely matches their own labels, thus creating a bias in the data; this motivates the design of truthful mechanisms that discourage false reports. Previous work [Meir et al., 2008] investigated both decision-theoretic and learning-theoretic variations of the setting, but only considered classifiers that belong to a degenerate class.\n\nIn this paper we assume that the agents are interested in a shared set of input points. We show that this plausible assumption leads to powerful results. In particular, we demonstrate that variations of a truthful random dictator mechanism can guarantee approximately optimal outcomes with respect to any class of classifiers.", "citation": "Citations (13)", "departments": ["Hebrew University of Jerusalem", "Microsoft", "Hebrew University of Jerusalem"], "authors": ["Reshef Meir.....http://dblp.org/pers/hd/m/Meir:Reshef", "Ariel D. Procaccia.....http://dblp.org/pers/hd/p/Procaccia:Ariel_D=", "Jeffrey S. Rosenschein.....http://dblp.org/pers/hd/r/Rosenschein:Jeffrey_S="], "conf": "ijcai", "year": "2009", "pages": 6}