{"title": "Online Learning with Switching Costs and Other Adaptive Adversaries.", "fields": ["bounded function", "mathematical optimization", "adversary", "regret", "machine learning"], "abstract": "We study the power of different types of adaptive (nonoblivious) adversaries in the setting of prediction with expert advice, under both full-information and bandit feedback. We measure the player's performance using a new notion of regret, also known as policy regret, which better captures the adversary's adaptiveness to the player's behavior. In a setting where losses are allowed to drift, we characterize \u2014in a nearly complete manner\u2014 the power of adaptive adversaries with bounded memories and switching costs. In particular, we show that with switching costs, the attainable rate with bandit feedback is \u0398(T2/3). Interestingly, this rate is significantly worse than the \u0398(\u221aT) rate attainable with switching costs in the full-information case. Via a novel reduction from experts to bandits, we also show that a bounded memory adversary can force ****\u0398(T2/3) regret even in the full information case, proving that switching costs are easier to control than bounded memory adversaries. Our lower bounds rely on a new stochastic adversary strategy that generates loss processes with strong dependencies.", "citation": "Citations (19)", "departments": ["University of Milan", "Microsoft", "Microsoft"], "authors": ["Nicol\u00f2 Cesa-Bianchi.....http://dblp.org/pers/hd/c/Cesa=Bianchi:Nicol=ograve=", "Ofer Dekel.....http://dblp.org/pers/hd/d/Dekel:Ofer", "Ohad Shamir.....http://dblp.org/pers/hd/s/Shamir:Ohad"], "conf": "nips", "year": "2013", "pages": 9}