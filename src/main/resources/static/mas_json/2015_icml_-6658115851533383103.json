{"title": "Information Geometry and Minimum Description Length Networks.", "fields": ["minimum description length", "probability distribution", "mixture model", "parametric statistics", "information geometry"], "abstract": "We study parametric unsupervised mixture learning. We measure the loss of intrinsic information from the observations to complex mixture models, and then to simple mixture models. We present a geometric picture, where all these representations are regarded as free points in the space of probability distributions. Based on minimum description length, we derive a simple geometric principle to learn all these models together. We present a new learning machine with theories, algorithms, and simulations.", "citation": "Not cited", "year": "2015", "departments": ["University of Geneva", "University of Geneva", "University of Applied Sciences Western Switzerland", "University of Geneva", "Expedia, Switzerland"], "conf": "icml", "authors": ["Ke Sun.....http://dblp.org/pers/hd/s/Sun_0001:Ke", "Jun Wang.....http://dblp.org/pers/hd/w/Wang_0017:Jun", "Alexandros Kalousis.....http://dblp.org/pers/hd/k/Kalousis:Alexandros", "St\u00e9phane Marchand-Maillet.....http://dblp.org/pers/hd/m/Marchand=Maillet:St=eacute=phane"], "pages": 10}