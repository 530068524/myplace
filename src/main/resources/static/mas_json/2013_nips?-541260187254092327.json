{"title": "Compressive Feature Learning.", "fields": ["minimum description length", "semi supervised learning", "supervised learning", "feature learning", "dimensionality reduction"], "abstract": "This paper addresses the problem of unsupervised feature learning for text data. Our method is grounded in the principle of minimum description length and uses a dictionary-based compression scheme to extract a succinct feature set. Specifically, our method finds a set of word k-grams that minimizes the cost of reconstructing the text losslessly. We formulate document compression as a binary optimization task and show how to solve it approximately via a sequence of reweighted linear programs that are efficient to solve and parallelizable. As our method is unsupervised, features may be extracted once and subsequently used in a variety of tasks. We demonstrate the performance of these features over a range of scenarios including unsupervised exploratory analysis and supervised text categorization. Our compressed feature space is two orders of magnitude smaller than the full k-gram space and matches the text categorization accuracy achieved in the full feature space. This dimensionality reduction not only results in faster training times, but it can also help elucidate structure in unsupervised learning tasks and reduce the amount of training data necessary for supervised learning.", "citation": "Citations (10)", "departments": ["Stanford University", "Stanford University", "Stanford University", "Stanford University"], "authors": ["Hristo S. Paskov.....http://dblp.org/pers/hd/p/Paskov:Hristo_S=", "Robert West.....http://dblp.org/pers/hd/w/West_0001:Robert", "John C. Mitchell.....http://dblp.org/pers/hd/m/Mitchell:John_C=", "Trevor J. Hastie.....http://dblp.org/pers/hd/h/Hastie:Trevor_J="], "conf": "nips", "year": "2013", "pages": 9}