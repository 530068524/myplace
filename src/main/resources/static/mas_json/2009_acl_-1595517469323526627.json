{"title": "Learning Context-Dependent Mappings from Sentences to Logical Form.", "fields": ["lambda calculus", "linear model", "truth table", "logical form", "logical nor"], "abstract": "We consider the problem of learning context-dependent mappings from sentences to logical form. The training examples are sequences of sentences annotated with lambda-calculus meaning representations. We develop an algorithm that maintains explicit, lambda-calculus representations of salient discourse entities and uses a context-dependent analysis pipeline to recover logical forms. The method uses a hidden-variable variant of the perception algorithm to learn a linear model used to select the best analysis. Experiments on context-dependent utterances from the ATIS corpus show that the method recovers fully correct logical forms with 83.7% accuracy.", "citation": "Citations (149)", "year": "2009", "departments": ["Massachusetts Institute of Technology", "Massachusetts Institute of Technology"], "conf": "acl", "authors": ["Luke S. Zettlemoyer.....http://dblp.org/pers/hd/z/Zettlemoyer:Luke_S=", "Michael Collins.....http://dblp.org/pers/hd/c/Collins_0001:Michael"], "pages": 9}