{"title": "Supervised Exponential Family Principal Component Analysis via Convex Optimization.", "fields": ["exponential family", "coordinate descent", "subgradient method", "dimensionality reduction", "local optimum"], "abstract": "Recently, supervised dimensionality reduction has been gaining attention, owing to the realization that data labels are often available and indicate important underlying structure in the data. In this paper, we present a novel convex supervised dimensionality reduction approach based on exponential family PCA, which is able to avoid the local optima of typical EM learning. Moreover, by introducing a sample-based approximation to exponential family models, it overcomes the limitation of the prevailing Gaussian assumptions of standard PCA, and produces a kernelized formulation for nonlinear supervised dimensionality reduction. A training algorithm is then devised based on a subgradient bundle method, whose scalability can be gained using a coordinate descent procedure. The advantage of our global optimization approach is demonstrated by empirical results over both synthetic and real data.", "citation": "Citations (8)", "year": "2008", "departments": ["Australian National University"], "conf": "nips", "authors": ["Yuhong Guo.....http://dblp.org/pers/hd/g/Guo:Yuhong"], "pages": 8}