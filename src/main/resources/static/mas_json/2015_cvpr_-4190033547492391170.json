{"title": "Mind's eye: A recurrent visual representation for image caption generation.", "fields": ["sentence", "image retrieval", "visual word", "recurrent neural network", "automatic image annotation"], "abstract": "In this paper we explore the bi-directional mapping between images and their sentence-based descriptions. Critical to our approach is a recurrent neural network that attempts to dynamically build a visual representation of the scene as a caption is being generated or read. The representation automatically learns to remember long-term visual concepts. Our model is capable of both generating novel captions given an image, and reconstructing visual features given an image description. We evaluate our approach on several tasks. These include sentence generation, sentence retrieval and image retrieval. State-of-the-art results are shown for the task of generating novel image descriptions. When compared to human generated captions, our automatically generated captions are equal to or preferred by humans 21.0% of the time. Results are better than or comparable to state-of-the-art results on the image and sentence retrieval tasks for methods using similar visual features.", "citation": "Citations (337)", "year": "2015", "departments": ["Carnegie Mellon University", "Microsoft"], "conf": "cvpr", "authors": ["Xinlei Chen.....http://dblp.org/pers/hd/c/Chen:Xinlei", "C. Lawrence Zitnick.....http://dblp.org/pers/hd/z/Zitnick:C=_Lawrence"], "pages": 10}