{"title": "Deep Lattice Networks and Partial Monotonic Functions.", "fields": ["graph", "piecewise linear function", "discrete mathematics", "monotonic function", "lattice"], "abstract": "We propose learning deep models that are monotonic with respect to a user-specified set of inputs by alternating layers of linear embeddings, ensembles of lattices, and calibrators (piecewise linear functions), with appropriate constraints for monotonicity, and jointly training the resulting network. We implement the layers and projections with new computational graph nodes in TensorFlow and use the Adam optimizer and batched stochastic gradients. Experiments on benchmark and real-world datasets show that six-layer monotonic deep lattice networks achieve state-of-the art performance for classification and regression with monotonicity guarantees.", "citation": "Citations (3)", "year": "2017", "departments": ["Google", "Google", "Google", "Google", "Google"], "conf": "nips", "authors": ["Seungil You.....http://dblp.org/pers/hd/y/You:Seungil", "David Ding.....http://dblp.org/pers/hd/d/Ding:David", "Kevin Robert Canini.....http://dblp.org/pers/hd/c/Canini:Kevin_Robert", "Jan Pfeifer.....http://dblp.org/pers/hd/p/Pfeifer:Jan", "Maya R. Gupta.....http://dblp.org/pers/hd/g/Gupta:Maya_R="], "pages": 9}