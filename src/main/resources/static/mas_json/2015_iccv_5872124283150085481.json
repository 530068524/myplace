{"title": "VQA: Visual Question Answering.", "fields": ["mirroring", "information retrieval", "natural language processing", "closed set", "question answering", "natural language"], "abstract": "We propose the task of free-form and open-ended Visual Question Answering (VQA). Given an image and a natural language question about the image, the task is to provide an accurate natural language answer. Mirroring real-world scenarios, such as helping the visually impaired, both the questions and answers are open-ended. Visual questions selectively target different areas of an image, including background details and underlying context. As a result, a system that succeeds at VQA typically needs a more detailed understanding of the image and complex reasoning than a system producing generic image captions. Moreover, VQA is amenable to automatic evaluation, since many open-ended answers contain only a few words or a closed set of answers that can be provided in a multiple-choice format. We provide a dataset containing ~0.25M images, ~0.76M questions, and ~10M answers (www.visualqa.org), and discuss the information it provides. Numerous baselines for VQA are provided and compared with human performance.", "citation": "Citations (800)", "year": "2015", "departments": ["Virginia Tech", "Virginia Tech", "Virginia Tech", "Microsoft", "Georgia Institute of Technology", "Virginia Tech", "Virginia Tech", "Virginia Tech", "Microsoft", "Facebook"], "conf": "iccv", "authors": ["Stanislaw Antol.....http://dblp.org/pers/hd/a/Antol:Stanislaw", "Aishwarya Agrawal.....http://dblp.org/pers/hd/a/Agrawal:Aishwarya", "Jiasen Lu.....http://dblp.org/pers/hd/l/Lu:Jiasen", "Margaret Mitchell.....http://dblp.org/pers/hd/m/Mitchell:Margaret", "Dhruv Batra.....http://dblp.org/pers/hd/b/Batra:Dhruv", "C. Lawrence Zitnick.....http://dblp.org/pers/hd/z/Zitnick:C=_Lawrence", "Devi Parikh.....http://dblp.org/pers/hd/p/Parikh:Devi"], "pages": 9}