{"title": "Learning from Limited Demonstrations.", "fields": ["upper and lower bounds", "supervised learning", "computer science", "artificial intelligence", "machine learning"], "abstract": "We propose a Learning from Demonstration (LfD) algorithm which leverages expert data, even if they are very few or inaccurate. We achieve this by using both expert data, as well as reinforcement signals gathered through trial-and-error interactions with the environment. The key idea of our approach, Approximate Policy Iteration with Demonstration (APID), is that expert's suggestions are used to define linear constraints which guide the optimization performed by Approximate Policy Iteration. We prove an upper bound on the Bellman error of the estimate computed by APID at each iteration. Moreover, we show empirically that APID outperforms pure Approximate Policy Iteration, a state-of-the-art LfD algorithm, and supervised learning in a variety of scenarios, including when very few and/or suboptimal demonstrations are available. Our experiments include simulations as well as a real robot path-finding task.", "citation": "Citations (15)", "departments": ["McGill University", "McGill University", "McGill University", "McGill University"], "authors": ["Beomjoon Kim.....http://dblp.org/pers/hd/k/Kim:Beomjoon", "Amir-massoud Farahmand.....http://dblp.org/pers/hd/f/Farahmand:Amir=massoud", "Joelle Pineau.....http://dblp.org/pers/hd/p/Pineau:Joelle", "Doina Precup.....http://dblp.org/pers/hd/p/Precup:Doina"], "conf": "nips", "year": "2013", "pages": 9}