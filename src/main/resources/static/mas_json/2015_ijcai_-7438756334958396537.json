{"title": "Network Representation Learning with Rich Text Information.", "fields": ["feature learning", "matrix decomposition", "rich text format", "contextual image classification", "multi task learning"], "abstract": "Representation learning has shown its effectiveness in many tasks such as image classification and text mining. Network representation learning aims at learning distributed vector representation for each vertex in a network, which is also increasingly recognized as an important aspect for network analysis. Most network representation learning methods investigate network structures for learning. In reality, network vertices contain rich information (such as text), which cannot be well applied with algorithmic frameworks of typical representation learning methods. By proving that DeepWalk, a state-of-the-art network representation method, is actually equivalent to matrix factorization (MF), we propose text-associated DeepWalk (TADW). TADW incorporates text features of vertices into network representation learning under the framework of matrix factorization. We evaluate our method and various baseline methods by applying them to the task of multi-class classification of vertices. The experimental results show that, our method outperforms other baselines on all three datasets, especially when networks are noisy and training ratio is small. The source code of this paper can be obtained from https://github.com/albertyang33/TADW.", "citation": "Citations (184)", "departments": ["Tsinghua University", "Tsinghua University", "HTC", "Tsinghua University", "HTC"], "authors": ["Cheng Yang.....http://dblp.org/pers/hd/y/Yang:Cheng", "Zhiyuan Liu.....http://dblp.org/pers/hd/l/Liu_0001:Zhiyuan", "Deli Zhao.....http://dblp.org/pers/hd/z/Zhao:Deli", "Maosong Sun.....http://dblp.org/pers/hd/s/Sun:Maosong", "Edward Y. Chang.....http://dblp.org/pers/hd/c/Chang:Edward_Y="], "conf": "ijcai", "year": "2015", "pages": 7}