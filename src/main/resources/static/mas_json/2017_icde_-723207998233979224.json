{"title": "Quantifying Differential Privacy under Temporal Correlations.", "fields": ["fold", "markov model", "probabilistic logic", "synthetic data", "differential privacy"], "abstract": "Differential Privacy (DP) has received increasing attention as a rigorous privacy framework. Many existing studies employ traditional DP mechanisms (e.g., the Laplace mechanism) as primitives, which assume that the data are independent, or that adversaries do not have knowledge of the data correlations. However, continuous generated data in the real world tend to be temporally correlated, and such correlations can be acquired by adversaries. In this paper, we investigate the potential privacy loss of a traditional DP mechanism under temporal correlations in the context of continuous data release. First, we model the temporal correlations using Markov model and analyze the privacy leakage of a DP mechanism when adversaries have knowledge of such temporal correlations. Our analysis reveals that the privacy loss of a DP mechanism may accumulate and increase over time. We call it temporal privacy leakage. Second, to measure such privacy loss, we design an efficient algorithm for calculating it in polynomial time. Although the temporal privacy leakage may increase over time, we also show that its supremum may exist in some cases. Third, to bound the privacy loss, we propose mechanisms that convert any existing DP mechanism into one against temporal privacy leakage. Experiments with synthetic data confirm that our approach is efficient and effective.", "citation": "Citations (4)", "departments": ["Emory University", "Kyoto University", "Emory University", "Emory University"], "authors": ["Yang Cao.....http://dblp.org/pers/hd/c/Cao:Yang", "Masatoshi Yoshikawa.....http://dblp.org/pers/hd/y/Yoshikawa:Masatoshi", "Yonghui Xiao.....http://dblp.org/pers/hd/x/Xiao:Yonghui", "Li Xiong.....http://dblp.org/pers/hd/x/Xiong_0001:Li"], "conf": "icde", "year": "2017", "pages": 12}