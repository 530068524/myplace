{"title": "Local Context Sparse Coding.", "fields": ["coordinate descent", "neural coding", "topic model", "feature vector", "locality"], "abstract": "The n-gram model has been widely used to capture the local ordering of words, yet its exploding feature space often causes an estimation issue. This paper presents local context sparse coding (LCSC), a non-probabilistic topic model that effectively handles large feature spaces using sparse coding. In addition, it introduces a new concept of locality, local contexts, which provides a representation that can generate locally coherent topics and document representations. Our model efficiently finds topics and representations by applying greedy coordinate descent updates. The model is useful for discovering local topics and the semantic flow of a document, as well as constructing predictive models.", "citation": "Citations (4)", "departments": ["Georgia Institute of Technology", "Georgia Institute of Technology", "Amazon.com", "Georgia Institute of Technology"], "authors": ["Seungyeon Kim.....http://dblp.org/pers/hd/k/Kim:Seungyeon", "Joonseok Lee.....http://dblp.org/pers/hd/l/Lee:Joonseok", "Guy Lebanon.....http://dblp.org/pers/hd/l/Lebanon:Guy", "Haesun Park.....http://dblp.org/pers/hd/p/Park:Haesun"], "conf": "aaai", "year": "2015", "pages": 7}