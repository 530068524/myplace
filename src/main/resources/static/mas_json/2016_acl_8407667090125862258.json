{"title": "Learning Concept Taxonomies from Multi-modal Data.", "fields": ["small set", "feature engineering", "ontology", "wordnet", "scratch"], "abstract": "We study the problem of automatically building hypernym taxonomies from textual and visual data. Previous works in taxonomy induction generally ignore the increasingly prominent visual data, which encode important perceptual semantics. Instead, we propose a probabilistic model for taxonomy induction by jointly leveraging text and images. To avoid hand-crafted feature engineering, we design end-to-end features based on distributed representations of images and words. The model is discriminatively trained given a small set of existing ontologies and is capable of building full taxonomies from scratch for a collection of unseen conceptual label items with associated images. We evaluate our model and features on the WordNet hierarchies, where our system outperforms previous approaches by a large gap.", "citation": "Citations (3)", "year": "2016", "departments": ["Carnegie Mellon University", "Carnegie Mellon University", "Carnegie Mellon University", "Carnegie Mellon University", "University of Illinois at Urbana\u2013Champaign"], "conf": "acl", "authors": ["Hao Zhang.....http://dblp.org/pers/hd/z/Zhang:Hao", "Zhiting Hu.....http://dblp.org/pers/hd/h/Hu:Zhiting", "Yuntian Deng.....http://dblp.org/pers/hd/d/Deng:Yuntian", "Mrinmaya Sachan.....http://dblp.org/pers/hd/s/Sachan:Mrinmaya", "Zhicheng Yan.....http://dblp.org/pers/hd/y/Yan:Zhicheng", "Eric P. Xing.....http://dblp.org/pers/hd/x/Xing:Eric_P="], "pages": -1}