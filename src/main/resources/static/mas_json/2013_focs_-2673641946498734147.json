{"title": "Iterative Row Sampling.", "fields": ["symmetric matrix", "approximation algorithm", "algorithm design", "matrix", "row"], "abstract": "There has been significant interest and progress recently in algorithms that solve regression problems involving tall and thin matrices in input sparsity time. Given a n * d matrix where n g d, these algorithms find an approximation with fewer rows, allowing one to solve a poly(d) sized problem instead. In practice, the best performances are often obtained by invoking these routines in an iterative fashion. We show these iterative methods can be adapted to give theoretical guarantees comparable to and better than the current state of the art. Our approaches are based on computing the importances of the rows, known as leverage scores, in an iterative manner. We show that alternating between computing a short matrix estimate and finding more accurate approximate leverage scores leads to a series of geometrically smaller instances. This gives an algorithm whose runtime is input sparsity plus an overhead comparable to the cost of solving a regression problem on the smaller approximation. Our results build upon the close connection between randomized matrix algorithms, iterative methods, and graph sparsification.", "citation": "Citations (34)", "year": "2013", "departments": ["Carnegie Mellon University", "Carnegie Mellon University", "Carnegie Mellon University"], "conf": "focs", "authors": ["Mu Li.....http://dblp.org/pers/hd/l/Li:Mu", "Gary L. Miller.....http://dblp.org/pers/hd/m/Miller:Gary_L=", "Richard Peng.....http://dblp.org/pers/hd/p/Peng:Richard"], "pages": 10}