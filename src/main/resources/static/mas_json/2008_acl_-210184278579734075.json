{"title": "Learning Effective Multimodal Dialogue Strategies from Wizard-of-Oz Data: Bootstrapping and Evaluation.", "fields": ["training set", "wizard", "reinforcement learning", "supervised learning", "bootstrapping"], "abstract": "We address two problems in the field of automatic optimization of dialogue strategies: learning effective dialogue strategies when no initial data or system exists, and evaluating the result with real users. We use Reinforcement Learning (RL) to learn multimodal dialogue strategies by interaction with a simulated environment which is \u201cbootstrapped\u201d from small amounts of Wizard-of-Oz (WOZ) data. This use of WOZ data allows development of optimal strategies for domains where no working prototype is available. We compare the RL-based strategy against a supervised strategy which mimics the wizards\u2019 policies. This comparison allows us to measure relative improvement over the training data. Our results show that RL significantly outperforms Supervised Learning when interacting in simulation as well as for interactions with real users. The RL-based policy gains on average 50-times more reward when tested in simulation, and almost 18-times more reward when interacting with real users. Users also subjectively rate the RL-based policy on average 10% higher.", "citation": "Citations (73)", "year": "2008", "departments": ["School of Mathe ... mputer Sciences", "School of Mathe ... omputer Science"], "conf": "acl", "authors": ["Verena Rieser.....http://dblp.org/pers/hd/r/Rieser:Verena", "Oliver Lemon.....http://dblp.org/pers/hd/l/Lemon:Oliver"], "pages": 9}