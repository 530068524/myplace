{"title": "Hierarchical Monte-Carlo Planning.", "fields": ["hierarchy", "probabilistic logic", "exploit", "partially observable markov decision process", "monte carlo tree search"], "abstract": "Monte-Carlo Tree Search, especially UCT and its POMDP version POMCP, have demonstrated excellent performance on many problems. However, to efficiently scale to large domains one should also exploit hierarchical structure if present. In such hierarchical domains, finding rewarded states typically requires to search deeply; covering enough such informative states very far from the root becomes computationally expensive in flat non-hierarchical search approaches. We propose novel, scalable MCTS methods which integrate a task hierarchy into the MCTS framework, specifically leading to hierarchical versions of both, UCT and POMCP. The new method does not need to estimate probabilistic models of each subtask, it instead computes subtask policies purely sample-based. We evaluate the hierarchical MCTS methods on various settings such as a hierarchical MDP, a Bayesian model-based hierarchical RL problem, and a large hierarchical POMDP.", "citation": "Citations (14)", "departments": ["University of Stuttgart", "University of Stuttgart"], "authors": ["Ngo Anh Vien.....http://dblp.org/pers/hd/v/Vien:Ngo_Anh", "Marc Toussaint.....http://dblp.org/pers/hd/t/Toussaint:Marc"], "conf": "aaai", "year": "2015", "pages": 7}