{"title": "Using Word Embedding to Evaluate the Coherence of Topics from Twitter Data.", "fields": ["pointwise mutual information", "word embedding", "coherence", "latent semantic analysis", "topic model"], "abstract": "Scholars often seek to understand topics discussed on Twitter using topic modelling approaches. Several coherence metrics have been proposed for evaluating the coherence of the topics generated by these approaches, including the pre-calculated Pointwise Mutual Information (PMI) of word pairs and the Latent Semantic Analysis (LSA) word representation vectors. As Twitter data contains abbreviations and a number of peculiarities (e.g. hashtags), it can be challenging to train effective PMI data or LSA word representation. Recently, Word Embedding (WE) has emerged as a particularly effective approach for capturing the similarity among words. Hence, in this paper, we propose new Word Embedding-based topic coherence metrics. To determine the usefulness of these new metrics, we compare them with the previous PMI/LSA-based metrics. We also conduct a large-scale crowdsourced user study to determine whether the new Word Embedding-based metrics better align with human preferences. Using two Twitter datasets, our results show that the WE-based metrics can capture the coherence of topics in tweets more robustly and efficiently than the PMI/LSA-based ones.", "citation": "Citations (8)", "departments": ["University of Glasgow", "University of Glasgow", "University of Glasgow", "University of Glasgow"], "authors": ["Anjie Fang.....http://dblp.org/pers/hd/f/Fang:Anjie", "Craig Macdonald.....http://dblp.org/pers/hd/m/Macdonald:Craig", "Iadh Ounis.....http://dblp.org/pers/hd/o/Ounis:Iadh", "Philip Habel.....http://dblp.org/pers/hd/h/Habel:Philip"], "conf": "sigir", "year": "2016", "pages": 4}