{"title": "Towards good practice in large-scale learning for image classification.", "fields": ["weighted arithmetic mean", "contextual image classification", "stochastic gradient descent", "early stopping", "ranking"], "abstract": "We propose a benchmark of several objective functions for large-scale image classification: we compare the one-vs-rest, multiclass, ranking and weighted average ranking SVMs. Using stochastic gradient descent optimization, we can scale the learning to millions of images and thousands of classes. Our experimental evaluation shows that ranking based algorithms do not outperform a one-vs-rest strategy and that the gap between the different algorithms reduces in case of high-dimensional data. We also show that for one-vs-rest, learning through cross-validation the optimal degree of imbalance between the positive and the negative samples can have a significant impact. Furthermore, early stopping can be used as an effective regularization strategy when training with stochastic gradient algorithms. Following these \"good practices\", we were able to improve the state-of-the-art on a large subset of 10K classes and 9M of images of lmageNet from 16.7% accuracy to 19.1%.", "citation": "Citations (123)", "year": "2012", "departments": ["French Institute for Research in Computer Science and Automation", "French Institute for Research in Computer Science and Automation", "TVPA team, XRCE, France", "TVPA team, XRCE, France"], "conf": "cvpr", "authors": ["Florent Perronnin.....http://dblp.org/pers/hd/p/Perronnin:Florent", "Zeynep Akata.....http://dblp.org/pers/hd/a/Akata:Zeynep", "Za\u00efd Harchaoui.....http://dblp.org/pers/hd/h/Harchaoui:Za=iuml=d", "Cordelia Schmid.....http://dblp.org/pers/hd/s/Schmid:Cordelia"], "pages": 8}