{"title": "Descriptive and prescriptive data cleaning.", "fields": ["business logic", "data quality", "scalability", "data integration", "tuple"], "abstract": "Data cleaning techniques usually rely on some quality rules to identify violating tuples, and then fix these violations using some repair algorithms. Oftentimes, the rules, which are related to the business logic, can only be defined on some target report generated by transformations over multiple data sources. This creates a situation where the violations detected in the report are decoupled in space and time from the actual source of errors. In addition, applying the repair on the report would need to be repeated whenever the data sources change. Finally, even if repairing the report is possible and affordable, this would be of little help towards identifying and analyzing the actual sources of errors for future prevention of violations at the target. In this paper, we propose a system to address this decoupling. The system takes quality rules defined over the output of a transformation and computes explanations of the errors seen on the output. This is performed both at the target level to describe these errors and at the source level to prescribe actions to solve them. We present scalable techniques to detect, propagate, and explain errors. We also study the effectiveness and efficiency of our techniques using the TPC-H Benchmark for different scenarios and classes of quality rules.", "citation": "Citations (23)", "year": "2014", "departments": ["University of Waterloo", "University of Waterloo", "Qatar Computing Research Institute", "Qatar Computing Research Institute"], "conf": "sigmod", "authors": ["Anup Chalamalla.....http://dblp.org/pers/hd/c/Chalamalla:Anup", "Ihab F. Ilyas.....http://dblp.org/pers/hd/i/Ilyas:Ihab_F=", "Mourad Ouzzani.....http://dblp.org/pers/hd/o/Ouzzani:Mourad", "Paolo Papotti.....http://dblp.org/pers/hd/p/Papotti:Paolo"], "pages": 12}