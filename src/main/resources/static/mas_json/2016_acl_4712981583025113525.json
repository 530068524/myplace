{"title": "Text Understanding with the Attention Sum Reader Network.", "fields": ["computer science", "machine learning", "comprehension", "artificial intelligence", "natural language processing"], "abstract": "Several large cloze-style context-question-answer datasets have been introduced recently: the CNN and Daily Mail news data and the Children's Book Test. Thanks to the size of these datasets, the associated text comprehension task is well suited for deep-learning techniques that currently seem to outperform all alternative approaches. We present a new, simple model that uses attention to directly pick the answer from the context as opposed to computing the answer using a blended representation of words in the document as is usual in similar models. This makes the model particularly suitable for question-answering problems where the answer is a single word from the document. Ensemble of our models sets new state of the art on all evaluated datasets.", "citation": "Citations (108)", "year": "2016", "departments": ["IBM", "IBM", "IBM", "IBM"], "conf": "acl", "authors": ["Rudolf Kadlec.....http://dblp.org/pers/hd/k/Kadlec:Rudolf", "Martin Schmid.....http://dblp.org/pers/hd/s/Schmid:Martin", "Ondrej Bajgar.....http://dblp.org/pers/hd/b/Bajgar:Ondrej", "Jan Kleindienst.....http://dblp.org/pers/hd/k/Kleindienst:Jan"], "pages": -1}