{"title": "Gradient descent with sparsification: an iterative algorithm for sparse recovery with restricted isometry property.", "fields": ["subspace topology", "lasso", "restricted isometry property", "magnitude", "order of magnitude"], "abstract": "We present an algorithm for finding an  s -sparse vector  x  that minimizes the  square-error  \u2225 y  -- \u03a6 x \u2225 2  where \u03a6 satisfies the  restricted isometry property  (RIP), with  isometric constant  \u0394 2 s    GraDeS  (Gradient Descent with Sparsification) iteratively updates  x  as: [EQUATION]   where \u03b3 > 1 and  H s   sets all but  s  largest magnitude coordinates to zero.  GraDeS  converges to the correct solution in constant number of iterations. The condition \u0394 2 s    near-linear time  algorithm is known. In comparison, the best condition under which a polynomial-time algorithm is known, is \u0394 2 s      Our Matlab implementation of  GraDeS  outperforms previously proposed algorithms like Subspace Pursuit, StOMP, OMP, and Lasso by an order of magnitude. Curiously, our experiments also uncovered cases where L1-regularized regression (Lasso) fails but  GraDeS  finds the correct solution.", "citation": "Citations (155)", "departments": ["IBM", "IBM"], "authors": ["Rahul Garg.....http://dblp.org/pers/hd/g/Garg:Rahul", "Rohit Khandekar.....http://dblp.org/pers/hd/k/Khandekar:Rohit"], "conf": "icml", "year": "2009", "pages": 8}