{"title": "A Reinforcement Learning Approach to the View Planning Problem.", "fields": ["greedy algorithm", "function approximation", "solid modeling", "score", "reinforcement learning"], "abstract": "We present a Reinforcement Learning (RL) solution to the view planning problem (VPP), which generates a sequence of view points that are capable of sensing all accessible area of a given object represented as a 3D model. In doing so, the goal is to minimize the number of view points, making the VPP a class of set covering optimization problem (SCOP). The SCOP is NP-hard, and the inapproximability results tell us that the greedy algorithm provides the best approximation that runs in polynomial time. In order to find a solution that is better than the greedy algorithm, (i) we introduce a novel score function by exploiting the geometry of the 3D model, (ii) we device an intuitive approach to VPP using this score function, and (iii) we cast VPP as a Markovian Decision Process (MDP), and solve the MDP in RL framework using well-known RL algorithms. In particular, we use SARSA, Watkins-Q and TD with function approximation to solve the MDP. We compare the results of our method with the baseline greedy algorithm in an extensive set of test objects, and show that we can outperform the baseline in almost all cases.", "citation": "Citations (2)", "departments": [], "authors": ["Mustafa Devrim Kaba.....http://dblp.org/pers/hd/k/Kaba:Mustafa_Devrim", "Mustafa G\u00f6khan Uzunbas.....http://dblp.org/pers/hd/u/Uzunbas:Mustafa_G=ouml=khan", "Ser-Nam Lim.....http://dblp.org/pers/hd/l/Lim:Ser=Nam"], "conf": "cvpr", "year": "2017", "pages": 9}