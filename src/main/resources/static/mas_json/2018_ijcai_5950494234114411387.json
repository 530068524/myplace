{"title": "Ensemble Neural Relation Extraction with Adaptive Boosting.", "fields": ["extractor", "boosting", "recurrent neural network", "relationship extraction", "sentence"], "abstract": "Relation extraction has been widely studied to extract new relational facts from open corpus. Previous relation extraction methods are faced with the problem of wrong labels and noisy data, which substantially decrease the performance of the model. In this paper, we propose an ensemble neural network model - Adaptive Boosting LSTMs with Attention, to more effectively perform relation extraction. Specifically, our model first employs the recursive neural network LSTMs to embed each sentence. Then we import attention into LSTMs by considering that the words in a sentence do not contribute equally to the semantic meaning of the sentence. Next via adaptive boosting, we build strategically several such neural classifiers. By ensembling multiple such LSTM classifiers with adaptive boosting, we could build a more effective and robust joint ensemble neural networks based relation extractor. Experiment results on real dataset demonstrate the superior performance of the proposed model, improving F1-score by about 8% compared to the state-of-the-art models. The code of this work is publicly available on this https URL", "citation": "Not cited", "departments": ["University of Southern California", "Nanjing University of Aeronautics and Astronautics", "Beihang University"], "authors": ["Dongdong Yang.....http://dblp.org/pers/hd/y/Yang:Dongdong", "Senzhang Wang.....http://dblp.org/pers/hd/w/Wang:Senzhang", "Zhoujun Li.....http://dblp.org/pers/hd/l/Li:Zhoujun"], "conf": "ijcai", "year": "2018", "pages": 7}