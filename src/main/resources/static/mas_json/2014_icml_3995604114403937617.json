{"title": "Prediction with Limited Advice and Multiarmed Bandits with Paid Observations.", "fields": ["logarithm", "regret", "machine learning", "information access", "adversarial system", "artificial intelligence"], "abstract": "We study two problems of online learning under restricted information access. In the first problem, prediction with limited advice, we consider a game of prediction with expert advice, where on each round of the game we query the advice of a subset of M out of N experts. We present an algorithm that achieves O(\u221aN/M T ln N) regret on T rounds of this game. The second problem, the multiarmed bandit with paid observations, is a variant of the adversarial N-armed bandit game, where on round t of the game we can observe the reward of any number of arms, but each observation has a cost c. We present an algorithm that achieves O((cN lnN)1/3 T2/3 + \u221aT lnN) regret on T rounds of this game in the worst case. Furthermore, we present a number of refinements that treat arm- and time-dependent observation costs and achieve lower regret under benign conditions. We present lower bounds that show that, apart from the logarithmic factors, the worst-case regret bounds cannot be improved.", "citation": "Citations (11)", "year": "2014", "departments": ["Queensland University of Technology", "Queensland University of Technology", "Technion \u2013 Israel Institute of Technology", "Queensland University of Technology"], "conf": "icml", "authors": ["Yevgeny Seldin.....http://dblp.org/pers/hd/s/Seldin:Yevgeny", "Peter L. Bartlett.....http://dblp.org/pers/hd/b/Bartlett:Peter_L=", "Koby Crammer.....http://dblp.org/pers/hd/c/Crammer:Koby", "Yasin Abbasi-Yadkori.....http://dblp.org/pers/hd/a/Abbasi=Yadkori:Yasin"], "pages": 8}