{"title": "Linear Bayesian Reinforcement Learning.", "fields": ["stochastic matrix", "bayesian linear regression", "bayesian average", "thompson sampling", "reinforcement learning"], "abstract": "This paper proposes a simple linear Bayesian approach to reinforcement learning. We show that with an appropriate basis, a Bayesian linear Gaussian model is sufficient for accurately estimating the system dynamics, and in particular when we allow for correlated noise. Policies are estimated by first sampling a transition model from the current posterior, and then performing approximate dynamic programming on the sampled model. This form of approximate Thompson sampling results in good exploration in unknown environments. The approach can also be seen as a Bayesian generalisation of least-squares policy iteration, where the empirical transition matrix is replaced with a sample from the posterior.", "citation": "Citations (6)", "year": "2013", "departments": ["University of Ioannina", "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne", "University of Ioannina"], "conf": "ijcai", "authors": ["Nikolaos Tziortziotis.....http://dblp.org/pers/hd/t/Tziortziotis:Nikolaos", "Christos Dimitrakakis.....http://dblp.org/pers/hd/d/Dimitrakakis:Christos", "Konstantinos Blekas.....http://dblp.org/pers/hd/b/Blekas:Konstantinos"], "pages": 8}