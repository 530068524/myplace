{"title": "Equivariance Through Parameter-Sharing.", "fields": ["homogeneous space", "permutation group", "symmetry group", "artificial neural network", "input output"], "abstract": "We propose to study equivariance in deep neural networks through parameter symmetries. In particular, given a group G that acts discretely on the input and output of a standard neural network layer $\\phi_W$, we show that equivariance of $\\phi_W$ is linked to the symmetry group of network parameters W. We then propose a sparse parameter-sharing scheme to induce the desirable symmetry on W. Under some conditions on the action of G, our procedure for tying the parameters achieves G-equivariance and guarantee sensitivity to all other permutation groups outside G. We demonstrate the relation of our approach to recently-proposed \"structured\" neural layers such as group-convolution and graph-convolution which leads to new insights and improvement of these operations.", "citation": "Citations (6)", "year": "2017", "departments": ["Carnegie Mellon University", "Carnegie Mellon University", "Carnegie Mellon University"], "conf": "icml", "authors": ["Siamak Ravanbakhsh.....http://dblp.org/pers/hd/r/Ravanbakhsh:Siamak", "Jeff G. Schneider.....http://dblp.org/pers/hd/s/Schneider:Jeff_G=", "Barnab\u00e1s P\u00f3czos.....http://dblp.org/pers/hd/p/P=oacute=czos:Barnab=aacute=s"], "pages": 10}