{"title": "Adaptive Algorithms for Online Convex Optimization with Long-term Constraints.", "fields": ["subderivative", "convex analysis", "linear matrix inequality", "regret", "proper convex function"], "abstract": "We present an adaptive online gradient descent algorithm to solve online convex optimization problems with long-term constraints, which are constraints that need to be satisfied when accumulated over a finite number of rounds T, but can be violated in intermediate rounds. For some user-defined trade-off parameter \u03b2 \u2208 (0; 1), the proposed algorithm achieves cumulative regret bounds of O(Tmax{\u03b2,1-\u03b2}) and O(T1-\u03b2/2), respectively for the loss and the constraint violations. Our results hold for convex losses, can handle arbitrary convex constraints and rely on a single computationally efficient algorithm. Our contributions generalize over the best known cumulative regret bounds of Mahdavi et al. (2012a), which are respectively O(T1/2) and O(T3/4) for general convex domains, and respectively O(T2/3) and O(T2/3) when the domain is further restricted to be a polyhedral set. We supplement the analysis with experiments validating the performance of our algorithm in practice.", "citation": "Citations (9)", "year": "2016", "departments": ["Amazon.com", "Amazon.com", "Amazon.com"], "conf": "icml", "authors": ["Rodolphe Jenatton.....http://dblp.org/pers/hd/j/Jenatton:Rodolphe", "Jim C. Huang.....http://dblp.org/pers/hd/h/Huang:Jim_C=", "C\u00e9dric Archambeau.....http://dblp.org/pers/hd/a/Archambeau:C=eacute=dric"], "pages": 10}