{"title": "Minimizing The Misclassification Error Rate Using a Surrogate Convex Loss.", "fields": ["binary classification", "margin of error", "word error rate", "hinge loss", "regular polygon"], "abstract": "We carefully study how well minimizing convex surrogate loss functions corresponds to minimizing the misclassification error rate for the problem of binary classification with linear predictors. We consider the agnostic setting, and investigate guarantees on the misclassification error of the loss-minimizer in terms of the margin error rate of the best predictor. We show that, aiming for such a guarantee, the hinge loss is essentially optimal among all convex losses.", "citation": "Citations (22)", "departments": ["University of Waterloo", "University of Waterloo", "Toyota Technological Institute at Chicago", "University of Pennsylvania"], "authors": ["Shai Ben-David.....http://dblp.org/pers/hd/b/Ben=David:Shai", "David Loker.....http://dblp.org/pers/hd/l/Loker:David", "Nathan Srebro.....http://dblp.org/pers/hd/s/Srebro:Nathan", "Karthik Sridharan.....http://dblp.org/pers/hd/s/Sridharan:Karthik"], "conf": "icml", "year": "2012", "pages": -1}