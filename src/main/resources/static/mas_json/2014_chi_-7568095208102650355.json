{"title": "Combining body pose, gaze, and gesture to determine intention to interact in vision-based interfaces.", "fields": ["human computer interaction", "computer vision", "gaze", "artificial intelligence", "gesture"], "abstract": "Vision-based interfaces, such as those made popular by the Microsoft Kinect, suffer from the Midas Touch problem: every user motion can be interpreted as an interaction. In response, we developed an algorithm that combines facial features, body pose and motion to approximate a user's intention to interact with the system. We show how this can be used to determine when to pay attention to a user's actions and when to ignore them. To demonstrate the value of our approach, we present results from a 30-person lab study conducted to compare four engagement algorithms in single and multi-user scenarios. We found that combining intention to interact with a 'raise an open hand in front of you' gesture yielded the best results. The latter approach offers a 12% improvement in accuracy and a 20% reduction in time to engage over a baseline 'wave to engage' gesture currently used on the Xbox 360.", "citation": "Citations (14)", "year": "2014", "departments": ["Carnegie Mellon University", "Microsoft", "Microsoft", "Carnegie Mellon University", "Carnegie Mellon University"], "conf": "chi", "authors": ["Julia Schwarz.....http://dblp.org/pers/hd/s/Schwarz:Julia", "Charles Claudius Marais.....http://dblp.org/pers/hd/m/Marais:Charles_Claudius", "Tommer Leyvand.....http://dblp.org/pers/hd/l/Leyvand:Tommer", "Scott E. Hudson.....http://dblp.org/pers/hd/h/Hudson:Scott_E=", "Jennifer Mankoff.....http://dblp.org/pers/hd/m/Mankoff:Jennifer"], "pages": 10}