{"title": "Information extraction from Wikipedia: moving down the long tail.", "fields": ["training set", "precision and recall", "retraining", "long tail", "recall"], "abstract": "Not only is Wikipedia a comprehensive source of quality information, it has several kinds of internal structure (e.g., relational summaries known as  infoboxes ), which enable self-supervised information extraction. While previous efforts at extraction from Wikipedia achieve high precision and recall on well-populated classes of articles, they fail in a larger number of cases, largely because incomplete articles and infrequent use of infoboxes lead to insufficient training data. This paper presents three novel techniques for increasing recall from Wikipedia's long tail of sparse classes: (1) shrinkage over an automatically-learned subsumption taxonomy, (2) a retraining technique for improving the training data, and (3) supplementing results by extracting from the broader Web. Our experiments compare design variations and show that, used in concert, these techniques increase recall by a factor of 1.76 to 8.71 while maintaining or increasing precision.", "citation": "Citations (161)", "departments": ["University of Washington", "University of Washington", "University of Washington"], "authors": ["Fei Wu.....http://dblp.org/pers/hd/w/Wu_0003:Fei", "Raphael Hoffmann.....http://dblp.org/pers/hd/h/Hoffmann:Raphael", "Daniel S. Weld.....http://dblp.org/pers/hd/w/Weld:Daniel_S="], "conf": "kdd", "year": "2008", "pages": 9}