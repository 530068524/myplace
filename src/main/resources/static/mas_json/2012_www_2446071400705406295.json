{"title": "Surviving a search engine overload.", "fields": ["distributed web crawling", "rewrite engine", "web analytics", "web search query", "web crawler"], "abstract": "Search engines are an essential component of the web, but their web crawling agents can impose a significant burden on heavily loaded web servers. Unfortunately, blocking or deferring web crawler requests is not a viable solution due to economic consequences. We conduct a quantitative measurement study on the impact and cost of web crawling agents, seeking optimization points for this class of request. Based on our measurements, we present a practical caching approach for mitigating search engine overload, and implement the two-level cache scheme on a very busy web server. Our experimental results show that the proposed caching framework can effectively reduce the impact of search engine overload on service quality.", "citation": "Citations (6)", "departments": ["College of William & Mary", "College of William & Mary"], "authors": ["Aaron Koehl.....http://dblp.org/pers/hd/k/Koehl:Aaron", "Haining Wang.....http://dblp.org/pers/hd/w/Wang:Haining"], "conf": "www", "year": "2012", "pages": 10}