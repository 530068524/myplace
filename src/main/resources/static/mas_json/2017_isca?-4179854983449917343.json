{"title": "Decoupled Affine Computation for SIMT GPUs.", "fields": ["cas latency", "memory address", "general purpose computing on graphics processing units", "affine transformation", "decoupling"], "abstract": "This paper introduces a method of decoupling affine computations---a class of expressions that produces extremely regular values across SIMT threads---from the main execution stream, so that the affine computations can be performed with greater efficiency and with greater independence from the main execution stream. This decoupling has two benefits: (1) For compute-bound programs, it significantly reduces the dynamic warp instruction count; (2) for memory-bound workloads, it significantly reduces memory latency, since it acts as a non-speculative prefetcher for the data specified by the many memory address calculations that are affine computations.   We evaluate our solution, known as Decoupled Affine Computation (DAC), using GPGPU-sim and a set of 29 GPGPU programs. We find that on average, DAC improves performance by 40% and reduces energy consumption by 20%. For the 11 compute-bound benchmarks, DAC improves performance by 34%, compared with 11% for the previous state-of-the-art. For the 18 memory-bound programs, DAC improves performance by an average of 44%, compared with 16% for state-of-the-art GPU prefetcher.", "citation": "Citations (1)", "departments": ["University of Texas at Austin", "University of Texas at Austin"], "authors": ["Kai Wang.....http://dblp.org/pers/hd/w/Wang:Kai", "Calvin Lin.....http://dblp.org/pers/hd/l/Lin:Calvin"], "conf": "isca", "year": "2017", "pages": 12}