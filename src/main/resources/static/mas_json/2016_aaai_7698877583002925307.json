{"title": "What Happens Next? Event Prediction Using a Compositional Neural Network Model.", "fields": ["initialization", "coherence", "baseline", "artificial neural network", "verb"], "abstract": "We address the problem of automatically acquiring knowledge of event sequences from text, with the aim of providing a predictive model for use in narrative generation systems. We present a neural network model that simultaneously learns embeddings for words describing events, a function to compose the embeddings into a representation of the event, and a coherence function to predict the strength of association between two events.\n\nWe introduce a new development of the narrative cloze evaluation task, better suited to a setting where rich information about events is available. We compare models that learn vector-space representations of the events denoted by verbs in chains centering on a single protagonist. We find that recent work on learning vector-space embeddings to capture word meaning can be effectively applied to this task, including simple incorporation of a verb's arguments in the representation by vector addition. These representations provide a good initialization for learning the richer, compositional model of events with a neural network, vastly outperforming a number of baselines and competitive alternatives.", "citation": "Citations (19)", "departments": ["University of Cambridge", "University of Cambridge"], "authors": ["Mark Granroth-Wilding.....http://dblp.org/pers/hd/g/Granroth=Wilding:Mark", "Stephen Clark.....http://dblp.org/pers/hd/c/Clark:Stephen"], "conf": "aaai", "year": "2016", "pages": 7}