{"title": "Sharing Deep Neural Network Models with Interpretation.", "fields": ["small set", "decision boundary", "traverse", "interpretability", "data point"], "abstract": "Despite outperforming humans in many tasks, deep neural network models are also criticized for the lack of transparency and interpretability in decision making. The opaqueness results in uncertainty and low confidence when deploying such a model in model sharing scenarios, where the model is developed by a third party. For a supervised machine learning model, sharing training process including training data provides an effective way to gain trust and to better understand model predictions. However, it is not always possible to share all training data due to privacy and policy constraints. In this paper, we propose a method to disclose a small set of training data that is just sufficient for users to get the insight of a complicated model. The method constructs a boundary tree using selected training data and the tree is able to approximate the complicated model with high fidelity. We show that traversing data points in the tree gives users significantly better understanding of the model and paves the way for trustworthy model sharing.", "citation": "Not cited", "departments": ["University of New South Wales", "Commonwealth Scientific and Industrial Research Organisation", "Commonwealth Scientific and Industrial Research Organisation", "National University of Defense Technology", "University of New South Wales"], "authors": ["Huijun Wu.....http://dblp.org/pers/hd/w/Wu:Huijun", "Chen Wang.....http://dblp.org/pers/hd/w/Wang_0008:Chen", "Jie Yin.....http://dblp.org/pers/hd/y/Yin:Jie", "Kai Lu.....http://dblp.org/pers/hd/l/Lu:Kai", "Liming Zhu.....http://dblp.org/pers/hd/z/Zhu:Liming"], "conf": "www", "year": "2018", "pages": 10}