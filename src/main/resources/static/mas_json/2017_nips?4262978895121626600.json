{"title": "Learning with Bandit Feedback in Potential Games.", "fields": ["almost surely", "epsilon equilibrium", "best response", "risk dominance", "equilibrium selection"], "abstract": "This paper examines the equilibrium convergence properties of no-regret learning with exponential weights in potential games. To establish convergence with minimal information requirements on the players' side, we focus on two frameworks: the semi-bandit case (where players have access to a noisy estimate of their payoff vectors, including strategies they did not play), and the bandit case (where players are only able to observe their in-game, realized payoffs). In the semi-bandit case, we show that the induced sequence of play converges almost surely to a Nash equilibrium at a quasi-exponential rate. In the bandit case, the same result holds for approximate Nash equilibria if we introduce a constant exploration factor that guarantees that action choice probabilities never become arbitrarily small. In particular, if the algorithm is run with a suitably decreasing exploration factor, the sequence of play converges to a bona fide Nash equilibrium with probability 1.", "citation": "Citations (2)", "year": "2017", "departments": ["Centre national de la recherche scientifique", "French Institute for Research in Computer Science and Automation", "Univ. Grenoble Alpes"], "conf": "nips", "authors": ["Am\u00e9lie H\u00e9liou.....http://dblp.org/pers/hd/h/H=eacute=liou:Am=eacute=lie", "Johanne Cohen.....http://dblp.org/pers/hd/c/Cohen:Johanne", "Panayotis Mertikopoulos.....http://dblp.org/pers/hd/m/Mertikopoulos:Panayotis"], "pages": 10}