{"title": "The Pareto Regret Frontier.", "fields": ["regret", "sample size determination", "pareto principle", "horizon", "hindsight bias"], "abstract": "Performance guarantees for online learning algorithms typically take the form of regret bounds, which express that the cumulative loss overhead compared to the best expert in hindsight is small. In the common case of large but structured expert sets we typically wish to keep the regret especially small compared to simple experts, at the cost of modest additional overhead compared to more complex others. We study which such regret trade-offs can be achieved, and how.\n\nWe analyse regret w.r.t. each individual expert as a multi-objective criterion in the simple but fundamental case of absolute loss. We characterise the achievable and Pareto optimal trade-offs, and the corresponding optimal strategies for each sample size both exactly for each finite horizon and asymptotically.", "citation": "Citations (8)", "departments": ["Queensland University of Technology"], "authors": ["Wouter M. Koolen.....http://dblp.org/pers/hd/k/Koolen:Wouter_M="], "conf": "nips", "year": "2013", "pages": 9}