{"title": "Automatic discovery and transfer of MAXQ hierarchies.", "fields": ["bellman equation", "abstraction", "reinforcement learning", "speedup", "dynamic bayesian network"], "abstract": "We present an algorithm, HI-MAT (Hierarchy Induction via Models And Trajectories), that discovers MAXQ task hierarchies by applying dynamic Bayesian network models to a successful trajectory from a source reinforcement learning task. HI-MAT discovers subtasks by analyzing the causal and temporal relationships among the actions in the trajectory. Under appropriate assumptions, HI-MAT induces hierarchies that are consistent with the observed trajectory and have compact value-function tables employing safe state abstractions. We demonstrate empirically that HI-MAT constructs compact hierarchies that are comparable to manually-engineered hierarchies and facilitate significant speedup in learning when transferred to a target task.", "citation": "Citations (90)", "year": "2008", "departments": ["Oregon State University", "Oregon State University", "Oregon State University", "Oregon State University"], "conf": "icml", "authors": ["Neville Mehta.....http://dblp.org/pers/hd/m/Mehta:Neville", "Soumya Ray.....http://dblp.org/pers/hd/r/Ray:Soumya", "Prasad Tadepalli.....http://dblp.org/pers/hd/t/Tadepalli:Prasad", "Thomas G. Dietterich.....http://dblp.org/pers/hd/d/Dietterich:Thomas_G="], "pages": 8}