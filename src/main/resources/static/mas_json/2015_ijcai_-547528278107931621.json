{"title": "Inverse Reinforcement Learning in Relational Domains.", "fields": ["machine learning", "inverse", "rotation formalisms in three dimensions", "statistical relational learning", "reinforcement learning"], "abstract": "In this work, we introduce the first approach to the Inverse Reinforcement Learning (IRL) problem in relational domains. IRL has been used to recover a more compact representation of the expert policy leading to better generalization performances among different contexts. On the other hand, relational learning allows representing problems with a varying number of objects (potentially infinite), thus provides more generalizable representations of problems and skills. We show how these different formalisms allow one to create a new IRL algorithm for relational domains that can recover with great efficiency rewards from expert data that have strong generalization and transfer properties. We evaluate our algorithm in representative tasks and study the impact of diverse experimental conditions such as : the number of demonstrations, knowledge about the dynamics, transfer among varying dimensions of a problem, and changing dynamics.", "citation": "Citations (6)", "departments": ["French Institute for Research in Computer Science and Automation", "university of lille", "Sup\u00e9lec", "university of lille", "French Institute for Research in Computer Science and Automation"], "authors": ["Thibaut Munzer.....http://dblp.org/pers/hd/m/Munzer:Thibaut", "Bilal Piot.....http://dblp.org/pers/hd/p/Piot:Bilal", "Matthieu Geist.....http://dblp.org/pers/hd/g/Geist:Matthieu", "Olivier Pietquin.....http://dblp.org/pers/hd/p/Pietquin:Olivier", "Manuel Lopes.....http://dblp.org/pers/hd/l/Lopes_0001:Manuel"], "conf": "ijcai", "year": "2015", "pages": 7}