{"title": "Black-box Optimization with a Politician.", "fields": ["proximal gradient methods", "broyden fletcher goldfarb shanno algorithm", "black box", "gradient descent", "proximal gradient methods for learning"], "abstract": "We propose a new framework for black-box convex optimization which is well-suited for situations where gradient computations are expensive. We derive a new method for this framework which leverages several concepts from convex optimization, from standard first-order methods (e.g. gradient descent or quasi-Newton methods) to analytical centers (i.e. minimizers of self-concordant barriers). We demonstrate empirically that our new technique compares favorably with state of the art algorithms (such as BFGS).", "citation": "Citations (2)", "year": "2016", "departments": ["Microsoft", "Massachusetts Institute of Technology"], "conf": "icml", "authors": ["S\u00e9bastien Bubeck.....http://dblp.org/pers/hd/b/Bubeck:S=eacute=bastien", "Yin Tat Lee.....http://dblp.org/pers/hd/l/Lee:Yin_Tat"], "pages": 8}