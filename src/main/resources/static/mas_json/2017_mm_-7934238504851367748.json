{"title": "Cross-modal Recipe Retrieval with Rich Food Attributes.", "fields": ["deep learning", "recipe", "composition", "modal", "ingredient"], "abstract": "Food is rich of visible (e.g., colour, shape) and procedural (e.g., cutting, cooking) attributes. Proper leveraging of these attributes, particularly the interplay among ingredients, cutting and cooking methods, for health-related applications has not been previously explored. This paper investigates cross-modal retrieval of recipes, specifically to retrieve a text-based recipe given a food picture as query. As similar ingredient composition can end up with wildly different dishes depending on the cooking and cutting procedures, the difficulty of retrieval originates from fine-grained recognition of rich attributes from pictures. With a multi-task deep learning model, this paper provides insights on the feasibility of predicting ingredient, cutting and cooking attributes for food recognition and recipe retrieval. In addition, localization of ingredient regions is also possible even when region-level training examples are not provided. Experiment results validate the merit of rich attributes when comparing to the recently proposed ingredient-only retrieval techniques.", "citation": "Citations (1)", "departments": ["City University of Hong Kong", "City University of Hong Kong", "National University of Singapore"], "authors": ["Jingjing Chen.....http://dblp.org/pers/hd/c/Chen:Jingjing", "Chong-Wah Ngo.....http://dblp.org/pers/hd/n/Ngo:Chong=Wah", "Tat-Seng Chua.....http://dblp.org/pers/hd/c/Chua:Tat=Seng"], "conf": "mm", "year": "2017", "pages": 9}