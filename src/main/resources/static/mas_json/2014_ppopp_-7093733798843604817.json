{"title": "CUDA-NP: realizing nested thread-level parallelism in GPGPU applications.", "fields": ["parallel computing", "implicit parallelism", "task parallelism", "general purpose computing on graphics processing units", "cuda", "data parallelism", "instruction level parallelism", "computer architecture"], "abstract": "Parallel programs consist of series of code sections with different thread-level parallelism (TLP). As a result, it is rather common that a thread in a parallel program, such as a GPU kernel in CUDA programs, still contains both se-quential code and parallel loops. In order to leverage such parallel loops, the latest Nvidia Kepler architecture intro-duces dynamic parallelism, which allows a GPU thread to start another GPU kernel, thereby reducing the overhead of launching kernels from a CPU. However, with dynamic parallelism, a parent thread can only communicate with its child threads through global memory and the overhead of launching GPU kernels is non-trivial even within GPUs. In this paper, we first study a set of GPGPU benchmarks that contain parallel loops, and highlight that these bench-marks do not have a very high loop count or high degrees of TLP. Consequently, the benefits of leveraging such par-allel loops using dynamic parallelism are too limited to offset its overhead. We then present our proposed solution to exploit nested parallelism in CUDA, referred to as CUDA-NP. With CUDA-NP, we initially enable a high number of threads when a GPU program starts, and use control flow to activate different numbers of threads for different code sections. We implemented our proposed CUDA-NP framework using a directive-based compiler approach. For a GPU kernel, an application developer only needs to add OpenMP-like pragmas for parallelizable code sections. Then, our CUDA-NP compiler automatically gen-erates the optimized GPU kernels. It supports both the reduction and the scan primitives, explores different ways to distribute parallel loop iterations into threads, and effi-ciently manages on-chip resource. Our experiments show that for a set of GPGPU benchmarks, which have already been optimized and contain nested parallelism, our pro-posed CUDA-NP framework further improves the perfor-mance by up to 6.69 times and 2.18 times on average.", "citation": "Not cited", "year": "2014", "departments": ["Princeton University", "North Carolina State University", "North Carolina State University", "North Carolina State University", "NEC Laboratories America"], "conf": "ppopp", "authors": ["Yi Yang.....http://dblp.org/pers/hd/y/Yang:Yi", "Huiyang Zhou.....http://dblp.org/pers/hd/z/Zhou:Huiyang"], "pages": 14}