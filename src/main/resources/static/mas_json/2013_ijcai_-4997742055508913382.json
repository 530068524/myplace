{"title": "A Generalization of SAT and #SAT for Robust Policy Evaluation.", "fields": ["reward based selection", "sample complexity", "machine learning", "finite set", "risk aversion"], "abstract": "We consider stochastic multiarmed bandit problems where each arm generates i.i.d. rewards according to an unknown distribution. Whereas classical bandit solutions only maximize the expected reward, we consider the problem of minimizing risk using notions such as the value-at-risk, the average value-at-risk, and the mean-variance risk. We present algorithms to minimize the risk over a single and multiple time periods, along with PAC accuracy guarantees given a finite number of reward samples. In the single-period case, we show that finding the arm with least risk requires not many more samples than the arm with highest expected reward. Although minimizing the multiperiod value-at-risk is known to be hard, we present an algorithm with comparable sample complexity under additional assumptions.", "citation": "Citations (11)", "year": "2013", "departments": ["IBM", "Texas A&M University"], "conf": "ijcai", "authors": ["Erik Peter Zawadzki.....http://dblp.org/pers/hd/z/Zawadzki:Erik_Peter", "Andr\u00e9 Platzer.....http://dblp.org/pers/hd/p/Platzer:Andr=eacute=", "Geoffrey J. Gordon.....http://dblp.org/pers/hd/g/Gordon:Geoffrey_J="], "pages": 8}