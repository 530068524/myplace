{"title": "Phrase-based Image Captioning.", "fields": ["standard test image", "closed captioning", "bilinear interpolation", "convolutional neural network", "automatic image annotation"], "abstract": "Generating a novel textual description of an image is an interesting problem that connects computer vision and natural language processing. In this paper, we present a simple model that is able to generate descriptive sentences given a sample image. This model has a strong focus on the syntax of the descriptions. We train a purely bilinear model that learns a metric between an image representation (generated from a previously trained Convolutional Neural Network) and phrases that are used to described them. The system is then able to infer phrases from a given image sample. Based on caption syntax statistics, we propose a simple language model that can produce relevant descriptions for a given test image using the phrases inferred. Our approach, which is considerably simpler than state-of-the-art models, achieves comparable results in two popular datasets for the task: Flickr30k and the recently proposed Microsoft COCO.", "citation": "Citations (65)", "year": "2015", "departments": ["\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne", "Idiap Research Institute", "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne", "Idiap Research Institute", "Facebook"], "conf": "icml", "authors": ["R\u00e9mi Lebret.....http://dblp.org/pers/hd/l/Lebret:R=eacute=mi", "Pedro H. O. Pinheiro.....http://dblp.org/pers/hd/p/Pinheiro:Pedro_H=_O=", "Ronan Collobert.....http://dblp.org/pers/hd/c/Collobert:Ronan"], "pages": 10}