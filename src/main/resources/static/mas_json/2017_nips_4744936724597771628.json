{"title": "Unsupervised Learning of Disentangled Representations from Video.", "fields": ["computer science", "coherence", "artificial intelligence", "unsupervised learning", "machine learning"], "abstract": "We present a new model DRNET that learns disentangled image representations from video. Our approach leverages the temporal coherence of video and a novel adversarial loss to learn a representation that factorizes each frame into a stationary part and a temporally varying component. The disentangled representation can be used for a range of tasks. For example, applying a standard LSTM to the time-vary components enables prediction of future frames. We evaluating our approach on a range of synthetic and real videos. For the latter, we demonstrate the ability to coherently generate up to several hundred steps into the future.", "citation": "Citations (31)", "year": "2017", "departments": ["New York University", "New York University"], "conf": "nips", "authors": ["Emily L. Denton.....http://dblp.org/pers/hd/d/Denton:Emily_L=", "Vighnesh Birodkar.....http://dblp.org/pers/hd/b/Birodkar:Vighnesh"], "pages": 10}