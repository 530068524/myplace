{"title": "Information Equals Amortized Communication.", "fields": ["mutual information", "combinatorics", "amortized analysis", "pointer jumping", "communication complexity", "discrete mathematics", "message passing", "potential method", "theoretical computer science"], "abstract": "We show how to efficiently simulate the sending of a message to a receiver who has partial information about the message, so that the expected number of bits communicated in the simulation is close to the amount of additional information that the message reveals to the receiver who has some information about the message. This is a generalization and strengthening of the Slepian Wolf theorem, which shows how to carry out such a simulation with low amortized communication in the case that the message is a deterministic function of an input. A caveat is that our simulation is interactive. As a consequence, we prove that the internal information cost(namely the information revealed to the parties) involved in computing any relation or function using a two party interactive protocol is exactly equal to the amortized communication complexity of computing independent copies of the same relation or function. We also show that the only way to prove a strong direct sum theorem for randomized communication complexity is by solving a particular variant of the pointer jumping problem that we define. Our work implies that a strong direct sum theorem for communication complexity holds if and only if efficient compression of communication protocols is possible.", "citation": "Citations (154)", "year": "2011", "departments": ["Princeton University", "University of Washington", "University of Toronto", "University of Washington"], "conf": "focs", "authors": ["Mark Braverman.....http://dblp.org/pers/hd/b/Braverman:Mark", "Anup Rao.....http://dblp.org/pers/hd/r/Rao:Anup"], "pages": 10}