{"title": "Evaluating multi-query sessions.", "fields": ["data mining", "information retrieval", "query expansion", "computer science", "search engine"], "abstract": "The standard system-based evaluation paradigm has focused on assessing the performance of retrieval systems in serving the best results for a single query. Real users, however, often begin an interaction with a search engine with a sufficiently under-specified query that they will need to reformulate before they find what they are looking for. In this work we consider the problem of evaluating retrieval systems over test collections of multi-query sessions. We propose two families of measures: a model-free family that makes no assumption about the user's behavior over a session, and a model-based family with a simple model of user interactions over the session. In both cases we generalize traditional evaluation metrics such as average precision to multi-query session evaluation. We demonstrate the behavior of the proposed metrics by using the new TREC 2010 Session track collection and simulations over the TREC-9 Query track collection.", "citation": "Citations (67)", "departments": ["University of Sheffield", "University of Delaware", "University of Sheffield", "RMIT University"], "authors": ["Evangelos Kanoulas.....http://dblp.org/pers/hd/k/Kanoulas:Evangelos", "Ben Carterette.....http://dblp.org/pers/hd/c/Carterette:Ben", "Paul D. Clough.....http://dblp.org/pers/hd/c/Clough:Paul_D=", "Mark Sanderson.....http://dblp.org/pers/hd/s/Sanderson:Mark"], "conf": "sigir", "year": "2011", "pages": 10}