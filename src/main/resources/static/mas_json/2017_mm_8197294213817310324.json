{"title": "Occlusion-aware Video Temporal Consistency.", "fields": ["image warping", "color balance", "video processing", "tone mapping", "local color"], "abstract": "Image color editing techniques such as color transfer, HDR tone mapping, dehazing, and white balance have been widely used and investigated in recent decades. However, naively employing them to videos frame-by-frame often leads to flickering or color inconsistency. To solve it generally, earlier methods rely on temporal filtering or warping from the previous frame, but they still fail in the cases of occlusion and produce blurry results. We introduce a new framework for these challenges: (1) We develop an online keyframe strategy to keep track of the dynamic objects, where more temporal information can be acquired than a single previous frame. (2) To preserve image details, local color affine model is employed. The main concept of this post-processing step is to capture the color transformation from editing algorithms and maintain the detail structures of the raw image simultaneously. Practically, our approach takes a raw video and its per-frame processed version, and generates a temporally consistent output. In addition, we propose a video quality metric to evaluate temporal coherence. Extensive experiments and subjective test are done to show the superiority of the proposed framework with respect to color fidelity, detail preservation, and temporal consistency.", "citation": "Citations (1)", "departments": ["National Taiwan University", "National Taiwan University", "National Taiwan University"], "authors": ["Chun-Han Yao.....http://dblp.org/pers/hd/y/Yao:Chun=Han", "Chia-Yang Chang.....http://dblp.org/pers/hd/c/Chang:Chia=Yang", "Shao-Yi Chien.....http://dblp.org/pers/hd/c/Chien:Shao=Yi"], "conf": "mm", "year": "2017", "pages": 9}