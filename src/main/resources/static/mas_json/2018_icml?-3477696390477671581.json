{"title": "Characterizing Implicit Bias in Terms of Optimization Geometry.", "fields": ["underdetermined system", "hyperparameter", "linear classifier", "separable space", "maxima and minima"], "abstract": "We study the bias of generic optimization methods, including Mirror Descent, Natural Gradient Descent and Steepest Descent with respect to different potentials and norms, when optimizing underdetermined linear regression or separable linear classification problems. We ask the question of whether the global minimum (among the many possible global minima) reached by optimization algorithms can be characterized in terms of the potential or norm, and independently of hyperparameter choices such as step size and momentum.", "citation": "Citations (2)", "departments": ["Toyota Technological Institute at Chicago", "University of Southern California", "Technion \u2013 Israel Institute of Technology", "Toyota Technological Institute at Chicago"], "authors": ["Suriya Gunasekar.....http://dblp.org/pers/hd/g/Gunasekar:Suriya", "Jason Lee.....http://dblp.org/pers/hd/l/Lee:Jason", "Daniel Soudry.....http://dblp.org/pers/hd/s/Soudry:Daniel", "Nathan Srebro.....http://dblp.org/pers/hd/s/Srebro:Nathan"], "conf": "icml", "year": "2018", "pages": 10}