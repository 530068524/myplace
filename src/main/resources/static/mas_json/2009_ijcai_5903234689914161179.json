{"title": "Bayesian Real-Time Dynamic Programming.", "fields": ["bayesian probability", "expected value of perfect information", "dynamic programming", "state space", "markov decision process"], "abstract": "Real-time dynamic programming (RTDP) solves Markov decision processes (MDPs) when the initial state is restricted, by focusing dynamic programming on the envelope of states reachable from an initial state set. RTDP often provides performance guarantees without visiting the entire state space. Building on RTDP, recent work has sought to improve its efficiency through various optimizations, including maintaining upper and lower bounds to both govern trial termination and prioritize state exploration. In this work, we take a Bayesian perspective on these upper and lower bounds and use a value of perfect information (VPI) analysis to govern trial termination and exploration in a novel algorithm we call VPI-RTDP. VPI-RTDP leads to an improvement over state-of-the-art RTDP methods, empirically yielding up to a three-fold reduction in the amount of time and number of visited states required to achieve comparable policy performance.", "citation": "Citations (29)", "departments": ["Catholic University of Leuven", "Catholic University of Leuven", "Microsoft", "SML Group, Nati ... rra, Australia"], "authors": ["Scott Sanner.....http://dblp.org/pers/hd/s/Sanner:Scott", "Robby Goetschalckx.....http://dblp.org/pers/hd/g/Goetschalckx:Robby", "Kurt Driessens.....http://dblp.org/pers/hd/d/Driessens:Kurt", "Guy Shani.....http://dblp.org/pers/hd/s/Shani:Guy"], "conf": "ijcai", "year": "2009", "pages": 6}