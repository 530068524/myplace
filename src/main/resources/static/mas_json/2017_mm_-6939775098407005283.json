{"title": "Improved Multimodal Representation Learning with Skip Connections.", "fields": ["data set", "inference", "multimedia information retrieval", "feature learning", "generative model"], "abstract": "Multimodal Deep Boltzmann Machines (DBMs) have demonstrated huge successes in multimodal representation learning tasks. During inference, DBMs function as Recurrent Neural Nets (RNNs) because of the intractable distributions. To learn the parameters, optimizations can alternatively be operated on these surrogate RNNs with \"truncated message passing\". As a consequence, the gradient will propagate through a long chain without any local guidance which can potentially affects the optimization procedure. In this paper, we address this problem by adding skip connections during back-propagation while keeping the forward propagation (inference) untouched. With skip connections, we implicitly assign local \"targets\" for the states of intermediate inference loops to approach. Applied to different training criteria on different data sets, we demonstrate the proposed algorithms can consistently help to train better models while at a lower cost of training time. Experimental results show that our algorithms can achieve state-of-the-art performance on the Multimedia Information Retrieval (MIR) Flickr data set.", "citation": "Not cited", "departments": ["University of Massachusetts Lowell", "University of Massachusetts Lowell", "University of Massachusetts Lowell", "University of Massachusetts Lowell"], "authors": ["Ning Zhang.....http://dblp.org/pers/hd/z/Zhang:Ning", "Yu Cao.....http://dblp.org/pers/hd/c/Cao_0002:Yu", "Benyuan Liu.....http://dblp.org/pers/hd/l/Liu:Benyuan", "Yan Luo.....http://dblp.org/pers/hd/l/Luo:Yan"], "conf": "mm", "year": "2017", "pages": 9}