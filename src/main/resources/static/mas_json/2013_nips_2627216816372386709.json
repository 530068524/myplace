{"title": "Optimization, Learning, and Games with Predictable Sequences.", "fields": ["simple algorithm", "minimax", "maximum flow problem", "exponential function", "saddle"], "abstract": "We provide several applications of Optimistic Mirror Descent, an online learning algorithm based on the idea of predictable sequences. First, we recover the Mirror Prox algorithm for offline optimization, prove an extension to Holder-smooth functions, and apply the results to saddle-point type problems. Next, we prove that a version of Optimistic Mirror Descent (which has a close relation to the Exponential Weights algorithm) can be used by two strongly-uncoupled players in a finite zero-sum matrix game to converge to the minimax equilibrium at the rate of O((log T)/T). This addresses a question of Daskalakis et al [6]. Further, we consider a partial information version of the problem. We then apply the results to convex programming and exhibit a simple algorithm for the approximate Max Flow problem.", "citation": "Citations (56)", "departments": ["University of Pennsylvania", "University of Pennsylvania"], "authors": ["Alexander Rakhlin.....http://dblp.org/pers/hd/r/Rakhlin:Alexander", "Karthik Sridharan.....http://dblp.org/pers/hd/s/Sridharan:Karthik"], "conf": "nips", "year": "2013", "pages": 9}