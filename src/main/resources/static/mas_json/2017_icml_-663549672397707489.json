{"title": "Natasha: Faster Non-Convex Stochastic Optimization via Strongly Non-Convex Parameter.", "fields": ["regular polygon", "stationary point", "hessian matrix", "mathematics", "stochastic optimization", "mathematical optimization", "sigma", "convexity"], "abstract": "Given a non-convex function $f(x)$ that is an average of $n$ smooth functions, we design stochastic first-order methods to find its approximate stationary points. The performance of our new methods depend on the smallest (negative) eigenvalue $-\\sigma$ of the Hessian. This parameter $\\sigma$ captures how strongly non-convex $f(x)$ is, and is analogous to the strong convexity parameter for convex optimization. \nOur methods outperform the best known results for a wide range of $\\sigma$, and can also be used to find approximate local minima. \nIn particular, we find an interesting dichotomy: there exists a threshold $\\sigma_0$ so that the fastest methods for $\\sigma>\\sigma_0$ and for $\\sigma<\\sigma_0$ have drastically different behaviors: the former scales with $n^{2/3}$ and the latter scales with $n^{3/4}$.", "citation": "Not cited", "departments": ["Princeton University"], "authors": ["Zeyuan Allen-Zhu.....http://dblp.org/pers/hd/a/Allen=Zhu:Zeyuan"], "conf": "icml", "year": "2017", "pages": 9}