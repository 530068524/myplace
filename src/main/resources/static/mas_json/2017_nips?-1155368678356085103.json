{"title": "Dynamic-Depth Context Tree Weighting.", "fields": ["bounded function", "order of magnitude", "context tree weighting", "suffix tree", "markov model"], "abstract": "Reinforcement learning (RL) in partially observable settings is challenging because the agent\u2019s observations are not Markov. Recently proposed methods can learn variable-order Markov models of the underlying process but have steep memory requirements and are sensitive to aliasing between observation histories due to sensor noise. This paper proposes dynamic-depth context tree weighting (D2-CTW), a model-learning method that addresses these limitations. D2-CTW dynamically expands a suffix tree while ensuring that the size of the model, but not its depth, remains bounded. We show that D2-CTW approximately matches the performance of state-of-the-art alternatives at stochastic time-series prediction while using at least an order of magnitude less memory. We also apply D2-CTW to model-based RL, showing that, on tasks that require memory of past observations, D2-CTW can learn without prior knowledge of a good state representation, or even the length of history upon which such a representation should depend.", "citation": "Citations (2)", "year": "2017", "departments": ["Instituto Superior T\u00e9cnico", "University of Oxford"], "conf": "nips", "authors": ["Jo\u00e3o V. Messias.....http://dblp.org/pers/hd/m/Messias:Jo=atilde=o_V=", "Shimon Whiteson.....http://dblp.org/pers/hd/w/Whiteson:Shimon"], "pages": 10}