{"title": "DTAM: Dense tracking and mapping in real-time.", "fields": ["depth map", "augmented reality", "rgb color model", "video tracking", "image texture"], "abstract": "DTAM is a system for real-time camera tracking and reconstruction which relies not on feature extraction but dense, every pixel methods. As a single hand-held RGB camera flies over a static scene, we estimate detailed textured depth maps at selected keyframes to produce a surface patchwork with millions of vertices. We use the hundreds of images available in a video stream to improve the quality of a simple photometric data term, and minimise a global spatially regularised energy functional in a novel non-convex optimisation framework. Interleaved, we track the camera's 6DOF motion precisely by frame-rate whole image alignment against the entire dense model. Our algorithms are highly parallelisable throughout and DTAM achieves real-time performance using current commodity GPU hardware. We demonstrate that a dense model permits superior tracking performance under rapid motion compared to a state of the art method using features; and also show the additional usefulness of the dense model for real-time scene interaction in a physics-enhanced augmented reality application.", "citation": "Citations (1,107)", "year": "2011", "departments": ["Imperial College London", "Imperial College London", "Imperial College London"], "conf": "iccv", "authors": ["Richard A. Newcombe.....http://dblp.org/pers/hd/n/Newcombe:Richard_A=", "Steven Lovegrove.....http://dblp.org/pers/hd/l/Lovegrove:Steven", "Andrew J. Davison.....http://dblp.org/pers/hd/d/Davison:Andrew_J="], "pages": 8}