{"title": "Random Oracle Reducibility.", "fields": ["hierarchy", "random self reducibility", "preimage attack", "elgamal encryption", "turing machine", "computation", "collision resistance", "non interactive zero knowledge proof", "combinatorics", "block cipher", "logarithm", "polynomial hierarchy", "non deterministic turing machine", "cipher", "computational complexity theory", "time complexity", "random oracle", "pseudorandom function family", "mutual information", "kolmogorov complexity", "diffie hellman key exchange", "discrete mathematics", "oracle", "np easy"], "abstract": "Preneel et al. (Crypto 1993) assessed 64 possible ways to construct a compression functions out of a blockcipher. They conjectured that 12 out of these 64 so-called PGV constructions achieve optimal se- curity bounds for collision resistance and preimage resistance. This was proven by Black et al. (Journal of Cryptology, 2010), if one assumes that the blockcipher is ideal. This result, however, does not apply to \"non- ideal\" blockciphers such as AES. To alleviate this problem, we revisit the PGV constructions in light of the recently proposed idea of random- oracle reducibility (Baecher and Fischlin, Crypto 2011). We say that the blockcipher in one of the 12 secure PGV constructions reduces to the one in another construction, if any secure instantiation of the cipher, ideal or not, for one construction also makes the other secure. This notion allows us to relate the underlying assumptions on blockciphers in different con- structions, and show that the requirements on the blockcipher for one case are not more demanding than those for the other. It turns out that this approach divides the 12 secure constructions into two groups of equal size, where within each group a blockcipher making one construction se- cure also makes all others secure. Across the groups this is provably not the case, showing that the sets of \"good\" blockciphers for each group are qualitatively distinct. We also relate the ideal ciphers in the PGV constructions with those in double-block-length hash functions such as Tandem-DM, Abreast-DM, and Hirose-DM. Here, our results show that, besides achieving better bounds, the double-block-length hash functions rely on weaker assumptions on the blockciphers to achieve collision and everywhere preimage resistance.", "citation": "Citations (6)", "departments": ["Technische Universit\u00e4t Darmstadt", "Technische Universit\u00e4t Darmstadt", "Technische Universit\u00e4t Darmstadt", "University of Bristol", "Polytechnic University of Catalonia", "Polytechnic University of Catalonia", "Technische Universit\u00e4t M\u00fcnchen", "AT&T Labs", "AT&T Labs", "Technische Universit\u00e4t Darmstadt", "Technische Universit\u00e4t Darmstadt", "University of Rochester", "University of Jena", "University of Rochester", "University of Rochester"], "authors": ["Paul Baecher.....http://dblp.org/pers/hd/b/Baecher:Paul", "Marc Fischlin.....http://dblp.org/pers/hd/f/Fischlin:Marc"], "conf": "crypto", "year": "2011", "pages": 18}