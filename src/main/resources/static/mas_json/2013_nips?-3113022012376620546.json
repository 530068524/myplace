{"title": "Projected Natural Actor-Critic.", "fields": ["gradient descent", "search algorithm", "reinforcement learning", "markov decision process", "machine learning"], "abstract": "Natural actor-critics form a popular class of policy search algorithms for finding locally optimal policies for Markov decision processes. In this paper we address a drawback of natural actor-critics that limits their real-world applicability\u2014their lack of safety guarantees. We present a principled algorithm for performing natural gradient descent over a constrained domain. In the context of reinforcement learning, this allows for natural actor-critic algorithms that are guaranteed to remain within a known safe region of policy space. While deriving our class of constrained natural actor-critic algorithms, which we call Projected Natural Actor-Critics (PNACs), we also elucidate the relationship between natural gradient descent and mirror descent.", "citation": "Citations (3)", "departments": ["University of Massachusetts Amherst", "University of Massachusetts Amherst", "University of Massachusetts Amherst", "University of Massachusetts Amherst"], "authors": ["Philip S. Thomas.....http://dblp.org/pers/hd/t/Thomas:Philip_S=", "William Dabney.....http://dblp.org/pers/hd/d/Dabney:William", "Stephen Giguere.....http://dblp.org/pers/hd/g/Giguere:Stephen", "Sridhar Mahadevan.....http://dblp.org/pers/hd/m/Mahadevan:Sridhar"], "conf": "nips", "year": "2013", "pages": 9}