{"title": "A Bayesian Approach for Policy Learning from Trajectory Preference Queries.", "fields": ["trajectory", "exploit", "bayesian inference", "bayesian probability", "policy learning"], "abstract": "We consider the problem of learning control policies via trajectory preference queries to an expert. In particular, the agent presents an expert with short runs of a pair of policies originating from the same state and the expert indicates which trajectory is preferred. The agent's goal is to elicit a latent target policy from the expert with as few queries as possible. To tackle this problem we propose a novel Bayesian model of the querying process and introduce two methods that exploit this model to actively select expert queries. Experimental results on four benchmark problems indicate that our model can effectively learn policies from trajectory preference queries and that active query selection can be substantially more efficient than random selection.", "citation": "Citations (61)", "departments": ["Oregon State University", "Oregon State University", "Oregon State University"], "authors": ["Aaron Wilson.....http://dblp.org/pers/hd/w/Wilson:Aaron", "Alan Fern.....http://dblp.org/pers/hd/f/Fern:Alan", "Prasad Tadepalli.....http://dblp.org/pers/hd/t/Tadepalli:Prasad"], "conf": "nips", "year": "2012", "pages": 9}