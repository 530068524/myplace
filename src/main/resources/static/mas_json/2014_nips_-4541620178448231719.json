{"title": "A Representation Theory for Ranking Functions.", "fields": ["ranking", "representation theory", "tensor", "bayes theorem", "supervised learning"], "abstract": "This paper presents a representation theory for permutation-valued functions, which in their general form can also be called listwise ranking functions. Point-wise ranking functions assign a score to each object independently, without taking into account the other objects under consideration; whereas listwise loss functions evaluate the set of scores assigned to all objects as a whole. In many supervised learning to rank tasks, it might be of interest to use listwise ranking functions instead; in particular, the Bayes Optimal ranking functions might themselves be listwise, especially if the loss function is listwise. A key caveat to using listwise ranking functions has been the lack of an appropriate representation theory for such functions. We show that a natural symmetricity assumption that we call exchangeability allows us to explicitly characterize the set of such exchangeable listwise ranking functions. Our analysis draws from the theories of tensor analysis, functional analysis and De Finetti theorems. We also present experiments using a novel reranking method motivated by our representation theory.", "citation": "Citations (5)", "year": "2014", "departments": ["University of Texas at Austin", "University of Texas at Austin"], "conf": "nips", "authors": ["Harsh H. Pareek.....http://dblp.org/pers/hd/p/Pareek:Harsh_H=", "Pradeep Ravikumar.....http://dblp.org/pers/hd/r/Ravikumar:Pradeep"], "pages": 9}