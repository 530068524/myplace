{"title": "Optimizing ETL workflows for fault-tolerance.", "fields": ["parallel processing", "data warehouse", "extract transform load", "search algorithm", "workflow"], "abstract": "Extract-Transform-Load (ETL) processes play an important role in data warehousing. Typically, design work on ETL has focused on performance as the sole metric to make sure that the ETL process finishes within an allocated time window. However, other quality metrics are also important and need to be considered during ETL design. In this paper, we address ETL design for performance plus fault-tolerance and freshness. There are many reasons why an ETL process can fail and a good design needs to guarantee that it can be recovered within the ETL time window. How to make ETL robust to failures is not trivial. There are different strategies that can be used and they each have different costs and benefits. In addition, other metrics can affect the choice of a strategy; e.g., higher freshness reduces the time window for recovery. The design space is too large for informal, ad-hoc approaches. In this paper, we describe our QoX optimizer that considers multiple design strategies and finds an ETL design that satisfies multiple objectives. In particular, we define the optimizer search space, cost functions, and search algorithms. Also, we illustrate its use through several experiments and we show that it produces designs that are very near optimal.", "citation": "Citations (74)", "departments": ["Hewlett-Packard", "Hewlett-Packard", "Hewlett-Packard", "Hewlett-Packard"], "authors": ["Alkis Simitsis.....http://dblp.org/pers/hd/s/Simitsis:Alkis", "Kevin Wilkinson.....http://dblp.org/pers/hd/w/Wilkinson:Kevin", "Umeshwar Dayal.....http://dblp.org/pers/hd/d/Dayal:Umeshwar", "Mal\u00fa Castellanos.....http://dblp.org/pers/hd/c/Castellanos:Mal=uacute="], "conf": "icde", "year": "2010", "pages": 12}