{"title": "A Universal Primal-Dual Convex Optimization Framework.", "fields": ["operator", "differentiable function", "residual", "smoothness", "frank wolfe algorithm"], "abstract": "We propose a new primal-dual algorithmic framework for a prototypical constrained convex optimization template. The algorithmic instances of our framework are universal since they can automatically adapt to the unknown Holder continuity degree and constant within the dual formulation. They are also guaranteed to have optimal convergence rates in the objective residual and the feasibility gap for each Holder smoothness degree. In contrast to existing primal-dual algorithms, our framework avoids the proximity operator of the objective function. We instead leverage computationally cheaper, Fenchel-type operators, which are the main workhorses of the generalized conditional gradient (GCG)-type methods. In contrast to the GCG-type methods, our framework does not require the objective function to be differentiable, and can also process additional general linear inclusion constraints, while guarantees the convergence rate on the primal problem.", "citation": "Citations (10)", "year": "2015", "departments": ["\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne", "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne", "Department of S ...  Research, UNC"], "conf": "nips", "authors": ["Alp Yurtsever.....http://dblp.org/pers/hd/y/Yurtsever:Alp", "Quoc Tran-Dinh.....http://dblp.org/pers/hd/t/Tran=Dinh:Quoc", "Volkan Cevher.....http://dblp.org/pers/hd/c/Cevher:Volkan"], "pages": 9}