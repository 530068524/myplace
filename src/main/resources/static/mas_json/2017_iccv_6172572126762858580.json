{"title": "Photographic Image Synthesis with Cascaded Refinement Networks.", "fields": ["training set", "semantics", "image resolution", "rendering", "computer vision", "computer science", "solid modeling", "artificial intelligence"], "abstract": "We present an approach to synthesizing photographic images conditioned on semantic layouts. Given a semantic label map, our approach produces an image with photographic appearance that conforms to the input layout. The approach thus functions as a rendering engine that takes a two-dimensional semantic specification of the scene and produces a corresponding photographic image. Unlike recent and contemporaneous work, our approach does not rely on adversarial training. We show that photographic images can be synthesized from semantic layouts by a single feedforward network with appropriate structure, trained end-to-end with a direct regression objective. The presented approach scales seamlessly to high resolutions; we demonstrate this by synthesizing photographic images at 2-megapixel resolution, the full resolution of our training data. Extensive perceptual experiments on datasets of outdoor and indoor scenes demonstrate that images synthesized by the presented approach are considerably more realistic than alternative approaches.", "citation": "Citations (28)", "year": "2017", "departments": ["Intel", "Intel", "Intel", "Intel"], "conf": "iccv", "authors": ["Qifeng Chen.....http://dblp.org/pers/hd/c/Chen:Qifeng", "Vladlen Koltun.....http://dblp.org/pers/hd/k/Koltun:Vladlen"], "pages": 10}