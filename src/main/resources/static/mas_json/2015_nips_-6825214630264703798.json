{"title": "Learning to Linearize Under Uncertainty.", "fields": ["hierarchy", "supervised learning", "network architecture", "generative model", "latent variable"], "abstract": "Training deep feature hierarchies to solve supervised learning tasks has achieved state of the art performance on many problems in computer vision. However, a principled way in which to train such hierarchies in the unsupervised setting has remained elusive. In this work we suggest a new architecture and loss for training deep feature hierarchies that linearize the transformations observed in unlabeled natural video sequences. This is done by training a generative model to predict video frames. We also address the problem of inherent uncertainty in prediction by introducing latent variables that are non-deterministic functions of the input into the network architecture.", "citation": "Citations (56)", "year": "2015", "departments": ["Courant Institute of Mathematical Sciences", "Courant Institute of Mathematical Sciences", "Courant Institute of Mathematical Sciences"], "conf": "nips", "authors": ["Ross Goroshin.....http://dblp.org/pers/hd/g/Goroshin:Ross", "Micha\u00ebl Mathieu.....http://dblp.org/pers/hd/m/Mathieu:Micha=euml=l", "Yann LeCun.....http://dblp.org/pers/hd/l/LeCun:Yann"], "pages": 9}