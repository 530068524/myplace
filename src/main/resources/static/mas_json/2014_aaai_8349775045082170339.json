{"title": "Regret-Based Optimization and Preference Elicitation for Stackelberg Security Games with Uncertainty.", "fields": ["regret", "preference elicitation", "machine learning", "minimax", "stackelberg competition"], "abstract": "Stackelberg security games (SSGs) have been deployed in a number of real-world domains. One key challenge in these applications is the assessment of attacker payoffs, which may not be perfectly known. Previous work has studied SSGs with uncertain payoffs modeled by interval uncertainty and provided maximin-based robust solutions. In contrast, in this work we propose the use of the less conservative minimax regret decision criterion for such payoff-uncertain SSGs and present the first algorithms for computing minimax regret for SSGs. We also address the challenge of preference elicitation, using minimax regret to develop the first elicitation strategies for SSGs. Experimental results validate the effectiveness of our approaches.", "citation": "Citations (14)", "departments": ["University of Southern California", "Nanyang Technological University", "Nanyang Technological University", "University of Southern California", "University of Toronto"], "authors": ["Thanh Hong Nguyen.....http://dblp.org/pers/hd/n/Nguyen:Thanh_Hong", "Amulya Yadav.....http://dblp.org/pers/hd/y/Yadav:Amulya", "Bo An.....http://dblp.org/pers/hd/a/An:Bo", "Milind Tambe.....http://dblp.org/pers/hd/t/Tambe:Milind", "Craig Boutilier.....http://dblp.org/pers/hd/b/Boutilier:Craig"], "conf": "aaai", "year": "2014", "pages": 7}