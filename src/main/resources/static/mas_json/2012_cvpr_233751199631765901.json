{"title": "A combined pose, object, and feature model for action understanding.", "fields": ["feature model", "pose", "discriminative model", "video tracking", "gesture recognition"], "abstract": "Understanding natural human activity involves not only identifying the action being performed, but also locating the semantic elements of the scene and describing the person's interaction with them. We present a system that is able to recognize complex, fine-grained human actions involving the manipulation of objects in realistic action sequences. Our method takes advantage of recent advances in sensors and pose trackers in learning an action model that draws on successful discriminative techniques while explicitly modeling both pose trajectories and object manipulations. By combining these elements in a single model, we are able to simultaneously recognize actions and track the location and manipulation of objects. To showcase this ability, we introduce a novel Cooking Action Dataset that contains video, depth readings, and pose tracks from a Kinect sensor. We show that our model outperforms existing state of the art techniques on this dataset as well as the VISINT dataset with only video sequences.", "citation": "Citations (56)", "year": "2012", "departments": ["Stanford University", "University of California, Berkeley", "Stanford University"], "conf": "cvpr", "authors": ["Benjamin Packer.....http://dblp.org/pers/hd/p/Packer:Benjamin", "Kate Saenko.....http://dblp.org/pers/hd/s/Saenko:Kate", "Daphne Koller.....http://dblp.org/pers/hd/k/Koller:Daphne"], "pages": 8}