{"title": "Efficient Exploration and Value Function Generalization in Deterministic Systems.", "fields": ["local consistency", "deterministic system", "special case", "bellman equation", "disjoint sets"], "abstract": "We consider the problem of reinforcement learning over episodes of a finite-horizon deterministic system and as a solution propose optimistic constraint propagation (OCP), an algorithm designed to synthesize efficient exploration and value function generalization. We establish that when the true value function Q* lies within the hypothesis class Q, OCP selects optimal actions over all but at most dimE[Q] episodes, where dimE denotes the eluder dimension. We establish further efficiency and asymptotic performance guarantees that apply even if Q* does not lie in Q, for the special case where Q is the span of pre-specified indicator functions over disjoint sets.", "citation": "Citations (8)", "departments": ["Stanford University", "Stanford University"], "authors": ["Zheng Wen.....http://dblp.org/pers/hd/w/Wen:Zheng", "Benjamin Van Roy.....http://dblp.org/pers/hd/r/Roy:Benjamin_Van"], "conf": "nips", "year": "2013", "pages": 9}