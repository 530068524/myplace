{"title": "Small-Variance Asymptotics for Dirichlet Process Mixtures of SVMs.", "fields": ["gibbs sampling", "inference", "asymptotic analysis", "dirichlet process", "monotonic function"], "abstract": "Infinite SVM (iSVM) is a Dirichlet process (DP) mixture of large-margin classifiers. Though flexible in learning nonlinear classifiers and discovering latent clustering structures, iSVM has a difficult inference task and existing methods could hinder its applicability to large-scale problems. This paper presents a small-variance asymptotic analysis to derive a simple and efficient algorithm, which monotonically optimizes a maxmargin DP-means (M2DPM) problem, an extension of DP-means for both predictive learning and descriptive clustering. Our analysis is built on Gibbs infinite SVMs, an alternative DP mixture of large-margin machines, which admits a partially collapsed Gibbs sampler without truncation by exploring data augmentation techniques. Experimental results show that M2DPM runs much faster than similar algorithms without sacrificing prediction accuracies.", "citation": "Citations (5)", "departments": ["Tsinghua University", "Tsinghua University"], "authors": ["Yining Wang.....http://dblp.org/pers/hd/w/Wang:Yining", "Jun Zhu.....http://dblp.org/pers/hd/z/Zhu_0001:Jun"], "conf": "aaai", "year": "2014", "pages": 7}