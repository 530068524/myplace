{"title": "Cold-Start Reinforcement Learning with Softmax Policy Gradient.", "fields": ["observable", "striatum", "supervised ", "expectancy theory", "unsupervised ", null, "partially observable markov decision process", "machine ", "recurrent neural network", "nonlinear conjugate ", "q ", "robot ", "feature ", "counterfactual thinking", "multi task ", "expected return", "markov decision process", "active "], "abstract": null, "citation": "Citations (2)", "year": "2017", "departments": ["University of Alberta", "Franklin & Marshall College", "University of Alberta", "Max Planck Society", "Dalle Molle Institute for Artificial Intelligence Research", "Technische Universit\u00e4t M\u00fcnchen", "Dalle Molle Institute for Artificial Intelligence Research", "Dalle Molle Institute for Artificial Intelligence Research", "Technische Universit\u00e4t M\u00fcnchen", "University of Cambridge", "University of Cambridge", "University of Cambridge", "University of Cambridge", "University of Cambridge", "University of Alberta", "IBM", "Royal Institute of Technology", "MPI for Biologi ...  Germany 72076", "Centre for Auto ... ockholm, Sweden", "Dept . of Compu ... uroscience Labs", "Dept . of Compu ... uroscience Labs"], "conf": "nips", "authors": ["Nan Ding.....http://dblp.org/pers/hd/d/Ding:Nan", "Radu Soricut.....http://dblp.org/pers/hd/s/Soricut:Radu"], "pages": 10}