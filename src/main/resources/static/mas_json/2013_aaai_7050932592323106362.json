{"title": "A Maximum K-Min Approach for Classification.", "fields": ["lemma", "machine learning", "hinge loss", "optimization problem", "nonlinear system"], "abstract": "In this paper, a general Maximum K-Min approach for classification is proposed. With the physical meaning of optimizing the classification confidence of the K worst instances, Maximum K-Min Gain/Minimum K-Max Loss (MKM) criterion is introduced. To make the original optimization problem with combinational number of constraints computationally tractable, the optimization techniques are adopted and a general compact representation lemma for MKM Criterion is summarized. Based on the lemma, a Nonlinear Maximum K-Min (NMKM) classifier and a Semi-supervised Maximum K-Min (SMKM) classifier are presented for traditional classification task and semi-supervised classification task respectively. Based on the experiment results of publicly available datasets, our Maximum K-Min methods have achieved competitive performance when comparing against Hinge Loss classifiers.", "citation": "Not cited", "year": "2013", "departments": ["Beijing University of Posts and Telecommunications", "Beijing University of Posts and Telecommunications", "Beijing University of Posts and Telecommunications", "Intel", "Beijing University of Posts and Telecommunications"], "conf": "aaai", "authors": ["Mingzhi Dong.....http://dblp.org/pers/hd/d/Dong:Mingzhi", "Liang Yin.....http://dblp.org/pers/hd/y/Yin:Liang"], "pages": -1}