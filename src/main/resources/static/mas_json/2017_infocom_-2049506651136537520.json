{"title": "Better with fewer bits: Improving the performance of cardinality estimation of large data streams.", "fields": ["query optimization", "cardinality", "peta", "data stream mining", "estimator"], "abstract": "Cardinality estimation is the task of determining the number of distinct elements (or the cardinality) in a data stream, under a stringent constraint that the input data stream can be scanned by just a single pass. This is a fundamental problem with many practical applications, such as traffic monitoring of high-speed networks and query optimization of Internetscale database. To solve the problem, we propose an algorithm named HLL-TailCut+, which implements the estimation standard error 1.0/\u221am using the memory units of three bits each, whose cost is much smaller than the five-bit memory units used by HyperLogLog, the best previously known cardinality estimator. This makes it possible to reduce the memory cost of HyperLogLog by 45%. For example, when the target estimation error is 1.1%, state-of-the-art HyperLogLog needs 5.6 kilobytes memory. By contrast, our new algorithm only needs 3 kilobytes memory consumption for attaining the same accuracy. Additionally, our algorithm is able to support the estimation of very large stream cardinalities, even on the Tera and Peta scale.", "citation": "Not cited", "departments": ["Southeast University", "University of Florida", "University of Florida"], "authors": ["Qingjun Xiao.....http://dblp.org/pers/hd/x/Xiao:Qingjun", "You Zhou.....http://dblp.org/pers/hd/z/Zhou_0003:You", "Shigang Chen.....http://dblp.org/pers/hd/c/Chen:Shigang"], "conf": "infocom", "year": "2017", "pages": 9}