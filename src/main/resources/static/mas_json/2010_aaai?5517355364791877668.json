{"title": "Epsilon-First Policies for Budget-Limited Multi-Armed Bandits.", "fields": ["regret", "unsupervised learning", "gittins index", "stochastic game", "data acquisition", "engineering", "data mining", "time complexity", "mechanism design", "incentive compatibility", "trade off", "rounding", "crowdsourcing", "bipartite graph", "artificial intelligence", "biology", "nondeterministic algorithm", "confidence interval", "approximation algorithm", "mathematical optimization", "translation project", "asymptotically optimal algorithm", "multi armed bandit", "machine learning", "response rate", "cluster analysis"], "abstract": "We introduce the budget?limited multi?armed bandit (MAB), which captures situations where a learner?s actions are costly and constrained by a fixed budget that is incommensurable with the rewards earned from the bandit machine, and then describe a first algorithm ", "citation": "Citations (72)", "departments": ["University of Southampton", "University of Southampton", "University of Southampton", "University of Southampton", "University of Southampton", "University of California, Santa Barbara", "Google", "Stanford University", "ETH Zurich", "CBS Interactive, Inc."], "authors": ["Long Tran-Thanh.....http://dblp.org/pers/hd/t/Tran=Thanh:Long", "Archie C. Chapman.....http://dblp.org/pers/hd/c/Chapman:Archie_C=", "Enrique Munoz de Cote.....http://dblp.org/pers/hd/c/Cote:Enrique_Munoz_de", "Alex Rogers.....http://dblp.org/pers/hd/r/Rogers:Alex", "Nicholas R. Jennings.....http://dblp.org/pers/hd/j/Jennings:Nicholas_R="], "conf": "aaai", "year": "2010", "pages": -1}