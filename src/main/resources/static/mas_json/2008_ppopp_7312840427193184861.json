{"title": "Scalable packet classification using interpreting: a cross-platform multi-core solution.", "fields": ["conventional memory", "cache only memory architecture", "cache oblivious algorithm", "non uniform memory access", "uniform memory access"], "abstract": "Packet classification is an enabling technology to support advanced Internet services. It is still a challenge for a software solution to achieve 10Gbps (line-rate) classification speed. This paper presents a classification algorithm that can be efficiently implemented on a multi-core architecture with or without cache. The algorithm embraces the holistic notion of exploiting application characteristics, considering the capabilities of the CPU and the memory hierarchy, and performing appropriate data partitioning. The classification algorithm adopts two stages: searching on a reduction tree and searching on a list of ranges. This decision is made based on a classification heuristic: the size of the range list is limited after the first stage search. Optimizations are then designed to speed up the two-stage execution. To exploit the speed gap (1) between the CPU and external memory; (2) between internal memory (cache) and external memory, an interpreter is used to trade the CPU idle cycles with demanding memory access requirements. By applying the CISC style of instruction encoding to compress the range expressions, it not only significantly reduces the total memory requirement but also makes effective use of the internal memory (cache) bandwidth. We show that compressing data structures is an effective optimization across the multi-core architectures.   We implement this algorithm on both Intel IXP2800 network processor and Core 2 Duo X86 architecture, and experiment with the classification benchmark, ClassBench. By incorporating architecture-awareness in algorithm design and taking into account the memory hierarchy, data partitioning, and latency hiding in algorithm implementation, the resulting algorithm shows a good scalability on Intel IXP2800. By effectively using the cache system, the algorithm also runs faster than the previous fastest RFC on the Core 2 Duo architecture.", "citation": "Citations (11)", "year": "2008", "departments": ["University of Science and Technology of China", "University of Science and Technology of China", "University of Science and Technology of China", "Intel"], "conf": "ppopp", "authors": ["Haipeng Cheng.....http://dblp.org/pers/hd/c/Cheng:Haipeng", "Zheng Chen.....http://dblp.org/pers/hd/c/Chen:Zheng", "Bei Hua.....http://dblp.org/pers/hd/h/Hua:Bei", "Xinan Tang.....http://dblp.org/pers/hd/t/Tang:Xinan"], "pages": 10}