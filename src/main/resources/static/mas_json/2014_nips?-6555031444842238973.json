{"title": "The Infinite Mixture of Infinite Gaussian Mixtures.", "fields": ["statistics", "dirichlet process", "gaussian", "mathematical analysis", "cluster", "generative model", "gibbs sampling", "mathematics"], "abstract": "Dirichlet process mixture of Gaussians (DPMG) has been used in the literature for clustering and density estimation problems. However, many real-world data exhibit cluster distributions that cannot be captured by a single Gaussian. Modeling such data sets by DPMG creates several extraneous clusters even when clusters are relatively well-defined. Herein, we present the infinite mixture of infinite Gaussian mixtures (I2GMM) for more flexible modeling of data sets with skewed and multi-modal cluster distributions. Instead of using a single Gaussian for each cluster as in the standard DPMG model, the generative model of I2GMM uses a single DPMG for each cluster. The individual DPMGs are linked together through centering of their base distributions at the atoms of a higher level DP prior. Inference is performed by a collapsed Gibbs sampler that also enables partial parallelization. Experimental results on several artificial and real-world data sets suggest the proposed I2GMM model can predict clusters more accurately than existing variational Bayes and Gibbs sampler versions of DPMG.", "citation": "Not cited", "year": "2014", "departments": ["Indiana University \u2013 Purdue University Indianapolis", "Purdue University", "Indiana University \u2013 Purdue University Indianapolis"], "conf": "nips", "authors": ["Halid Ziya Yerebakan.....http://dblp.org/pers/hd/y/Yerebakan:Halid_Ziya", "Bartek Rajwa.....http://dblp.org/pers/hd/r/Rajwa:Bartek", "Murat Dundar.....http://dblp.org/pers/hd/d/Dundar:Murat"], "pages": 9}