{"title": "Adaptive Hedge.", "fields": ["mathematical optimization", "existential quantification", "probabilistic logic", "regret", "machine learning"], "abstract": "Most methods for decision-theoretic online learning are based on the Hedge algorithm, which takes a parameter called the learning rate. In most previous analyses the learning rate was carefully tuned to obtain optimal worst-case performance, leading to suboptimal performance on easy instances, for example when there exists an action that is significantly better than all others. We propose a new way of setting the learning rate, which adapts to the difficulty of the learning problem: in the worst case our procedure still guarantees optimal performance, but on easy instances it achieves much smaller regret. In particular, our adaptive method achieves constant regret in a probabilistic setting, when there exists an action that on average obtains strictly smaller loss than all other actions. We also provide a simulation study comparing our approach to existing methods.", "citation": "Citations (17)", "departments": ["VU University Amsterdam", "Royal Holloway, University of London", "Centrum Wiskunde & Informatica", "Centrum Wiskunde & Informatica"], "authors": ["Tim van Erven.....http://dblp.org/pers/hd/e/Erven:Tim_van", "Peter Grunwald.....http://dblp.org/pers/hd/g/Grunwald:Peter", "Wouter M. Koolen.....http://dblp.org/pers/hd/k/Koolen:Wouter_M=", "Steven de Rooij.....http://dblp.org/pers/hd/r/Rooij:Steven_de"], "conf": "nips", "year": "2011", "pages": 9}