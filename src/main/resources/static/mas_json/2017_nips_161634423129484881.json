{"title": "Variational Inference via \\chi Upper Bound Minimization.", "fields": ["probit model", "expectation propagation", "closeness", "markov chain monte carlo", "cox process"], "abstract": "Variational inference (VI) is widely used as an efficient alternative to Markov chain Monte Carlo. It posits a family of approximating distributions $q$ and finds the closest member to the exact posterior $p$. Closeness is usually measured via a divergence $D(q || p)$ from $q$ to $p$. While successful, this approach also has problems. Notably, it typically leads to underestimation of the posterior variance. In this paper we propose CHIVI, a black-box variational inference algorithm that minimizes $D_{\\chi}(p || q)$, the $\\chi$-divergence from $p$ to $q$. CHIVI minimizes an upper bound of the model evidence, which we term the $\\chi$ upper bound (CUBO). Minimizing the CUBO leads to improved posterior uncertainty, and it can also be used with the classical VI lower bound (ELBO) to provide a sandwich estimate of the model evidence. We study CHIVI on three models: probit regression, Gaussian process classification, and a Cox process model of basketball plays. When compared to expectation propagation and classical VI, CHIVI produces better error rates and more accurate estimates of posterior variance.", "citation": "Citations (5)", "year": "2017", "departments": ["Columbia University", "Columbia University", "OpenAI", "Princeton University", "Columbia University", "Columbia University"], "conf": "nips", "authors": ["Adji Bousso Dieng.....http://dblp.org/pers/hd/d/Dieng:Adji_Bousso", "Dustin Tran.....http://dblp.org/pers/hd/t/Tran:Dustin", "Rajesh Ranganath.....http://dblp.org/pers/hd/r/Ranganath:Rajesh", "John William Paisley.....http://dblp.org/pers/hd/p/Paisley:John_William", "David M. Blei.....http://dblp.org/pers/hd/b/Blei:David_M="], "pages": 10}