{"title": "The Return of the Gating Network: Combining Generative Models and Discriminative Training in Natural Image Priors.", "fields": ["latent variable", "discriminative model", "generative design", "image restoration", "generative model"], "abstract": "In recent years, approaches based on machine learning have achieved state-of-the-art performance on image restoration problems. Successful approaches include both generative models of natural images as well as discriminative training of deep neural networks. Discriminative training of feed forward architectures allows explicit control over the computational cost of performing restoration and therefore often leads to better performance at the same cost at run time. In contrast, generative models have the advantage that they can be trained once and then adapted to any image restoration task by a simple use of Bayes' rule.\n\nIn this paper we show how to combine the strengths of both approaches by training a discriminative, feed-forward architecture to predict the state of latent variables in a generative model of natural images. We apply this idea to the very successful Gaussian Mixture Model (GMM) of natural images. We show that it is possible to achieve comparable performance as the original GMM but with two orders of magnitude improvement in run time while maintaining the advantage of generative models.", "citation": "Citations (5)", "year": "2015", "departments": ["Hebrew University of Jerusalem", "Hebrew University of Jerusalem"], "conf": "nips", "authors": ["Dan Rosenbaum.....http://dblp.org/pers/hd/r/Rosenbaum:Dan", "Yair Weiss.....http://dblp.org/pers/hd/w/Weiss:Yair"], "pages": 9}