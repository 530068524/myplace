{"title": "Crowdsourcing user studies with Mechanical Turk.", "fields": ["crowdsourcing", "user modeling", "trade off", "ranging", "computer user satisfaction"], "abstract": "User studies are important for many aspects of the design process and involve techniques ranging from informal surveys to rigorous laboratory studies. However, the costs involved in engaging users often requires practitioners to trade off between sample size, time requirements, and monetary costs. Micro-task markets, such as Amazon's Mechanical Turk, offer a potential paradigm for engaging a large number of users for low time and monetary costs. Here we investigate the utility of a micro-task market for collecting user measurements, and discuss design considerations for developing remote micro user evaluation tasks. Although micro-task markets have great potential for rapidly collecting user measurements at low costs, we found that special care is needed in formulating tasks in order to harness the capabilities of the approach.", "citation": "Citations (1,716)", "year": "2008", "departments": ["PARC, Palo Alto, CA, USA", "PARC, Palo Alto, CA, USA", "PARC, Palo Alto, CA, USA"], "conf": "chi", "authors": ["Aniket Kittur.....http://dblp.org/pers/hd/k/Kittur:Aniket", "Ed H. Chi.....http://dblp.org/pers/hd/c/Chi:Ed_H=", "Bongwon Suh.....http://dblp.org/pers/hd/s/Suh:Bongwon"], "pages": 4}