{"title": "Learning with Annotation Noise.", "fields": ["pattern recognition", "machine learning", "perceptron", "annotation", "natural language processing"], "abstract": "It is usually assumed that the kind of noise existing in annotated data is random classification noise. Yet there is evidence that differences between annotators are not always random attention slips but could result from different biases towards the classification categories, at least for the harder-to-decide cases. Under an annotation generation model that takes this into account, there is a hazard that some of the training instances are actually hard cases with unreliable annotations. We show that these are relatively unproblematic for an algorithm operating under the 0--1 loss model, whereas for the commonly used voted perceptron algorithm, hard training cases could result in incorrect prediction on the uncontroversial cases at test time.", "citation": "Citations (28)", "year": "2009", "departments": ["Washington University in St. Louis", "Northwestern University"], "conf": "acl", "authors": ["Eyal Beigman.....http://dblp.org/pers/hd/b/Beigman:Eyal", "Beata Beigman Klebanov.....http://dblp.org/pers/hd/k/Klebanov:Beata_Beigman"], "pages": 8}