{"title": "Fast Stochastic Variance Reduced ADMM for Stochastic Composition Optimization.", "fields": ["lipschitz continuity", "regular polygon", "stochastic optimization", "ranging", "smoothness"], "abstract": "We consider the stochastic composition optimization problem proposed in [Wang et al., 2016a], which has applications ranging from estimation to statistical and machine learning. We propose the first ADMM-based algorithm named com-SVR-ADMM, and show that com-SVR-ADMM converges linearly for strongly convex and Lipschitz smooth objectives, and has a convergence rate of O(log S/S), which improves upon the O(S-4/9) rate in [Wang et al., 2016b] when the objective is convex and Lipschitz smooth. Moreover, com-SVR-ADMM possesses a rate of O(1/\u221aS) when the objective is convex but without Lipschitz smoothness. We also conduct experiments and show that it outperforms existing algorithms.", "citation": "Citations (3)", "year": "2017", "departments": ["Tsinghua University", "Tsinghua University"], "conf": "ijcai", "authors": ["Yue Yu.....http://dblp.org/pers/hd/y/Yu:Yue", "Longbo Huang.....http://dblp.org/pers/hd/h/Huang:Longbo"], "pages": 7}