{"title": "A Non-Parametric Approach to Dynamic Programming.", "fields": ["nonparametric statistics", "kernel density estimation", "galerkin method", "bellman equation", "temporal difference learning"], "abstract": "In this paper, we consider the problem of policy evaluation for continuous-state systems. We present a non-parametric approach to policy evaluation, which uses kernel density estimation to represent the system. The true form of the value function for this model can be determined, and can be computed using Galerkin's method. Furthermore, we also present a unified view of several well-known policy evaluation methods. In particular, we show that the same Galerkin method can be used to derive Least-Squares Temporal Difference learning, Kernelized Temporal Difference learning, and a discrete-state Dynamic Programming solution, as well as our proposed method. In a numerical evaluation of these algorithms, the proposed approach performed better than the other methods.", "citation": "Citations (9)", "departments": ["Max Planck Society", "Max Planck Society"], "authors": ["Oliver Kroemer.....http://dblp.org/pers/hd/k/Kroemer:Oliver", "Jan Peters.....http://dblp.org/pers/hd/p/Peters_0001:Jan"], "conf": "nips", "year": "2011", "pages": 9}