{"title": "Deep transfer metric learning.", "fields": ["data point", "autoencoder", "unsupervised learning", "divergence", "data set", "exploit", "discriminative model", "semi supervised learning"], "abstract": "Conventional metric learning methods usually assume that the training and test samples are captured in similar scenarios so that their distributions are assumed to be the same. This assumption doesn't hold in many real visual recognition applications, especially when samples are captured across different datasets. In this paper, we propose a new deep transfer metric learning (DTML) method to learn a set of hierarchical nonlinear transformations for cross-domain visual recognition by transferring discriminative knowledge from the labeled source domain to the unlabeled target domain. Specifically, our DTML learns a deep metric network by maximizing the inter-class variations and minimizing the intra-class variations, and minimizing the distribution divergence between the source domain and the target domain at the top layer of the network. To better exploit the discriminative information from the source domain, we further develop a deeply supervised transfer metric learning (DSTML) method by including an additional objective on DTML where the output of both the hidden layers and the top layer are optimized jointly. Experimental results on cross-dataset face verification and person re-identification validate the effectiveness of the proposed methods.", "citation": "Citations (99)", "year": "2015", "departments": ["Nanyang Technological University", "Agency for Science, Technology and Research", "Nanyang Technological University", "Nanyang Technological University", "Tsinghua University", "Nanyang Technological University", "Tsinghua University"], "conf": "cvpr", "authors": ["Junlin Hu.....http://dblp.org/pers/hd/h/Hu:Junlin", "Jiwen Lu.....http://dblp.org/pers/hd/l/Lu:Jiwen", "Yap-Peng Tan.....http://dblp.org/pers/hd/t/Tan:Yap=Peng"], "pages": 9}