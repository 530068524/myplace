{"title": "Binarized Neural Networks.", "fields": ["multiplication", "theano", "mnist database", "logical matrix", "binary number"], "abstract": "We introduce a method to train Binarized Neural Networks (BNNs) - neural networks with binary weights and activations at run-time. At train-time the binary weights and activations are used for computing the parameter gradients. During the forward pass, BNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations, which is expected to substantially improve power-efficiency. To validate the effectiveness of BNNs, we conducted two sets of experiments on the Torch7 and Theano frameworks. On both, BNNs achieved nearly state-of-the-art results over the MNIST, CIFAR-10 and SVHN datasets. We also report our preliminary results on the challenging ImageNet dataset. Last but not least, we wrote a binary matrix multiplication GPU kernel with which it is possible to run our MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The code for training and running our BNNs is available on-line.", "citation": "Citations (223)", "departments": ["Technion \u2013 Israel Institute of Technology", "\u00c9cole Polytechnique de Montr\u00e9al", "Columbia University", "Technion \u2013 Israel Institute of Technology", "Universit\u00e9 de Montr\u00e9al"], "authors": ["Itay Hubara.....http://dblp.org/pers/hd/h/Hubara:Itay", "Matthieu Courbariaux.....http://dblp.org/pers/hd/c/Courbariaux:Matthieu", "Daniel Soudry.....http://dblp.org/pers/hd/s/Soudry:Daniel", "Ran El-Yaniv.....http://dblp.org/pers/hd/e/El=Yaniv:Ran", "Yoshua Bengio.....http://dblp.org/pers/hd/b/Bengio:Yoshua"], "conf": "nips", "year": "2016", "pages": 9}