{"title": "Convex Adversarial Collective Classification.", "fields": ["adversary model", "regularization", "adversary", "regular polygon", "adversarial system"], "abstract": "In this paper, we present a novel method for robustly performing collective classification in the presence of a malicious adversary that can modify up to a fixed number of binary-valued attributes. Our method is formulated as a convex quadratic program that guarantees optimal weights against a worst-case adversary in polynomial time. In addition to increased robustness against active adversaries, this kind of adversarial regularization can also lead to improved generalization even when no adversary is present. In experiments on real and simulated data, our method consistently outperforms both nonadversarial and non-relational baselines.", "citation": "Citations (15)", "departments": ["University of Oregon", "University of Oregon"], "authors": ["MohamadAli Torkamani.....http://dblp.org/pers/hd/t/Torkamani:MohamadAli", "Daniel Lowd.....http://dblp.org/pers/hd/l/Lowd:Daniel"], "conf": "icml", "year": "2013", "pages": 9}