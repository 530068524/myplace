{"title": "Reinforcement Learning for Mapping Instructions to Actions.", "fields": ["action selection", "executable", "supervised learning", "troubleshooting", "log linear model"], "abstract": "In this paper, we present a reinforcement learning approach for mapping natural language instructions to sequences of executable actions. We assume access to a reward function that defines the quality of the executed actions. During training, the learner repeatedly constructs action sequences for a set of documents, executes those actions, and observes the resulting reward. We use a policy gradient algorithm to estimate the parameters of a log-linear model for action selection. We apply our method to interpret instructions in two domains --- Windows troubleshooting guides and game tutorials. Our results demonstrate that this method can rival supervised learning techniques while requiring few or no annotated training examples.", "citation": "Citations (183)", "year": "2009", "departments": ["Massachusetts Institute of Technology", "Massachusetts Institute of Technology", "Massachusetts Institute of Technology", "Massachusetts Institute of Technology"], "conf": "acl", "authors": ["S. R. K. Branavan.....http://dblp.org/pers/hd/b/Branavan:S=_R=_K=", "Harr Chen.....http://dblp.org/pers/hd/c/Chen:Harr", "Luke S. Zettlemoyer.....http://dblp.org/pers/hd/z/Zettlemoyer:Luke_S=", "Regina Barzilay.....http://dblp.org/pers/hd/b/Barzilay:Regina"], "pages": 9}