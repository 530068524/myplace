{"title": "Discriminative Vanishing Component Analysis.", "fields": ["polynomial kernel", "kernel principal component analysis", "component analysis", "discriminative model", "kernel method"], "abstract": "Vanishing Component Analysis (VCA) is a recently proposed prominent work in machine learning. It narrows the gap between tools and computational algebra: the vanishing ideal and its applications to classification problem. In this paper, we will analyze VCA in the kernel view, which is also another important research direction in machine learning. Under a very weak assumption, we provide a different point of view to VCA and make the kernel trick on VCA become possible. We demonstrate that the projection matrix derived by VCA is located in the same space as that of Kernel Principal Component Analysis (KPCA) with a polynomial kernel. Two groups of projections can express each other by linear transformation. Furthermore, we prove that KPCA and VCA have identical discriminative power, provided that the ratio trace criteria is employed as the measurement. We also show that the kernel formulated by the inner products of VCA's projections can be expressed by the KPCA's kernel linearly. Based on the analysis above, we proposed a novel Discriminative Vanishing Component Analysis (DVCA) approach. Experimental results are provided for demonstration.", "citation": "Citations (2)", "departments": ["National University of Defense Technology", "Northwestern Polytechnical University", "University of Technology, Sydney"], "authors": ["Chenping Hou.....http://dblp.org/pers/hd/h/Hou:Chenping", "Feiping Nie.....http://dblp.org/pers/hd/n/Nie:Feiping", "Dacheng Tao.....http://dblp.org/pers/hd/t/Tao:Dacheng"], "conf": "aaai", "year": "2016", "pages": 7}