{"title": "Generating Long-term Trajectories Using Deep Hierarchical Networks.", "fields": ["artificial neural network", "machine learning", "baseline", "markov decision process", "policy learning"], "abstract": "We study the problem of modeling spatiotemporal trajectories over long time horizons using expert demonstrations. For instance, in sports, agents often choose action sequences with long-term goals in mind, such as achieving a certain strategic position. Conventional policy learning approaches, such as those based on Markov decision processes, generally fail at learning cohesive long-term behavior in such high-dimensional state spaces, and are only effective when fairly myopic decision-making yields the desired behavior. The key difficulty is that conventional models are ``single-scale'' and only learn a single state-action policy. We instead propose a hierarchical policy class that automatically reasons about both long-term and short-term goals, which we instantiate as a hierarchical neural network. We showcase our approach in a case study on learning to imitate demonstrated basketball trajectories, and show that it generates significantly more realistic trajectories compared to non-hierarchical baselines as judged by professional sports analysts.", "citation": "Citations (13)", "departments": ["California Institute of Technology", "California Institute of Technology", "Disney Research"], "authors": ["Stephan Zheng.....http://dblp.org/pers/hd/z/Zheng:Stephan", "Yisong Yue.....http://dblp.org/pers/hd/y/Yue:Yisong", "Jennifer Hobbs.....http://dblp.org/pers/hd/h/Hobbs:Jennifer"], "conf": "nips", "year": "2016", "pages": 9}