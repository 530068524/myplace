{"title": "Stochastic Variational Inference for Bayesian Time Series Models.", "fields": ["hidden markov model", "inference", "small number", "time series", "bayesian probability"], "abstract": "Bayesian models provide powerful tools for analyzing complex time series data, but performing inference with large datasets is a challenge. Stochastic variational inference (SVI) provides a new framework for approximating model posteriors with only a small number of passes through the data, enabling such models to be fit at scale. However, its application to time series models has not been studied.\n\nIn this paper we develop SVI algorithms for several common Bayesian time series models, namely the hidden Markov model (HMM), hidden semi-Markov model (HSMM), and the non-parametric HDP-HMM and HDP-HSMM. In addition, because HSMM inference can be expensive even in the minibatch setting of SVI, we develop fast approximate updates for HSMMs with durations distributions that are negative binomials or mixtures of negative binomials.", "citation": "Citations (29)", "year": "2014", "departments": ["Massachusetts Institute of Technology", "Massachusetts Institute of Technology"], "conf": "icml", "authors": ["Matthew James Johnson.....http://dblp.org/pers/hd/j/Johnson:Matthew_James", "Alan S. Willsky.....http://dblp.org/pers/hd/w/Willsky:Alan_S="], "pages": 9}