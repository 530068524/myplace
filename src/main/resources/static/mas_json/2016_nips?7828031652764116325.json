{"title": "Higher-Order Factorization Machines.", "fields": ["machine learning", "existential quantification", "artificial intelligence", "factorization", "supervised learning"], "abstract": "Factorization machines (FMs) are a supervised learning approach that can use second-order feature combinations even when the data is very high-dimensional. Unfortunately, despite increasing interest in FMs, there exists to date no efficient training algorithm for higher-order FMs (HOFMs). In this paper, we present the first generic yet efficient algorithms for training arbitrary-order HOFMs. We also present new variants of HOFMs with shared parameters, which greatly reduce model size and prediction times while maintaining similar accuracy. We demonstrate the proposed approaches on four different link prediction tasks.", "citation": "Citations (11)", "departments": ["Nippon Telegraph and Telephone", "Nippon Telegraph and Telephone", "Nippon Telegraph and Telephone", "Nippon Telegraph and Telephone"], "authors": ["Mathieu Blondel.....http://dblp.org/pers/hd/b/Blondel:Mathieu", "Akinori Fujino.....http://dblp.org/pers/hd/f/Fujino:Akinori", "Naonori Ueda.....http://dblp.org/pers/hd/u/Ueda:Naonori", "Masakazu Ishihata.....http://dblp.org/pers/hd/i/Ishihata:Masakazu"], "conf": "nips", "year": "2016", "pages": 9}