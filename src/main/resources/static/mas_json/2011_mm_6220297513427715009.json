{"title": "Efficient multi-modal retrieval in conceptual space.", "fields": ["visual word", "video tracking", "feature", "bag of words model in computer vision", "automatic image annotation"], "abstract": "In this paper, we propose a new, efficient retrieval system for large-scale multi-modal data including video tracks. With large-scale multi-modal data, the huge data size and various contents cause degradation of efficiency and precision of retrieval results. Recent research on image annotation and retrieval shows that image features based on the Bag-of-Visual Words approach with local descriptors such as SIFT perform surprisingly well with large-scale image datasets. Those powerful descriptors tend to be high-dimensional, imposing a high computational cost for approximate nearest neighbor searching in raw feature space. Our video retrieval method is focused on the correlation between image, sound, and location information recorded simultaneously, and to learn conceptual space describing the contents of the data to realize efficient searching. Experiments show good performance of our retrieval system with low memory usage and temporal complexity.", "citation": "Citations (5)", "departments": ["University of Tokyo", "University of Tokyo", "University of Tokyo", "University of Tokyo"], "authors": ["Jun Imura.....http://dblp.org/pers/hd/i/Imura:Jun", "Teppei Fujisawa.....http://dblp.org/pers/hd/f/Fujisawa:Teppei", "Tatsuya Harada.....http://dblp.org/pers/hd/h/Harada:Tatsuya", "Yasuo Kuniyoshi.....http://dblp.org/pers/hd/k/Kuniyoshi:Yasuo"], "conf": "mm", "year": "2011", "pages": 4}