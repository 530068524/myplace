{"title": "Matrix Eigen-decomposition via Doubly Stochastic Riemannian Optimization.", "fields": ["eigendecomposition of a matrix", "gradient descent", "manifold", "euclidean geometry", "matrix"], "abstract": "Matrix eigen-decomposition is a classic and long-standing problem that plays a fundamental role in scientific computing and machine learning. Despite some existing algorithms for this inherently non-convex problem, the study remains inadequate for the need of large data nowadays. To address this gap, we propose a Doubly Stochastic Riemannian Gradient EIGenSolver, DSRG-EIGS, where the double stochasticity comes from the generalization of the stochastic Euclidean gradient ascent and the stochastic Euclidean coordinate ascent to Riemannian manifolds. As a result, it induces a greatly reduced complexity per iteration, enables the algorithm to completely avoid the matrix inversion, and consequently makes it well-suited to large-scale applications. We theoretically analyze its convergence properties and empirically validate it on real-world datasets. Encouraging experimental results demonstrate its advantages over the deterministic counterpart.", "citation": "Citations (2)", "year": "2016", "departments": ["Agency for Science, Technology and Research", "Agency for Science, Technology and Research", "Agency for Science, Technology and Research", "Agency for Science, Technology and Research"], "conf": "icml", "authors": ["Zhiqiang Xu.....http://dblp.org/pers/hd/x/Xu:Zhiqiang", "Peilin Zhao.....http://dblp.org/pers/hd/z/Zhao:Peilin", "Jianneng Cao.....http://dblp.org/pers/hd/c/Cao:Jianneng", "Xiaoli Li.....http://dblp.org/pers/hd/l/Li_0001:Xiaoli"], "pages": 10}