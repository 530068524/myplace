{"title": "Improving Model Counting by Leveraging Definability.", "fields": ["machine learning", "discrete mathematics", "preprocessor", "artificial intelligence", "theoretical computer science"], "abstract": "We present a new preprocessing technique for propositional model counting. This technique leverages definability, i.e., the ability to determine that some gates are implied by the input formula \u03a3. Such gates can be exploited to simplify \u03a3 without modifying its number of models. Unlike previous techniques based on gate detection and replacement, gates do not need to be made explicit in our approach. Our preprocessing technique thus consists of two phases: computing a bipartition \u2329I,O\u232a of the variables of \u03a3 where the variables from O are defined in \u03a3 in terms of I, then eliminating some variables of O in \u03a3. Our experiments show the computational benefits which can be achieved by taking advantage of our preprocessing technique for model counting.", "citation": "Not cited", "year": "2016", "departments": ["Centre national de la recherche scientifique", "Centre national de la recherche scientifique", "Centre national de la recherche scientifique"], "conf": "ijcai", "authors": ["Jean-Marie Lagniez.....http://dblp.org/pers/hd/l/Lagniez:Jean=Marie", "Emmanuel Lonca.....http://dblp.org/pers/hd/l/Lonca:Emmanuel", "Pierre Marquis.....http://dblp.org/pers/hd/m/Marquis:Pierre"], "pages": 7}