{"title": "Learning to See Physics via Visual De-animation.", "fields": ["real image", "generative grammar", "rendering", "animation", "differentiable function"], "abstract": "We introduce a paradigm for understanding physical scenes without human annotations. At the core of our system is a physical world representation that is first recovered by a perception module and then utilized by physics and graphics engines. During training, the perception module and the generative models learn by visual de-animation --- interpreting and reconstructing the visual information stream. During testing, the system first recovers the physical world state, and then uses the generative models for reasoning and future prediction. Even more so than forward simulation, inverting a physics or graphics engine is a computationally hard problem; we overcome this challenge by using a convolutional inversion network. Our system quickly recognizes the physical world state from appearance and motion cues, and has the flexibility to incorporate both differentiable and non-differentiable physics and graphics engines. We evaluate our system on both synthetic and real datasets involving multiple physical scenes, and demonstrate that our system performs well on both physical state estimation and reasoning problems. We further show that the knowledge learned on the synthetic dataset generalizes to constrained real images.", "citation": "Citations (11)", "year": "2017", "departments": ["Massachusetts Institute of Technology", "University of Oxford", "Microsoft", "Massachusetts Institute of Technology", "Massachusetts Institute of Technology"], "conf": "nips", "authors": ["Jiajun Wu.....http://dblp.org/pers/hd/w/Wu_0001:Jiajun", "Erika Lu.....http://dblp.org/pers/hd/l/Lu:Erika", "Pushmeet Kohli.....http://dblp.org/pers/hd/k/Kohli:Pushmeet", "Bill Freeman.....http://dblp.org/pers/hd/f/Freeman:Bill", "Josh Tenenbaum.....http://dblp.org/pers/hd/t/Tenenbaum:Josh"], "pages": 12}