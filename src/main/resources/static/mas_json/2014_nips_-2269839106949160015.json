{"title": "Deep Recursive Neural Networks for Compositionality in Language.", "fields": ["deep belief network", "recursion", "principle of compositionality", "recurrent neural network", "sentiment analysis"], "abstract": "Recursive neural networks comprise a class of architecture that can operate on structured input. They have been previously successfully applied to model com-positionality in natural language using parse-tree-based structural representations. Even though these architectures are deep in structure, they lack the capacity for hierarchical representation that exists in conventional deep feed-forward networks as well as in recently investigated deep recurrent neural networks. In this work we introduce a new architecture \u2014 a deep recursive neural network (deep RNN) \u2014 constructed by stacking multiple recursive layers. We evaluate the proposed model on the task of fine-grained sentiment classification. Our results show that deep RNNs outperform associated shallow counterparts that employ the same number of parameters. Furthermore, our approach outperforms previous baselines on the sentiment analysis task, including a multiplicative RNN variant as well as the recently introduced paragraph vectors, achieving new state-of-the-art results. We provide exploratory analyses of the effect of multiple layers and show that they capture different aspects of compositionality in language.", "citation": "Citations (137)", "year": "2014", "departments": ["Cornell University", "Cornell University"], "conf": "nips", "authors": ["Ozan Irsoy.....http://dblp.org/pers/hd/i/Irsoy:Ozan", "Claire Cardie.....http://dblp.org/pers/hd/c/Cardie:Claire"], "pages": 9}