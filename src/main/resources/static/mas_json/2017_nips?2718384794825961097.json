{"title": "Controllable Invariance through Adversarial Feature Learning.", "fields": ["contextual image classification", "minimax", "feature learning", "trait", "multi task learning"], "abstract": "Learning meaningful representations that maintain the content necessary for a particular task while filtering away detrimental variations is a problem of great interest in machine learning. In this paper, we tackle the problem of learning representations invariant to a specific factor or trait of data. The representation learning process is formulated as an adversarial minimax game. We analyze the optimal equilibrium of such a game and find that it amounts to maximizing the uncertainty of inferring the detrimental factor given the representation while maximizing the certainty of making task-specific predictions. On three benchmark tasks, namely fair and bias-free classification, language-independent generation, and lighting-independent image classification, we show that the proposed framework induces an invariant representation, and leads to better generalization evidenced by the improved performance.", "citation": "Citations (5)", "year": "2017", "departments": ["Carnegie Mellon University", "Carnegie Mellon University", "Carnegie Mellon University", "Carnegie Mellon University", "Nara Institute of Science and Technology"], "conf": "nips", "authors": ["Qizhe Xie.....http://dblp.org/pers/hd/x/Xie:Qizhe", "Zihang Dai.....http://dblp.org/pers/hd/d/Dai:Zihang", "Yulun Du.....http://dblp.org/pers/hd/d/Du:Yulun", "Eduard H. Hovy.....http://dblp.org/pers/hd/h/Hovy:Eduard_H=", "Graham Neubig.....http://dblp.org/pers/hd/n/Neubig:Graham"], "pages": 12}