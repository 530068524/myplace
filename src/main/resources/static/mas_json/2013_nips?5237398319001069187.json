{"title": "Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima.", "fields": ["generalized linear model", "high dimensional statistics", "estimator", "local optimum", "convexity", "lasso"], "abstract": "We provide novel theoretical results regarding local optima of regularized M-estimators, allowing for nonconvexity in both loss and penalty functions. Under restricted strong convexity on the loss and suitable regularity conditions on the penalty, we prove that any stationary point of the composite objective function will lie within statistical precision of the underlying parameter vector. Our theory covers many nonconvex objective functions of interest, including the corrected Lasso for errors-in-variables linear models; regression for generalized linear models with nonconvex penalties such as SCAD, MCP, and capped-l 1; and high-dimensional graphical model estimation. We quantify statistical accuracy by providing bounds on the l1-, l2-, and prediction error between stationary points and the population-level optimum. We also propose a simple modification of composite gradient descent that may be used to obtain a near-global optimum within statistical precision estat in log(1/estat) steps, which is the fastest possible rate of any first-order method. We provide simulation studies illustrating the sharpness of our theoretical results.", "citation": "Citations (220)", "departments": ["University of Pennsylvania", "University of California, Berkeley", "University of California, Berkeley", "University of California, Berkeley"], "authors": ["Po-Ling Loh.....http://dblp.org/pers/hd/l/Loh:Po=Ling", "Martin J. Wainwright.....http://dblp.org/pers/hd/w/Wainwright:Martin_J="], "conf": "nips", "year": "2013", "pages": 9}