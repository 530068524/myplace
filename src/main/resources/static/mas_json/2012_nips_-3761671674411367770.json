{"title": "On the Use of Non-Stationary Policies for Stationary Infinite-Horizon Markov Decision Processes.", "fields": ["horizon", "mathematical optimization", "existential quantification", "argument", "markov decision process"], "abstract": "We consider infinite-horizon stationary \u03b3-discounted Markov Decision Processes, for which it is known that there exists a stationary optimal policy. Using Value and Policy Iteration with some error e at each iteration, it is well-known that one can compute stationary policies that are 2\u03b3/(1 - \u03b3)2 e-optimal. After arguing that this guarantee is tight, we develop variations of Value and Policy Iteration for computing non-stationary policies that can be up to 2\u03b3/1-\u03b3 e-optimal, which constitutes a significant improvement in the usual situation when \u03b3 is close to 1. Surprisingly, this shows that the problem of \"computing near-optimal non-stationary policies\" is much simpler than that of \"computing near-optimal stationary policies\".", "citation": "Citations (9)", "departments": ["French Institute for Research in Computer Science and Automation", "French Institute for Research in Computer Science and Automation"], "authors": ["Bruno Scherrer.....http://dblp.org/pers/hd/s/Scherrer:Bruno", "Boris Lesner.....http://dblp.org/pers/hd/l/Lesner:Boris"], "conf": "nips", "year": "2012", "pages": 9}