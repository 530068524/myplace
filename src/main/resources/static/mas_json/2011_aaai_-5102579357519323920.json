{"title": "Learning Structured Embeddings of Knowledge Bases.", "fields": ["quantities of information", "collaborative filtering", "machine learning", "artificial intelligence", "mathematics", "annotation", "wordnet", "natural language understanding"], "abstract": "Many Knowledge Bases (KBs) are now readily available and encompass colossal quantities of information thanks to either a long-term funding effort (e.g. WordNet, OpenCyc) or a collaborative process (e.g. Freebase, DBpedia). However, each of them is based on a different rigid symbolic framework which makes it hard to use their data in other systems. It is unfortunate because such rich structured knowledge might lead to a huge leap forward in many other areas of AI like natural language processing (word-sense disambiguation, natural language understanding, ...), vision (scene classification, image semantic annotation, ...) or collaborative filtering. In this paper, we present a learning process based on an innovative neural network architecture designed to embed any of these symbolic representations into a more flexible continuous vector space in which the original knowledge is kept and enhanced. These learnt embeddings would allow data from any KB to be easily used in recent machine learning methods for prediction and information retrieval. We illustrate our method on WordNet and Freebase and also present a way to adapt it to knowledge extraction from raw text.", "citation": "Not cited", "departments": ["Centre national de la recherche scientifique", "Google", "Universit\u00e9 de Montr\u00e9al", "IDIAP, Martigny, Switzerland"], "authors": ["Antoine Bordes.....http://dblp.org/pers/hd/b/Bordes:Antoine", "Jason Weston.....http://dblp.org/pers/hd/w/Weston:Jason", "Ronan Collobert.....http://dblp.org/pers/hd/c/Collobert:Ronan", "Yoshua Bengio.....http://dblp.org/pers/hd/b/Bengio:Yoshua"], "conf": "aaai", "year": "2011", "pages": -1}