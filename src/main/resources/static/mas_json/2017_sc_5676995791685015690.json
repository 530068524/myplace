{"title": "Toward standardized near-data processing with unrestricted data placement for GPUs.", "fields": ["memory bandwidth", "cache", "general purpose computing on graphics processing units", "stack", "bottleneck"], "abstract": "3D-stacked memory devices with processing logic can help alleviate the memory bandwidth bottleneck in GPUs. However, in order for such Near-Data Processing (NDP) memory stacks to be used for different GPU architectures, it is desirable to standardize the NDP architecture. Our proposal enables this standardization by allowing data to be spread across multiple memory stacks as is the norm in high-performance systems without an MMU on the NDP stack. The keys to this architecture are the ability to move data between memory stacks as required for computation, and a  partitioned execution  mechanism that offloads memory-intensive application segments onto the NDP stack and decouples address translation from DRAM accesses. By enhancing this system with a smart offload selection mechanism that is cognizant of the compute capability of the NDP and cache locality on the host processor, system performance and energy are improved by up to 66.8% and 37.6%, respectively.", "citation": "Not cited", "year": "2017", "departments": ["Nvidia", "University of Texas at Austin", "Carnegie Mellon University", "Arm"], "conf": "sc", "authors": ["Gwangsun Kim.....http://dblp.org/pers/hd/k/Kim:Gwangsun", "Niladrish Chatterjee.....http://dblp.org/pers/hd/c/Chatterjee:Niladrish", "Mike O'Connor.....http://dblp.org/pers/hd/o/O=Connor:Mike", "Kevin Hsieh.....http://dblp.org/pers/hd/h/Hsieh:Kevin"], "pages": 12}