{"title": "Stable and Efficient Representation Learning with Nonnegativity Constraints.", "fields": ["overfitting", "pattern recognition", "scalability", "machine learning", "mathematics", "feature learning", "matching pursuit", "approximation algorithm", "artificial intelligence"], "abstract": "Orthogonal matching pursuit (OMP) is an efficient approximation algorithm for computing sparse representations. However, prior research has shown that the representations computed by OMP may be of inferior quality, as they deliver suboptimal classification accuracy on several image datasets. We have found that this problem is caused by OMP's relatively weak stability under data variations, which leads to unreliability in supervised classifier training. We show that by imposing a simple nonnegativity constraint, this nonnegative variant of OMP (NOMP) can mitigate OMP's stability issue and is resistant to noise overfitting. In this work, we provide extensive analysis and experimental results to examine and validate the stability advantage of NOMP. In our experiments, we use a multi-layer deep architecture for representation learning, where we use K-means for feature learning and NOMP for representation encoding. The resulting learning framework is not only efficient and scalable to large feature dictionaries, but also is robust against input noise. This framework achieves the state-of-the-art accuracy on the STL-10 dataset.", "citation": "Citations (25)", "year": "2014", "departments": ["Harvard University", "Harvard University"], "conf": "icml", "authors": ["Tsung-Han Lin.....http://dblp.org/pers/hd/l/Lin:Tsung=Han", "H. T. Kung.....http://dblp.org/pers/hd/k/Kung:H=_T="], "pages": 9}