{"title": "Learning Linear Regression Models over Factorized Joins.", "fields": ["table", "recursive join", "external data representation", "joins", "sql"], "abstract": "We investigate the problem of building least squares regression models over training datasets defined by arbitrary join queries on database tables. Our key observation is that joins entail a high degree of redundancy in both computation and data representation, which is not required for the end-to-end solution to learning over joins.   We propose a new paradigm for computing batch gradient descent that exploits the factorized computation and representation of the training datasets, a rewriting of the regression objective function that decouples the computation of cofactors of model parameters from their convergence, and the commutativity of cofactor computation with relational union and projection. We introduce three flavors of this approach: F/FDB computes the cofactors in one pass over the materialized factorized join; Favoids this materialization and intermixes cofactor and join computation; F/SQL expresses this mixture as one SQL query.   Our approach has the complexity of join factorization, which can be exponentially lower than of standard joins. Experiments with commercial, public, and synthetic datasets show that it outperforms MADlib, Python StatsModels, and R, by up to three orders of magnitude.", "citation": "Citations (33)", "year": "2016", "departments": ["University of Oxford", "University of Oxford", "University of Oxford"], "conf": "sigmod", "authors": ["Maximilian Schleich.....http://dblp.org/pers/hd/s/Schleich:Maximilian", "Dan Olteanu.....http://dblp.org/pers/hd/o/Olteanu:Dan", "Radu Ciucanu.....http://dblp.org/pers/hd/c/Ciucanu:Radu"], "pages": 16}