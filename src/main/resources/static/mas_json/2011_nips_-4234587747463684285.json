{"title": "Composite Multiclass Losses.", "fields": ["bayes theorem", "machine learning", "uniqueness", "hessian matrix", "binary number", "mathematical optimization", "composite number", "convexity"], "abstract": "We consider loss functions for multiclass prediction problems. We show when a multiclass loss can be expressed as a \"proper composite loss\", which is the composition of a proper loss and a link function. We extend existing results for binary losses to multiclass losses. We subsume results on \"classification calibration\" by relating it to properness. We determine the stationarity condition, Bregman representation, order-sensitivity, and quasi-convexity of multiclass proper losses. We then characterise the existence and uniqueness of the composite representation for multiclass losses. We show how the composite representation is related to other core properties of a loss: mixability, admissibility and (strong) convexity of multiclass losses which we characterise in terms of the Hessian of the Bayes risk. We show that the simple integral representation for binary proper losses can not be extended to multiclass losses but offer concrete guidance regarding how to design different loss functions. The conclusion drawn from these results is that the proper composite representation is a natural and convenient tool for the design of multiclass loss functions.", "citation": "Citations (12)", "departments": ["Australian National University", "University of Cambridge", "Australian National University", "\u00c9cole Normale Sup\u00e9rieure", "Australian National University", "Australian National University"], "authors": ["Elodie Vernet.....http://dblp.org/pers/hd/v/Vernet:Elodie", "Robert C. Williamson.....http://dblp.org/pers/hd/w/Williamson:Robert_C=", "Mark D. Reid.....http://dblp.org/pers/hd/r/Reid:Mark_D="], "conf": "nips", "year": "2011", "pages": 9}