{"title": "Solving Risk-Sensitive POMDPs With and Without Cost Observations.", "fields": ["observable", "partially observable markov decision process", "scalability", "markov decision process", "machine learning"], "abstract": "Partially Observable Markov Decision Processes (POMDPs) are often used to model planning problems under uncertainty. The goal in Risk-Sensitive POMDPs (RS-POMDPs) is to find a policy that maximizes the probability that the cumulative cost is within some user-defined cost threshold. In this paper, unlike existing POMDP literature, we distinguish between the two cases of whether costs can or cannot be observed and show the empirical impact of cost observations. We also introduce a new search-based algorithm to solve RS-POMDPs and show that it is faster and more scalable than existing approaches in two synthetic domains and a taxi domain generated with real-world data.", "citation": "Citations (2)", "departments": ["New Mexico State University", "New Mexico State University", "Singapore Management University"], "authors": ["Ping Hou.....http://dblp.org/pers/hd/h/Hou:Ping", "William Yeoh.....http://dblp.org/pers/hd/y/Yeoh_0001:William", "Pradeep Varakantham.....http://dblp.org/pers/hd/v/Varakantham:Pradeep"], "conf": "aaai", "year": "2016", "pages": 7}