{"title": "Stability of influence maximization.", "fields": ["robust optimization", "machine learning", "maximization", "artificial intelligence", "submodular set function"], "abstract": "The present article serves as an erratum to our paper of the same title, which was presented and published in the KDD 2014 conference. In that article, we claimed falsely that the objective function defined in Section 1.4 is non-monotone submodular. We are deeply indebted to Debmalya Mandal, Jean Pouget-Abadie and Yaron Singer for bringing to our attention a counter-example to that claim.      Subsequent to becoming aware of the counter-example, we have shown that the objective function is in fact NP-hard to approximate to within a factor of O(n 1-e ) for any e > 0.      In an attempt to fix the record, the present article combines the problem motivation, models, and experimental results sections from the original incorrect article with the new hardness result. We would like readers to only cite and use this version (which will remain an unpublished note) instead of the incorrect conference version.", "citation": "Citations (16)", "departments": ["University of Southern California", "University of Southern California"], "authors": ["Xinran He.....http://dblp.org/pers/hd/h/He:Xinran", "David Kempe.....http://dblp.org/pers/hd/k/Kempe_0001:David"], "conf": "kdd", "year": "2014", "pages": 10}