{"title": "Multi Class Learning with Individual Sparsity.", "fields": ["small set", "training set", "small number", "regularization", "lasso"], "abstract": "Multi class problems are everywhere. Given an input the goal is to predict one of a few possible classes. Most previous work reduced learning to minimizing the empirical loss over some training set and an additional regularization term, prompting simple models or some other prior knowledge. Many learning regularizations promote sparsity, that is, small models or small number of features, as performed in group LASSO. Yet, such models do not always represent the classes well. In some problems, for each class, there is a small set of features that represents it well, yet the union of these sets is not small. We propose to use other regularizations that promote this type of sparsity, analyze the generalization property of such formulations, and show empirically that indeed, these regularizations not only perform well, but also promote such sparsity structure.", "citation": "Citations (1)", "year": "2013", "departments": ["Technion \u2013 Israel Institute of Technology", "Technion \u2013 Israel Institute of Technology"], "conf": "ijcai", "authors": ["Ben Zion Vatashsky.....http://dblp.org/pers/hd/v/Vatashsky:Ben_Zion", "Koby Crammer.....http://dblp.org/pers/hd/c/Crammer:Koby"], "pages": 7}