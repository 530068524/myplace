{"title": "Automatic construction of an action video shot database using web videos.", "fields": ["visualization", "image segmentation", "visualrank", "web api", "similarity matrix"], "abstract": "There are a huge number of videos with text tags on the Web nowadays. In this paper, we propose a method of automatically extracting from Web videos video shots corresponding to specific actions with just only providing action keywords such as \u201cwalking\u201d and \u201ceating\u201d. The proposed method consists of three steps: (1) tag-based video selection, (2) segmenting videos into shots and extracting features from the shots, and (3) visual-feature-based video shot selection with tag-based scores taken into account. Firstly, we gather video IDs and tag lists for 1000 Web videos corresponding to given keywords via Web API, and we calculate tag relevance scores for each video using a tag-co-occurrence dictionary which is constructed in advance. Secondly, we fetch the top 200 videos from the Web in the descending order of the tag relevance scores, and segment each downloaded video into several shots. From each shot we extract spatio-temporal features, global motion features and appearance features, and convert them into the bag-of-features representation. Finally, we apply the VisualRank method to select the video shots which describe the actions corresponding to the given keywords best after calculating a similarity matrix between video shots. In the experiments, we achieved the 49.5% precision at 100 shots over six kinds of human actions by just providing keywords without any supervision. In addition, we made large-scale experiments on 100 kinds of action keywords.", "citation": "Citations (10)", "year": "2011", "departments": ["University of Electro-Communications", "University of Electro-Communications"], "conf": "iccv", "authors": ["Do Hang Nga.....http://dblp.org/pers/hd/n/Nga:Do_Hang", "Keiji Yanai.....http://dblp.org/pers/hd/y/Yanai:Keiji"], "pages": 8}