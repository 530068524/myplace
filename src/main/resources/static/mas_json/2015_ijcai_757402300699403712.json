{"title": "Efficient Generalized Conditional Gradient with Gradient Sliding for Composite Optimization.", "fields": ["proximal gradient methods", "matrix decomposition", "lasso", "nonlinear conjugate gradient method", "frank wolfe algorithm"], "abstract": "Generalized conditional gradient method has regained increasing research interest as an alternative to another popular proximal gradient method for sparse optimization problems. For particular tasks, its low computation cost of linear subproblem evaluation on each iteration leads to superior practical performance. However, the inferior iteration complexity incurs excess number of gradient evaluations, which can counteract the efficiency gained by solving low cost linear subproblem. In this paper, we therefore propose a novel algorithm that requires optimal graduate evaluations as proximal gradient. We also present a refined variant for a type of gauge regularized problem where approximation techniques are allowed to further accelerate linear subproblem computation. Experiments of CUR-like matrix factorization problem with group lasso penalty on four real-world datasets demonstrate the efficiency of the proposed method.", "citation": "Not cited", "departments": ["Hong Kong Baptist University", "Hong Kong Baptist University"], "authors": ["Yiu-ming Cheung.....http://dblp.org/pers/hd/c/Cheung:Yiu=ming", "Jian Lou.....http://dblp.org/pers/hd/l/Lou:Jian"], "conf": "ijcai", "year": "2015", "pages": 7}