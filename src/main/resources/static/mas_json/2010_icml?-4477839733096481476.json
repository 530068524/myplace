{"title": "Least-Squares Policy Iteration: Bias-Variance Trade-off in Control Problems.", "fields": ["modified richardson iteration", "arnoldi iteration", "fixed point iteration", "markov decision process", "preconditioner"], "abstract": "In the context of large space MDPs with linear value function approximation, we introduce a new approximate version of \u03bb-Policy Iteration (Bertsekas & Ioffe, 1996), a method that generalizes Value Iteration and Policy Iteration with a parameter \u03bb \u2208 (0,1). Our approach, called Least-Squares \u03bb Policy Iteration, generalizes LSPI (Lagoudakis & Parr, 2003) which makes efficient use of training samples compared to classical temporal-differences methods. The motivation of our work is to exploit the \u03bb parameter within the least-squares context, and without having to generate new samples at each iteration or to know a model of the MDP. We provide a performance bound that shows the soundness of the algorithm. We show empirically on a simple chain problem and on the Tetris game that this \u03bb parameter acts as a bias-variance trade-off that may improve the convergence and the performance of the policy obtained.", "citation": "Citations (20)", "departments": ["French Institute for Research in Computer Science and Automation", "French Institute for Research in Computer Science and Automation"], "authors": ["Christophe Thiery.....http://dblp.org/pers/hd/t/Thiery:Christophe", "Bruno Scherrer.....http://dblp.org/pers/hd/s/Scherrer:Bruno"], "conf": "icml", "year": "2010", "pages": 8}