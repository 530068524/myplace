{"title": "Counterfactual Multi-Agent Policy Gradients.", "fields": ["network packet", "micromanagement", "observability", "testbed", "counterfactual thinking"], "abstract": "Cooperative multi-agent systems can be naturally used to model many real world problems, such as network packet routing and the coordination of autonomous vehicles. There is a great need for new reinforcement learning methods that can efficiently learn decentralised policies for such systems. To this end, we propose a new multi-agent actor-critic method called counterfactual multi-agent (COMA) policy gradients. COMA uses a centralised critic to estimate the Q-function and decentralised actors to optimise the agents' policies. In addition, to address the challenges of multi-agent credit assignment, it uses a counterfactual baseline that marginalises out a single agent's action, while keeping the other agents' actions fixed. COMA also uses a critic representation that allows the counterfactual baseline to be computed efficiently in a single forward pass. We evaluate COMA in the testbed of StarCraft unit micromanagement, using a decentralised variant with significant partial observability. COMA significantly improves average performance over other multi-agent actor-critic methods in this setting, and the best performing agents are competitive with state-of-the-art centralised controllers that get access to the full state.", "citation": "Citations (21)", "departments": ["University of Oxford", "University of Oxford", "University of Oxford", "University of Oxford"], "authors": ["Jakob N. Foerster.....http://dblp.org/pers/hd/f/Foerster:Jakob_N=", "Gregory Farquhar.....http://dblp.org/pers/hd/f/Farquhar:Gregory", "Triantafyllos Afouras.....http://dblp.org/pers/hd/a/Afouras:Triantafyllos", "Nantas Nardelli.....http://dblp.org/pers/hd/n/Nardelli:Nantas", "Shimon Whiteson.....http://dblp.org/pers/hd/w/Whiteson:Shimon"], "conf": "aaai", "year": "2018", "pages": 9}