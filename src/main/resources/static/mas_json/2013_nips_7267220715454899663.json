{"title": "Learning Stochastic Inverses.", "fields": ["fold", "joint probability distribution", "markov chain monte carlo", "factorization", "conditional probability distribution"], "abstract": "We describe a class of algorithms for amortized inference in Bayesian networks. In this setting, we invest computation upfront to support rapid online inference for a wide range of queries. Our approach is based on learning an inverse factorization of a model's joint distribution: a factorization that turns observations into root nodes. Our algorithms accumulate information to estimate the local conditional distributions that constitute such a factorization. These stochastic inverses can be used to invert each of the computation steps leading to an observation, sampling backwards in order to quickly find a likely explanation. We show that estimated inverses converge asymptotically in number of (prior or posterior) training samples. To make use of inverses before convergence, we describe the Inverse MCMC algorithm, which uses stochastic inverses to make block proposals for a Metropolis-Hastings sampler. We explore the efficiency of this sampler for a variety of parameter regimes and Bayes nets.", "citation": "Citations (32)", "departments": ["Massachusetts Institute of Technology", "Stanford University", "Stanford University"], "authors": ["Andreas Stuhlm\u00fcller.....http://dblp.org/pers/hd/s/Stuhlm=uuml=ller:Andreas", "Jessica Taylor.....http://dblp.org/pers/hd/t/Taylor:Jessica", "Noah D. Goodman.....http://dblp.org/pers/hd/g/Goodman:Noah_D="], "conf": "nips", "year": "2013", "pages": 9}