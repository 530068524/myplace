{"title": "Algorithmic Exam Generation.", "fields": ["computer science", "machine learning", "composition", "artificial intelligence", "overlay"], "abstract": "Given a class of students, and a pool of questions in the domain of study, what subset will constitute a \"good\" exam? Millions of educators are dealing with this difficult problem worldwide, yet exams are still composed manually in non-systematic ways. In this work we present a novel algorithmic framework for exam composition. Our framework requires two input components: a student population represented by a distribution over overlay models, each consisting of a set of mastered abilities, or actions; and a target model ordering that, given any two student models, defines which should be given the higher grade. To determine the performance of a student model on a potential question, we test whether it satisfies a disjunctive action landmark, i.e., whether its abilities are sufficient to follow at least one solution path. We present a novel utility function for evaluating exams, using the described components. An exam is highly evaluated if it is expected to order the student population with high correlation to the target order. The merit of our algorithmic framework is exemplified with real autogenerated questions in the domain of middle-school algebra.", "citation": "Not cited", "departments": ["Technion \u2013 Israel Institute of Technology", "Technion \u2013 Israel Institute of Technology"], "authors": ["Omer Geiger.....http://dblp.org/pers/hd/g/Geiger:Omer", "Shaul Markovitch.....http://dblp.org/pers/hd/m/Markovitch:Shaul"], "conf": "ijcai", "year": "2015", "pages": 7}