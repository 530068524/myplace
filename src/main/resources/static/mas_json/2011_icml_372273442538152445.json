{"title": "Apprenticeship Learning About Multiple Intentions.", "fields": ["apprenticeship learning", "natural approach", "gradient descent", "reinforcement learning", "trajectory"], "abstract": "In this paper, we apply tools from inverse reinforcement learning (IRL) to the problem of learning from (unlabeled) demonstration trajectories of behavior generated by varying \"intentions\" or objectives. We derive an EM approach that clusters observed trajectories by inferring the objectives for each cluster using any of several possible IRL methods, and then uses the constructed clusters to quickly identify the intent of a trajectory. We show that a natural approach to IRL\u2014a gradient ascent method that modifies reward parameters to maximize the likelihood of the observed trajectories\u2014is successful at quickly identifying unknown reward functions. We demonstrate these ideas in the context of apprenticeship learning by acquiring the preferences of a human driver in a simple highway car simulator.", "citation": "Citations (75)", "year": "2011", "departments": ["Rutgers University", "Rutgers University", "Georgia Institute of Technology", "Rutgers University"], "conf": "icml", "authors": ["Monica Babes.....http://dblp.org/pers/hd/b/Babes:Monica", "Vukosi N. Marivate.....http://dblp.org/pers/hd/m/Marivate:Vukosi_N=", "Kaushik Subramanian.....http://dblp.org/pers/hd/s/Subramanian:Kaushik", "Michael L. Littman.....http://dblp.org/pers/hd/l/Littman:Michael_L="], "pages": 8}