{"title": "A Teacher-Student Framework for Zero-Resource Neural Machine Translation.", "fields": ["bleu", "machine translation", "natural language processing", "scarcity", "sentence"], "abstract": "While end-to-end neural machine translation (NMT) has made remarkable progress recently, it still suffers from the data scarcity problem for low-resource language pairs and domains. In this paper, we propose a method for zero-resource NMT by assuming that parallel sentences have close probabilities of generating a sentence in a third language. Based on this assumption, our method is able to train a source-to-target NMT model (\"student\") without parallel corpora available, guided by an existing pivot-to-target NMT model (\"teacher\") on a source-pivot parallel corpus. Experimental results show that the proposed method significantly improves over a baseline pivot-based model by +3.0 BLEU points across various language pairs.", "citation": "Citations (8)", "year": "2017", "departments": ["University of Hong Kong", "Tsinghua University", "Tsinghua University", "University of Hong Kong"], "conf": "acl", "authors": ["Yun Chen.....http://dblp.org/pers/hd/c/Chen:Yun", "Yang Liu.....http://dblp.org/pers/hd/l/Liu:Yang", "Yong Cheng.....http://dblp.org/pers/hd/c/Cheng:Yong", "Victor O. K. Li.....http://dblp.org/pers/hd/l/Li:Victor_O=_K="], "pages": 11}