{"title": "Dynamic Memory Networks for Visual and Textual Question Answering.", "fields": ["dynamic random access memory", "question answering", "architecture", "artificial neural network", "modalities"], "abstract": "Neural network architectures with memory and attention mechanisms exhibit certain reasoning capabilities required for question answering. One such architecture, the dynamic memory network (DMN), obtained high accuracy on a variety of language tasks. However, it was not shown whether the architecture achieves strong results for question answering when supporting facts are not marked during training or whether it could be applied to other modalities such as images. Based on an analysis of the DMN, we propose several improvements to its memory and input modules. Together with these changes we introduce a novel input module for images in order to be able to answer visual questions. Our new DMN+ model improves the state of the art on both the Visual Question Answering dataset and the bAbI-10k text question-answering dataset without supporting fact supervision.", "citation": "Citations (268)", "year": "2016", "departments": ["Salesforce.com", "Salesforce.com", "Salesforce.com"], "conf": "icml", "authors": ["Caiming Xiong.....http://dblp.org/pers/hd/x/Xiong:Caiming", "Stephen Merity.....http://dblp.org/pers/hd/m/Merity:Stephen", "Richard Socher.....http://dblp.org/pers/hd/s/Socher:Richard"], "pages": 10}