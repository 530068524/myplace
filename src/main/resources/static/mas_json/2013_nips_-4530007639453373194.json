{"title": "Reward Mapping for Transfer in Long-Lived Agents.", "fields": ["reward based selection", "bounded function", "counterintuitive", "reuse", "machine learning"], "abstract": "We consider how to transfer knowledge from previous tasks (MDPs) to a current task in long-lived and bounded agents that must solve a sequence of tasks over a finite lifetime. A novel aspect of our transfer approach is that we reuse reward functions. While this may seem counterintuitive, we build on the insight of recent work on the optimal rewards problem that guiding an agent's behavior with reward functions other than the task-specifying reward function can help overcome computational bounds of the agent. Specifically, we use good guidance reward functions learned on previous tasks in the sequence to incrementally train a reward mapping function that maps task-specifying reward functions into good initial guidance reward functions for subsequent tasks. We demonstrate that our approach can substantially improve the agent's performance relative to other approaches, including an approach that transfers policies.", "citation": "Citations (3)", "departments": ["University of Michigan", "University of Michigan", "University of Michigan"], "authors": ["Xiaoxiao Guo.....http://dblp.org/pers/hd/g/Guo:Xiaoxiao", "Satinder P. Singh.....http://dblp.org/pers/hd/s/Singh:Satinder_P=", "Richard L. Lewis.....http://dblp.org/pers/hd/l/Lewis:Richard_L="], "conf": "nips", "year": "2013", "pages": 9}