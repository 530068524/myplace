{"title": "On the local optimality of LambdaRank.", "fields": ["learning to rank", "training set", "data mining", "small number", "machine learning"], "abstract": "A machine learning approach to learning to rank trains a model to optimize a target evaluation measure with repect to training data. Currently, existing information retrieval measures are impossible to optimize directly except for models with a very small number of parameters. The IR community thus faces a major challenge: how to optimize IR measures of interest directly. In this paper, we present a solution. Specifically, we show that LambdaRank, which smoothly approximates the gradient of the target measure, can be adapted to work with four popular IR target evaluation measures using the same underlying gradient construction. It is likely, therefore, that this construction is extendable to other evaluation measures. We empirically show that LambdaRank finds a locally optimal solution for mean NDCG@10, mean NDCG, MAP and MRR with a 99% confidence rate. We also show that the amount of effective training data varies with IR measure and that with a sufficiently large training set size, matching the training optimization measure to the target evaluation measure yields the best accuracy.", "citation": "Citations (82)", "departments": ["Carnegie Mellon University", "Microsoft", "Microsoft"], "authors": ["Pinar Donmez.....http://dblp.org/pers/hd/d/Donmez:Pinar", "Krysta Marie Svore.....http://dblp.org/pers/hd/s/Svore:Krysta_Marie", "Christopher J. C. Burges.....http://dblp.org/pers/hd/b/Burges:Christopher_J=_C="], "conf": "sigir", "year": "2009", "pages": 8}