{"title": "CalvinFS: Consistent WAN Replication and Scalable Metadata Management for Distributed File Systems.", "fields": ["torrent file", "fork", "self certifying file system", "unix file types", "file control block"], "abstract": "Existing file systems, even the most scalable systems that store hundreds of petabytes (or more) of data across thousands of machines, store file metadata on a single server or via a shared-disk architecture in order to ensure consistency and validity of the metadata.\n\nThis paper describes a completely different approach for the design of replicated, scalable file systems, which leverages a high-throughput distributed database system for metadata management. This results in improved scalability of the metadata layer of the file system, as file metadata can be partitioned (and replicated) across a (shared-nothing) cluster of independent servers, and operations on file metadata transformed into distributed transactions.\n\nIn addition, our file system is able to support standard file system semantics--including fully linearizable random writes by concurrent users to arbitrary byte offsets within the same file--across wide geographic areas. Such high performance, fully consistent, geographically distributed files systems do not exist today.\n\nWe demonstrate that our approach to file system design can scale to billions of files and handle hundreds of thousands of updates and millions of reads per second-- while maintaining consistently low read latencies. Furthermore, such a deployment can survive entire datacenter outages with only small performance hiccups and no loss of availability.", "citation": "Citations (62)", "departments": ["Google", "Yale University"], "authors": ["Alexander Thomson.....http://dblp.org/pers/hd/t/Thomson:Alexander", "Daniel J. Abadi.....http://dblp.org/pers/hd/a/Abadi:Daniel_J="], "conf": "fast", "year": "2015", "pages": 14}