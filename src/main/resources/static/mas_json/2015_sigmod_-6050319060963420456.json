{"title": "Bayesian Differential Privacy on Correlated Data.", "fields": ["probabilistic logic", "tuple", "adversary", "bayesian probability", "differential privacy"], "abstract": "Differential privacy provides a rigorous standard for evaluating the privacy of perturbation algorithms. It has widely been regarded that differential privacy is a universal definition that deals with both independent and correlated data and a differentially private algorithm can protect privacy against arbitrary adversaries. However, recent research indicates that differential privacy may not guarantee privacy against arbitrary adversaries if the data are correlated.   In this paper, we focus on the private perturbation algorithms on correlated data. We investigate the following three problems: (1) the influence of data correlations on privacy; (2) the influence of adversary prior knowledge on privacy; and (3) a general perturbation algorithm that is private for prior knowledge of any subset of tuples in the data when the data are correlated. We propose a Pufferfish definition of privacy, called Bayesian differential privacy, by which the privacy level of a probabilistic perturbation algorithm can be evaluated even when the data are correlated and when the prior knowledge is incomplete. We present a Gaussian correlation model to accurately describe the structure of data correlations and analyze the Bayesian differential privacy of the perturbation algorithm on the basis of this model. Our results show that privacy is poorest for an adversary who has the least prior knowledge. We further extend this model to a more general one that considers uncertain prior knowledge.", "citation": "Citations (25)", "year": "2015", "departments": ["Rakuten", "University of Tokyo", "University of Tokyo"], "conf": "sigmod", "authors": ["Bin Yang.....http://dblp.org/pers/hd/y/Yang:Bin", "Issei Sato.....http://dblp.org/pers/hd/s/Sato:Issei", "Hiroshi Nakagawa.....http://dblp.org/pers/hd/n/Nakagawa:Hiroshi"], "pages": 16}