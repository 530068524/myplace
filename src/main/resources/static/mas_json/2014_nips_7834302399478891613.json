{"title": "Do Deep Nets Really Need to be Deep?", "fields": ["computer science", "timit", "artificial intelligence", "artificial neural network", "machine learning"], "abstract": "Currently, deep neural networks are the state of the art on problems such as speech recognition and computer vision. In this paper we empirically demonstrate that shallow feed-forward nets can learn the complex functions previously learned by deep nets and achieve accuracies previously only achievable with deep models. Moreover, in some cases the shallow nets can learn these deep functions using the same number of parameters as the original deep models. On the TIMIT phoneme recognition and CIFAR-10 image recognition tasks, shallow nets can be trained that perform similarly to complex, well-engineered, deeper convolutional models.", "citation": "Citations (391)", "year": "2014", "departments": ["University of Toronto", "Microsoft", "Microsoft"], "conf": "nips", "authors": ["Jimmy Ba.....http://dblp.org/pers/hd/b/Ba:Jimmy", "Rich Caruana.....http://dblp.org/pers/hd/c/Caruana:Rich"], "pages": 9}