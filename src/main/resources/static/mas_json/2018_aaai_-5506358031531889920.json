{"title": "EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples.", "fields": ["elastic net regularization", "special case", "mnist database", "adversarial machine learning", "adversarial system"], "abstract": "Recent studies have highlighted the vulnerability of deep neural networks (DNNs) to adversarial examples - a visually indistinguishable adversarial image can easily be crafted to cause a well-trained model to misclassify. Existing methods for crafting adversarial examples are based on $L_2$ and $L_\\infty$ distortion metrics. However, despite the fact that $L_1$ distortion accounts for the total variation and encourages sparsity in the perturbation, little has been developed for crafting $L_1$-based adversarial examples. In this paper, we formulate the process of attacking DNNs via adversarial examples as an elastic-net regularized optimization problem. Our elastic-net attacks to DNNs (EAD) feature $L_1$-oriented adversarial examples and include the state-of-the-art $L_2$ attack as a special case. Experimental results on MNIST, CIFAR10 and ImageNet show that EAD can yield a distinct set of adversarial examples with small $L_1$ distortion and attains similar attack performance to the state-of-the-art methods in different attack scenarios. More importantly, EAD leads to improved attack transferability and complements adversarial training for DNNs, suggesting novel insights on leveraging $L_1$ distortion in adversarial machine learning and security implications of DNNs.", "citation": "Citations (16)", "departments": ["IBM", "IBM", "University of California, Davis", "IBM", "University of California, Davis"], "authors": ["Pin-Yu Chen.....http://dblp.org/pers/hd/c/Chen:Pin=Yu", "Yash Sharma.....http://dblp.org/pers/hd/s/Sharma:Yash", "Huan Zhang.....http://dblp.org/pers/hd/z/Zhang:Huan", "Jinfeng Yi.....http://dblp.org/pers/hd/y/Yi:Jinfeng", "Cho-Jui Hsieh.....http://dblp.org/pers/hd/h/Hsieh:Cho=Jui"], "conf": "aaai", "year": "2018", "pages": 8}