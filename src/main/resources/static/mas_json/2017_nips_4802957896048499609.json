{"title": "Federated Multi-Task Learning.", "fields": ["computer science", "machine learning", "artificial intelligence", "fault tolerance", "multi task learning"], "abstract": "Federated learning poses new statistical and systems challenges in training machine learning models over distributed networks of devices. In this work, we show that multi-task learning is naturally suited to handle the statistical challenges of this setting, and propose a novel systems-aware optimization method, MOCHA, that is robust to practical systems issues. Our method and theory for the first time consider issues of high communication cost, stragglers, and fault tolerance for distributed multi-task learning. The resulting method achieves significant speedups compared to alternatives in the federated setting, as we demonstrate through simulations on real-world federated datasets.", "citation": "Citations (5)", "year": "2017", "departments": ["University of California, Berkeley", "University of California, Los Angeles", "University of Southern California", "University of California, Los Angeles"], "conf": "nips", "authors": ["Virginia Smith.....http://dblp.org/pers/hd/s/Smith:Virginia", "Chao-Kai Chiang.....http://dblp.org/pers/hd/c/Chiang:Chao=Kai", "Maziar Sanjabi.....http://dblp.org/pers/hd/s/Sanjabi:Maziar", "Ameet S. Talwalkar.....http://dblp.org/pers/hd/t/Talwalkar:Ameet_S="], "pages": 11}