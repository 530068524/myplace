{"title": "Scalable Training of Markov Logic Networks Using Approximate Counting.", "fields": ["markov logic network", "markov chain", "computation", "scalability", "orders of magnitude"], "abstract": "In this paper, we propose principled weight learning algorithms for Markov logic networks that can easily scale to much larger datasets and application domains than existing algorithms. The main idea in our approach is to use approximate counting techniques to substantially reduce the complexity of the most computation intensive sub-step in weight learning: computing the number of groundings of a first-order formula that evaluate to true given a truth assignment to all the random variables. We derive theoretical bounds on the performance of our new algorithms and demonstrate experimentally that they are orders of magnitude faster and achieve the same accuracy or better than existing approaches.", "citation": "Citations (5)", "departments": ["University of Texas at Dallas", "University of Memphis", "University of Texas at Dallas", "Indian Institute of Technology Delhi", "University of Texas at Dallas"], "authors": ["Somdeb Sarkhel.....http://dblp.org/pers/hd/s/Sarkhel:Somdeb", "Deepak Venugopal.....http://dblp.org/pers/hd/v/Venugopal:Deepak", "Tuan Anh Pham.....http://dblp.org/pers/hd/p/Pham:Tuan_Anh", "Parag Singla.....http://dblp.org/pers/hd/s/Singla:Parag", "Vibhav Gogate.....http://dblp.org/pers/hd/g/Gogate:Vibhav"], "conf": "aaai", "year": "2016", "pages": 7}