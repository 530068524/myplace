{"title": "Out-of-sample extension of graph adjacency spectral embedding.", "fields": ["vertex", "central limit theorem", "adjacency list", "embedding", "dot product"], "abstract": "Many popular dimensionality reduction procedures have out-of-sample extensions, which allow a practitioner to apply a learned embedding to observations not seen in the initial training sample. In this work, we consider the problem of obtaining an out-of-sample extension for the adjacency spectral embedding, a procedure for embedding the vertices of a graph into Euclidean space. We present two different approaches to this problem, one based on a least-squares objective and the other based on a maximum-likelihood formulation. We show that if the graph of interest is drawn according to a certain latent position model called a random dot product graph, then both of these out-of-sample extensions estimate the true latent position of the out-of-sample vertex with the same error rate. Further, we prove a central limit theorem for the least-squares-based extension, showing that the estimate is asymptotically normal about the truth in the large-graph limit.", "citation": "Not cited", "departments": ["University of Michigan", "University of Queensland", "University of California, Berkeley", "Johns Hopkins University"], "authors": ["Keith Levin.....http://dblp.org/pers/hd/l/Levin:Keith", "Farbod Roosta-Khorasani.....http://dblp.org/pers/hd/r/Roosta=Khorasani:Farbod", "Michael W. Mahoney.....http://dblp.org/pers/hd/m/Mahoney:Michael_W=", "Carey E. Priebe.....http://dblp.org/pers/hd/p/Priebe:Carey_E="], "conf": "icml", "year": "2018", "pages": 10}