{"title": "Privacy-preserving statistical estimation with optimal convergence rates.", "fields": ["v statistic", "asymptotic distribution", "statistic", "sampling distribution", "asymptotic theory"], "abstract": "Consider an analyst who wants to release aggregate statistics about a data set containing sensitive information. Using  differentially private  algorithms guarantees that the released statistics reveal very little about any particular record in the data set. In this paper we study the asymptotic properties of differentially private algorithms for statistical inference.   We show that for a large class of statistical estimators T and input distributions P, there is a differentially private estimator A T  with the same asymptotic distribution as T. That is, the random variables A T (X) and T(X) converge in distribution when X consists of an i.i.d. sample from P of increasing size. This implies that A T (X) is essentially as good as the original statistic T(X) for statistical inference, for sufficiently large samples. Our technique applies to (almost) any pair T,P such that T is asymptotically normal on i.i.d. samples from P---in particular, to parametric maximum likelihood estimators and estimators for logistic and linear regression under standard regularity conditions.   A consequence of our techniques is the existence of low-space streaming algorithms whose output converges to the same asymptotic distribution as a given estimator T (for the same class of estimators and input distributions as above).", "citation": "Citations (128)", "year": "2011", "departments": ["Pennsylvania State University"], "conf": "stoc", "authors": ["Adam D. Smith.....http://dblp.org/pers/hd/s/Smith:Adam_D="], "pages": 10}