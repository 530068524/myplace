{"title": "Multi-Task Learning for Multiple Language Translation.", "fields": ["example based machine translation", "computer assisted translation", "machine translation software usability", "universal networking language", "multi task learning"], "abstract": "In this paper, we investigate the problem of learning a machine translation model that can simultaneously translate sentences from one source language to multiple target languages. Our solution is inspired by the recently proposed neural machine translation model which generalizes machine translation as a sequence learning problem. We extend the neural machine translation to a multi-task learning framework which shares source language representation and separates the modeling of different target language translation. Our framework can be applied to situations where either large amounts of parallel data or limited parallel data is available. Experiments show that our multi-task learning model is able to achieve significantly higher translation quality over individually learned model in both situations on the data sets publicly available.", "citation": "Citations (103)", "year": "2015", "departments": ["Baidu", "Baidu", "Harbin Institute of Technology", "Baidu"], "conf": "acl", "authors": ["Daxiang Dong.....http://dblp.org/pers/hd/d/Dong:Daxiang", "Hua Wu.....http://dblp.org/pers/hd/w/Wu_0003:Hua", "Wei He.....http://dblp.org/pers/hd/h/He:Wei", "Dianhai Yu.....http://dblp.org/pers/hd/y/Yu:Dianhai", "Haifeng Wang.....http://dblp.org/pers/hd/w/Wang:Haifeng"], "pages": 10}