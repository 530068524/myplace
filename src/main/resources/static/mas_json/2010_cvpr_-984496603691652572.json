{"title": "Modeling mutual context of object and human pose in human-object interaction activities.", "fields": ["articulated body pose estimation", "context model", "object model", "pose", "3d pose estimation"], "abstract": "Detecting objects in cluttered scenes and estimating articulated human body parts are two challenging problems in computer vision. The difficulty is particularly pronounced in activities involving human-object interactions (e.g. playing tennis), where the relevant object tends to be small or only partially visible, and the human body parts are often self-occluded. We observe, however, that objects and human poses can serve as mutual context to each other \u2013 recognizing one facilitates the recognition of the other. In this paper we propose a new random field model to encode the mutual context of objects and human poses in human-object interaction activities. We then cast the model learning task as a structure learning problem, of which the structural connectivity between the object, the overall human pose, and different body parts are estimated through a structure search approach, and the parameters of the model are estimated by a new max-margin algorithm. On a sports data set of six classes of human-object interactions [12], we show that our mutual context model significantly outperforms state-of-the-art in detecting very difficult objects and human poses.", "citation": "Citations (469)", "year": "2010", "departments": ["Stanford University", "Stanford University"], "conf": "cvpr", "authors": ["Bangpeng Yao.....http://dblp.org/pers/hd/y/Yao:Bangpeng", "Fei-Fei Li.....http://dblp.org/pers/hd/l/Li:Fei=Fei"], "pages": 8}