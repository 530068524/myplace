{"title": "Model Selection for High-Dimensional Regression under the Generalized Irrepresentability Condition.", "fields": ["ordinary least squares", "covariate", "sample size determination", "model selection", "lasso"], "abstract": "In the high-dimensional regression model a response variable is linearly related to p covariates, but the sample size n is smaller than p. We assume that only a small subset of covariates is 'active' (i.e., the corresponding coefficients are non-zero), and consider the model-selection problem of identifying the active covariates.\n\nA popular approach is to estimate the regression coefficients through the Lasso (l1-regularized least squares). This is known to correctly identify the active set only if the irrelevant covariates are roughly orthogonal to the relevant ones, as quantified through the so called 'irrepresentability' condition. In this paper we study the 'Gauss-Lasso' selector, a simple two-stage method that first solves the Lasso, and then performs ordinary least squares restricted to the Lasso active set.\n\nWe formulate 'generalized irrepresentability condition' (GIC), an assumption that is substantially weaker than irrepresentability. We prove that, under GIC, the Gauss-Lasso correctly recovers the active set.", "citation": "Citations (8)", "departments": ["Stanford University", "Stanford University"], "authors": ["Adel Javanmard.....http://dblp.org/pers/hd/j/Javanmard:Adel", "Andrea Montanari.....http://dblp.org/pers/hd/m/Montanari:Andrea"], "conf": "nips", "year": "2013", "pages": 9}